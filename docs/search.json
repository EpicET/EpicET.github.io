[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Machine Learning Blog",
    "section": "",
    "text": "Pnuemonia Detection\n\n\n\n\n\nIn this project, we built a convolutional neural network (CNN) to embed chest X-ray images into a latent space, then compared three binary classifiers‚ÄîSupport Vector Machine, XGBoost, and Transformer‚Äîon their ability to detect pneumonia.\n\n\n\n\n\nMay 19, 2025\n\n\nLia Smith, Cameron Hudson, Robsan Dinka, Emmanuel Towner\n\n\n\n\n\n\n\n\n\n\n\n\nAdvanced Optimization\n\n\n\n\n\nIn this blog post, I explore three advanced optimization techniques‚ÄîNewton‚Äôs Method, the Adam optimizer, and Gradient Descent Optimizer‚Äîin the context of logistic regression applied to heart disease prediction. The goal is to understand how different optimization algorithms influence model performance and training dynamics in a binary classification tasks.\n\n\n\n\n\nMay 7, 2025\n\n\nEmmanuel Towner\n\n\n\n\n\n\n\n\n\n\n\n\nSparse Kernel Machines\n\n\n\n\n\nIn this post, I implement a sparse kernel logistic regression using radial basis function (RBF) kernels. Additionally, explore how regularization strength (ùúÜ) and the bandwidth (ùõæ) effect influence it‚Äôs sparsity and overfitting.\n\n\n\n\n\nApr 29, 2025\n\n\nEmmanuel Towner\n\n\n\n\n\n\n\n\n\n\n\n\nOverfitting and Double Descents\n\n\n\n\n\nIn this blog post, I explore the deep learning phenomenon of overfitting and the resulting double descent using a linear regression model and an overparameterized optimizer. I evaluated the model by its mean squared error (MSE) based on number of features.\n\n\n\n\n\nApr 23, 2025\n\n\nEmmanuel Towner\n\n\n\n\n\n\n\n\n\n\n\n\nImplementing Logistic Regression\n\n\n\n\n\nThis blog post implements logistic regression with momentum from scratch in Python and performs three experiments evaluating the loss and accuracy.\n\n\n\n\n\nApr 9, 2025\n\n\nEmmanuel Towner\n\n\n\n\n\n\n\n\n\n\n\n\nAuditing Bias\n\n\n\n\n\nIn this blog post, my goal was to make a prediction of employment status based on various demographics excluding race using a subset of data from the American Community Service focused on Massachusetts residents in 2023. After training a model on this data, I evaluated its performance and examined potential biases in its predictions.\n\n\n\n\n\nMar 12, 2025\n\n\nEmmanuel Towner\n\n\n\n\n\n\n\n\n\n\n\n\nClassifying Palmer Penguins\n\n\n\n\n\nIn this blog post, I analyze the Palmer Penguins dataset to identify the best features for determining penguin species based on their measurements.\n\n\n\n\n\nFeb 12, 2025\n\n\nEmmanuel Towner\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Emmanuel Towner",
    "section": "",
    "text": "Pneumonia Classification\nA deep learning project that used a Vision Transformer to classify pneumonia in chest X-rays.\nBanking Application\nA full-stack web application simulating bank functions, built with Java SpringBoot and React.\nMiddHousing\nA web app for Middlebury students to find and review dorm rooms, featuring a campus map and user reviews."
  },
  {
    "objectID": "index.html#projects",
    "href": "index.html#projects",
    "title": "Emmanuel Towner",
    "section": "",
    "text": "Pneumonia Classification\nA deep learning project that used a Vision Transformer to classify pneumonia in chest X-rays.\nBanking Application\nA full-stack web application simulating bank functions, built with Java SpringBoot and React.\nMiddHousing\nA web app for Middlebury students to find and review dorm rooms, featuring a campus map and user reviews."
  },
  {
    "objectID": "index.html#latest-blog-post",
    "href": "index.html#latest-blog-post",
    "title": "Emmanuel Towner",
    "section": "üìù Latest Blog Post",
    "text": "üìù Latest Blog Post\n\nPneumonia Detection Project\nAn exploration of deep learning techniques for pneumonia detection in chest X-rays.\n\nMore Blog Posts"
  },
  {
    "objectID": "index.html#lets-connect",
    "href": "index.html#lets-connect",
    "title": "Emmanuel Towner",
    "section": "üì¨ Let‚Äôs Connect",
    "text": "üì¨ Let‚Äôs Connect\nLinkedIn | Email"
  },
  {
    "objectID": "projects/vit/vit.html",
    "href": "projects/vit/vit.html",
    "title": "Pneumonia Classification with Vision Transformer",
    "section": "",
    "text": "This model was part of a larger project where a team built a machine learning pipeline for image classification. We leveraged the Kaggle pneumonia chest X-ray dataset, which contains labeled normal and pneumonia cases. Our pipeline consisted of a CNN autoencoder to extract latent vectors from the images, which were then fed into different machine learning models for classification."
  },
  {
    "objectID": "projects/vit/vit.html#overview",
    "href": "projects/vit/vit.html#overview",
    "title": "Pneumonia Classification with Vision Transformer",
    "section": "",
    "text": "This model was part of a larger project where a team built a machine learning pipeline for image classification. We leveraged the Kaggle pneumonia chest X-ray dataset, which contains labeled normal and pneumonia cases. Our pipeline consisted of a CNN autoencoder to extract latent vectors from the images, which were then fed into different machine learning models for classification."
  },
  {
    "objectID": "projects/vit/vit.html#my-role",
    "href": "projects/vit/vit.html#my-role",
    "title": "Pneumonia Classification with Vision Transformer",
    "section": "My Role",
    "text": "My Role\nI designed a Vision Transformer in PyTorch that processed latent vectors, using self-attention mechanisms for binary image classification. The model achieved 77% overall accuracy and 98% recall on pneumonia cases. We felt that minimizing false negatives was more important than maximizing overall accuracy, effectively addressing class imbalance."
  },
  {
    "objectID": "projects/vit/vit.html#features",
    "href": "projects/vit/vit.html#features",
    "title": "Pneumonia Classification with Vision Transformer",
    "section": "Features",
    "text": "Features\n\nAccepts latent vectors as input\nComputes probabilities for each class (pneumonia or not pneumonia)\nTrains, tests, and evaluates the model"
  },
  {
    "objectID": "projects/vit/vit.html#technologies",
    "href": "projects/vit/vit.html#technologies",
    "title": "Pneumonia Classification with Vision Transformer",
    "section": "Technologies",
    "text": "Technologies\nPython, PyTorch, NumPy, scikit-learn"
  },
  {
    "objectID": "projects/vit/vit.html#links",
    "href": "projects/vit/vit.html#links",
    "title": "Pneumonia Classification with Vision Transformer",
    "section": "Links",
    "text": "Links\n\nüì¶ Transformer Repository\nüìñ Project Repository\n\n\n\n\n\nChest X-Ray"
  },
  {
    "objectID": "posts/kernel/index.html",
    "href": "posts/kernel/index.html",
    "title": "Sparse Kernel Machines",
    "section": "",
    "text": "In this post, I explore sparse kernel logistic regression using radial basis function (RBF) kernels. I demonstrate how sparsity naturally emerges in these models, meaning only a subset of training points contribute significantly to the final decision function. I examine how key hyperparameters like the regularization strength (ùúÜ) and the bandwidth (ùõæ) influence model behavior, including sparsity, decision boundaries, and overfitting. Through several experiments, I visualize decision surface, investigate the impact of parameter choices, and show how kernel methods can capture nonlinear patterns effectively. To evaluate generalization, I conclude with an overfitting case study using ROC curves to compare training and test performance.\n\n\nCode\n%load_ext autoreload\n%autoreload 2\n\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\nClassification (cell 15) and kernel (cell 16) code adapted from Prof.¬†Phil.\n\n\nCode\nimport torch\nfrom matplotlib import pyplot as plt\n\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\n\ndef classification_data(n_points=300, noise=0.2, p_dims=2):\n\n    y = torch.arange(n_points) &gt;= int(n_points / 2)\n    y = 1.0 * y\n    X = y[:, None] + torch.normal(0.0, noise, size=(n_points, p_dims))\n    # X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    X = X - X.mean(dim=0, keepdim=True)\n    return X, y\n\n\ndef plot_classification_data(X, y, ax):\n    assert X.shape[1] == 2, \"This function only works for data created with p_dims == 2\"\n    targets = [0, 1]\n    markers = [\"o\", \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(\n            X[ix, 0],\n            X[ix, 1],\n            s=20,\n            c=y[ix],\n            facecolors=\"none\",\n            edgecolors=\"darkgrey\",\n            cmap=\"BrBG\",\n            vmin=-1,\n            vmax=2,\n            alpha=0.8,\n            marker=markers[i],\n        )\n    ax.set(xlabel=r\"$x_1$\", ylabel=r\"$x_2$\")\n\n\nfig, ax = plt.subplots(1, 1)\nX, y = classification_data(n_points=100, noise=0.4)\nplot_classification_data(X, y, ax)\n\n\n\n\n\n\n\n\n\n\n\nCode\ndef rbf_kernel(X_1, X_2, gamma):\n    return torch.exp(-gamma * torch.cdist(X_1, X_2) ** 2)\n\n\n\n\nCode\nfrom kernel_logistic import KernelLogisticRegression\n\nKR = KernelLogisticRegression(rbf_kernel, lam = 0.1, gamma = 1)\nKR.fit(X, y, m_epochs = 500000, lr = 0.0001)\n\n\n\n\nCode\n(1.0 * (KR.a &gt; 0.001)).mean()\n\n\ntensor(0.5300)\n\n\n\n\nCode\nix = torch.abs(KR.a) &gt; 0.001\n\nx1 = torch.linspace(X[:, 0].min() - 0.2, X[:, 0].max() + 0.2, 101)\nx2 = torch.linspace(X[:, 1].min() - 0.2, X[:, 1].max() + 0.2, 101)\n\nX1, X2 = torch.meshgrid(x1, x2, indexing=\"ij\")\n\nx1 = X1.ravel()\nx2 = X2.ravel()\n\nX_ = torch.stack((x1, x2), dim=1)\n\npreds = KR.prediction(X_, recompute_kernel=True)\npreds = 1.0 * torch.reshape(preds, X1.size())\n\nfig, ax = plt.subplots(1, 1)\nax.contourf(\n    X1,\n    X2,\n    preds,\n    origin=\"lower\",\n    cmap=\"BrBG\",\n    vmin=2 * preds.min() - preds.max(),\n    vmax=2 * preds.max() - preds.min(),\n)\nplot_classification_data(X, y, ax)\nplt.scatter(X[ix, 0], X[ix, 1], facecolors=\"none\", edgecolors=\"black\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis experiment shows that when ùúÜ is very large, there may be only one point in the training data with a wieght distinguishable from zero.\n\n\nCode\nKR = KernelLogisticRegression(rbf_kernel, lam=166, gamma=1)\nKR.fit(X, y, m_epochs=20000, lr=0.0001)\n\nix = torch.abs(KR.a) &gt; 0.001\n\nx1 = torch.linspace(X[:, 0].min() - 0.2, X[:, 0].max() + 0.2, 101)\nx2 = torch.linspace(X[:, 1].min() - 0.2, X[:, 1].max() + 0.2, 101)\n\nX1, X2 = torch.meshgrid(x1, x2, indexing=\"ij\")\n\nx1 = X1.ravel()\nx2 = X2.ravel()\n\nX_ = torch.stack((x1, x2), dim=1)\n\npreds = KR.prediction(X_, recompute_kernel=True)\npreds = 1.0 * torch.reshape(preds, X1.size())\n\nfig, ax = plt.subplots(1, 1)\nax.contourf(\n    X1,\n    X2,\n    preds,\n    origin=\"lower\",\n    cmap=\"BrBG\",\n    vmin=2 * preds.min() - preds.max(),\n    vmax=2 * preds.max() - preds.min(),\n)\nplot_classification_data(X, y, ax)\nplt.scatter(X[ix, 0], X[ix, 1], facecolors=\"none\", edgecolors=\"black\")\nplt.show()\n\n\n\n\n\n\n\n\n\nAt a lambda of ~166, there was only 1 data point in the center of brown region that had a distinguishable weight.\n\n\n\nThis experiment is to show that changing ùõÑ can result in wigglier descision boundaries.\n\n\nCode\ngammas = [1, 10, 20, 50, 100]  # List of gamma values to try\nfig, axs = plt.subplots(1, 5, figsize=(20, 4))  # One row, 5 subplots\n\nfor i, gamma in enumerate(gammas):\n    KR = KernelLogisticRegression(rbf_kernel, lam=0.1, gamma=gamma)\n    KR.fit(X, y, m_epochs=10000, lr=0.0001)\n\n    ix = torch.abs(KR.a) &gt; 0.001\n\n    x1 = torch.linspace(X[:, 0].min() - 0.2, X[:, 0].max() + 0.2, 101)\n    x2 = torch.linspace(X[:, 1].min() - 0.2, X[:, 1].max() + 0.2, 101)\n    X1, X2 = torch.meshgrid(x1, x2, indexing=\"ij\")\n    x1_r = X1.ravel()\n    x2_r = X2.ravel()\n    X_ = torch.stack((x1_r, x2_r), dim=1)\n\n    preds = KR.prediction(X_, recompute_kernel=True)\n    preds = torch.reshape(preds, X1.size())\n\n    axs[i].set_title(f\"Gamma = {gamma}\")\n    \n    axs[i].contourf(\n        X1,\n        X2,\n        preds,\n        origin=\"lower\",\n        cmap=\"BrBG\",\n        vmin=2 * preds.min() - preds.max(),\n        vmax=2 * preds.max() - preds.min(),\n    )\n    # Actual decision boundary at probability 0.5\n    axs[i].contour(X1, X2, preds, levels=[0.5], colors='black', linewidths=2)\n\n    plot_classification_data(X, y, axs[i])\n    axs[i].scatter(X[ix, 0], X[ix, 1], facecolors=\"none\", edgecolors=\"black\", label='Support Vectors')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nIn this experiment, I test my model with a gammas of 1, 10, 20, 50, 100 to see with the decision boundaries looked like. I observed that is the gamma increased the boundaries became more focused on one class and more wiggly.\n\n\n\nThis experiment shows that the kernelized model can still find the pattern within nonlinear data. First, I generate nonlinear data for the model to use.\n\n\nCode\nfrom sklearn.datasets import make_moons\n\nX_nonlinear, y_nonlinear = make_moons(n_samples=400, noise=0.9)\n\n\nX_nonlinear = torch.tensor(X_nonlinear, dtype=torch.float32)\ny_nonlinear = torch.tensor(y_nonlinear, dtype=torch.float32)\n\n\nThen I run the usual graphing code to visualize results.\n\n\nCode\nKR = KernelLogisticRegression(rbf_kernel, lam=1.0, gamma=10)\nKR.fit(X_nonlinear, y_nonlinear, m_epochs=200000, lr=0.0001)\n\nix = torch.abs(KR.a) &gt; 0.001\n\nx1 = torch.linspace(X_nonlinear[:, 0].min() - 0.2, X_nonlinear[:, 0].max() + 0.2, 101)\nx2 = torch.linspace(X_nonlinear[:, 1].min() - 0.2, X_nonlinear[:, 1].max() + 0.2, 101)\n\nX1, X2 = torch.meshgrid(x1, x2, indexing=\"ij\")\n\nx1 = X1.ravel()\nx2 = X2.ravel()\n\nX_ = torch.stack((x1, x2), dim=1)\n\npreds = KR.prediction(X_, recompute_kernel=True)\npreds = 1.0 * torch.reshape(preds, X1.size())\n\nfig, ax = plt.subplots(1, 1)\nax.contourf(\n    X1,\n    X2,\n    preds,\n    origin=\"lower\",\n    cmap=\"BrBG\",\n    vmin=2 * preds.min() - preds.max(),\n    vmax=2 * preds.max() - preds.min(),\n)\n\nax.contour(X1, X2, preds, levels=[0.5], colors='black', linewidths=2)\n\nplot_classification_data(X_nonlinear, y_nonlinear, ax)\nplt.scatter(X_nonlinear[ix, 0], X_nonlinear[ix, 1], facecolors=\"none\", edgecolors=\"black\")\nplt.title(\"Kernel Logistic Regression on Nonlinear Data\")\nplt.show()\n\n\n\n\n\n\n\n\n\nIn this experiment, the model is used to classify classify nonlinear data generated by make_moons. Initially, with a low gamma value (Œ≥ = 0.01), the model underfit the data, producing a nearly linear decision boundary that failed to capture the curved structure of the classes. By increasing gamma to 10, the kernel returned a more accurate nonlinear decision boundaries. Both separated concentrations of the blue region from the brown.s\n\n\n\n\n\n\nCode\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import train_test_split\n\n# Generate and split data\nX_over, y_over = classification_data(n_points=1000, noise=0.8)\nX_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.4, random_state=42)\n\n# Fit a model with high gamma (likely to overfit)\nKRO = KernelLogisticRegression(rbf_kernel, lam=1e-5, gamma=1000)\nKRO.fit(X_train, y_train, m_epochs=30000, lr=0.0001)\n\n# Predict probabilities on train and test\nwith torch.no_grad():\n    y_train_scores = KRO.prediction(X_train, recompute_kernel=True)\n    y_test_scores = KRO.prediction(X_test, recompute_kernel=True)\n\n# Convert to NumPy for sklearn\ny_train_np = y_train.numpy()\ny_test_np = y_test.numpy()\ntrain_scores_np = y_train_scores.numpy()\ntest_scores_np = y_test_scores.numpy()\n\n# Compute ROC curves\nfpr_train, tpr_train, _ = roc_curve(y_train_np, train_scores_np)\nfpr_test, tpr_test, _ = roc_curve(y_test_np, test_scores_np)\n\n# Compute AUC\nroc_auc_train = auc(fpr_train, tpr_train)\nroc_auc_test = auc(fpr_test, tpr_test)\n\n# Plot\nplt.figure(figsize=(7, 5))\nplt.plot(fpr_train, tpr_train, label=f\"Train ROC (AUC = {roc_auc_train:.2f})\")\nplt.plot(fpr_test, tpr_test, label=f\"Test ROC (AUC = {roc_auc_test:.2f})\", linestyle='--')\nplt.plot([0, 1], [0, 1], \"k--\", alpha=0.5)\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curves: Overfitting\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nIn this experiment, I simulate the problem of overfitting by training a kernel logistic regression model with extremely high gamma of 1000. This allows the model to fit the training data very closely, but it generalizes poorly to unseen test data.\nThe (AUC) score for training set was near with perfect with 0.99 but the testing set was near 0.72. This large gap between train and test AUCs is a sign that there is overfitting.\n\n\n\nIn this post, I explored the behavior of sparse kernel logistic regression with RBF kernels through several experiments:\n\nSparsity and Regularization: When using a large regularization parameter (ùúÜ = 166), only 1 out of 100 training points had a weight (Œ±) greater than 0.001, demonstrating extreme sparsity. In contrast, with a smaller ùúÜ (e.g., 0.1), a larger fraction of points acted as support vectors, contributing to the decision boundary.\nEffect of Gamma (ùõæ): By varying ùõæ from 1 to 100, I observed that the decision boundary became increasingly complex and less smooth. For example, at ùõæ = 1, the boundary was broad and circular, while at ùõæ = 100, it became highly irregular, closely fitting the training data.\nNonlinear Data: On a challenging, noisy dataset (400 points, noise = 0.9), the kernelized model with ùõæ = 10 was still able to capture the nonlinear patterns.\nOverfitting: Training with a very high ùõæ (1000) and low ùúÜ (1e-5) on a larger dataset (1000 points, noise = 0.8), the model achieved a near-perfect training AUC of 0.99, but the test AUC dropped to 0.72. This large gap quantitatively demonstrates overfitting: the model fits the training data extremely well but fails to generalize.\n\n\n\n\n\nAdapted code from Professor Phil Chodrow at Middlebury College in his class CSCI 0451: Machine Learning."
  },
  {
    "objectID": "posts/kernel/index.html#abstract",
    "href": "posts/kernel/index.html#abstract",
    "title": "Sparse Kernel Machines",
    "section": "",
    "text": "In this post, I explore sparse kernel logistic regression using radial basis function (RBF) kernels. I demonstrate how sparsity naturally emerges in these models, meaning only a subset of training points contribute significantly to the final decision function. I examine how key hyperparameters like the regularization strength (ùúÜ) and the bandwidth (ùõæ) influence model behavior, including sparsity, decision boundaries, and overfitting. Through several experiments, I visualize decision surface, investigate the impact of parameter choices, and show how kernel methods can capture nonlinear patterns effectively. To evaluate generalization, I conclude with an overfitting case study using ROC curves to compare training and test performance.\n\n\nCode\n%load_ext autoreload\n%autoreload 2\n\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\nClassification (cell 15) and kernel (cell 16) code adapted from Prof.¬†Phil.\n\n\nCode\nimport torch\nfrom matplotlib import pyplot as plt\n\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n\n\ndef classification_data(n_points=300, noise=0.2, p_dims=2):\n\n    y = torch.arange(n_points) &gt;= int(n_points / 2)\n    y = 1.0 * y\n    X = y[:, None] + torch.normal(0.0, noise, size=(n_points, p_dims))\n    # X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    X = X - X.mean(dim=0, keepdim=True)\n    return X, y\n\n\ndef plot_classification_data(X, y, ax):\n    assert X.shape[1] == 2, \"This function only works for data created with p_dims == 2\"\n    targets = [0, 1]\n    markers = [\"o\", \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(\n            X[ix, 0],\n            X[ix, 1],\n            s=20,\n            c=y[ix],\n            facecolors=\"none\",\n            edgecolors=\"darkgrey\",\n            cmap=\"BrBG\",\n            vmin=-1,\n            vmax=2,\n            alpha=0.8,\n            marker=markers[i],\n        )\n    ax.set(xlabel=r\"$x_1$\", ylabel=r\"$x_2$\")\n\n\nfig, ax = plt.subplots(1, 1)\nX, y = classification_data(n_points=100, noise=0.4)\nplot_classification_data(X, y, ax)\n\n\n\n\n\n\n\n\n\n\n\nCode\ndef rbf_kernel(X_1, X_2, gamma):\n    return torch.exp(-gamma * torch.cdist(X_1, X_2) ** 2)\n\n\n\n\nCode\nfrom kernel_logistic import KernelLogisticRegression\n\nKR = KernelLogisticRegression(rbf_kernel, lam = 0.1, gamma = 1)\nKR.fit(X, y, m_epochs = 500000, lr = 0.0001)\n\n\n\n\nCode\n(1.0 * (KR.a &gt; 0.001)).mean()\n\n\ntensor(0.5300)\n\n\n\n\nCode\nix = torch.abs(KR.a) &gt; 0.001\n\nx1 = torch.linspace(X[:, 0].min() - 0.2, X[:, 0].max() + 0.2, 101)\nx2 = torch.linspace(X[:, 1].min() - 0.2, X[:, 1].max() + 0.2, 101)\n\nX1, X2 = torch.meshgrid(x1, x2, indexing=\"ij\")\n\nx1 = X1.ravel()\nx2 = X2.ravel()\n\nX_ = torch.stack((x1, x2), dim=1)\n\npreds = KR.prediction(X_, recompute_kernel=True)\npreds = 1.0 * torch.reshape(preds, X1.size())\n\nfig, ax = plt.subplots(1, 1)\nax.contourf(\n    X1,\n    X2,\n    preds,\n    origin=\"lower\",\n    cmap=\"BrBG\",\n    vmin=2 * preds.min() - preds.max(),\n    vmax=2 * preds.max() - preds.min(),\n)\nplot_classification_data(X, y, ax)\nplt.scatter(X[ix, 0], X[ix, 1], facecolors=\"none\", edgecolors=\"black\")\nplt.show()"
  },
  {
    "objectID": "posts/kernel/index.html#basic-experiments",
    "href": "posts/kernel/index.html#basic-experiments",
    "title": "Sparse Kernel Machines",
    "section": "",
    "text": "This experiment shows that when ùúÜ is very large, there may be only one point in the training data with a wieght distinguishable from zero.\n\n\nCode\nKR = KernelLogisticRegression(rbf_kernel, lam=166, gamma=1)\nKR.fit(X, y, m_epochs=20000, lr=0.0001)\n\nix = torch.abs(KR.a) &gt; 0.001\n\nx1 = torch.linspace(X[:, 0].min() - 0.2, X[:, 0].max() + 0.2, 101)\nx2 = torch.linspace(X[:, 1].min() - 0.2, X[:, 1].max() + 0.2, 101)\n\nX1, X2 = torch.meshgrid(x1, x2, indexing=\"ij\")\n\nx1 = X1.ravel()\nx2 = X2.ravel()\n\nX_ = torch.stack((x1, x2), dim=1)\n\npreds = KR.prediction(X_, recompute_kernel=True)\npreds = 1.0 * torch.reshape(preds, X1.size())\n\nfig, ax = plt.subplots(1, 1)\nax.contourf(\n    X1,\n    X2,\n    preds,\n    origin=\"lower\",\n    cmap=\"BrBG\",\n    vmin=2 * preds.min() - preds.max(),\n    vmax=2 * preds.max() - preds.min(),\n)\nplot_classification_data(X, y, ax)\nplt.scatter(X[ix, 0], X[ix, 1], facecolors=\"none\", edgecolors=\"black\")\nplt.show()\n\n\n\n\n\n\n\n\n\nAt a lambda of ~166, there was only 1 data point in the center of brown region that had a distinguishable weight.\n\n\n\nThis experiment is to show that changing ùõÑ can result in wigglier descision boundaries.\n\n\nCode\ngammas = [1, 10, 20, 50, 100]  # List of gamma values to try\nfig, axs = plt.subplots(1, 5, figsize=(20, 4))  # One row, 5 subplots\n\nfor i, gamma in enumerate(gammas):\n    KR = KernelLogisticRegression(rbf_kernel, lam=0.1, gamma=gamma)\n    KR.fit(X, y, m_epochs=10000, lr=0.0001)\n\n    ix = torch.abs(KR.a) &gt; 0.001\n\n    x1 = torch.linspace(X[:, 0].min() - 0.2, X[:, 0].max() + 0.2, 101)\n    x2 = torch.linspace(X[:, 1].min() - 0.2, X[:, 1].max() + 0.2, 101)\n    X1, X2 = torch.meshgrid(x1, x2, indexing=\"ij\")\n    x1_r = X1.ravel()\n    x2_r = X2.ravel()\n    X_ = torch.stack((x1_r, x2_r), dim=1)\n\n    preds = KR.prediction(X_, recompute_kernel=True)\n    preds = torch.reshape(preds, X1.size())\n\n    axs[i].set_title(f\"Gamma = {gamma}\")\n    \n    axs[i].contourf(\n        X1,\n        X2,\n        preds,\n        origin=\"lower\",\n        cmap=\"BrBG\",\n        vmin=2 * preds.min() - preds.max(),\n        vmax=2 * preds.max() - preds.min(),\n    )\n    # Actual decision boundary at probability 0.5\n    axs[i].contour(X1, X2, preds, levels=[0.5], colors='black', linewidths=2)\n\n    plot_classification_data(X, y, axs[i])\n    axs[i].scatter(X[ix, 0], X[ix, 1], facecolors=\"none\", edgecolors=\"black\", label='Support Vectors')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nIn this experiment, I test my model with a gammas of 1, 10, 20, 50, 100 to see with the decision boundaries looked like. I observed that is the gamma increased the boundaries became more focused on one class and more wiggly.\n\n\n\nThis experiment shows that the kernelized model can still find the pattern within nonlinear data. First, I generate nonlinear data for the model to use.\n\n\nCode\nfrom sklearn.datasets import make_moons\n\nX_nonlinear, y_nonlinear = make_moons(n_samples=400, noise=0.9)\n\n\nX_nonlinear = torch.tensor(X_nonlinear, dtype=torch.float32)\ny_nonlinear = torch.tensor(y_nonlinear, dtype=torch.float32)\n\n\nThen I run the usual graphing code to visualize results.\n\n\nCode\nKR = KernelLogisticRegression(rbf_kernel, lam=1.0, gamma=10)\nKR.fit(X_nonlinear, y_nonlinear, m_epochs=200000, lr=0.0001)\n\nix = torch.abs(KR.a) &gt; 0.001\n\nx1 = torch.linspace(X_nonlinear[:, 0].min() - 0.2, X_nonlinear[:, 0].max() + 0.2, 101)\nx2 = torch.linspace(X_nonlinear[:, 1].min() - 0.2, X_nonlinear[:, 1].max() + 0.2, 101)\n\nX1, X2 = torch.meshgrid(x1, x2, indexing=\"ij\")\n\nx1 = X1.ravel()\nx2 = X2.ravel()\n\nX_ = torch.stack((x1, x2), dim=1)\n\npreds = KR.prediction(X_, recompute_kernel=True)\npreds = 1.0 * torch.reshape(preds, X1.size())\n\nfig, ax = plt.subplots(1, 1)\nax.contourf(\n    X1,\n    X2,\n    preds,\n    origin=\"lower\",\n    cmap=\"BrBG\",\n    vmin=2 * preds.min() - preds.max(),\n    vmax=2 * preds.max() - preds.min(),\n)\n\nax.contour(X1, X2, preds, levels=[0.5], colors='black', linewidths=2)\n\nplot_classification_data(X_nonlinear, y_nonlinear, ax)\nplt.scatter(X_nonlinear[ix, 0], X_nonlinear[ix, 1], facecolors=\"none\", edgecolors=\"black\")\nplt.title(\"Kernel Logistic Regression on Nonlinear Data\")\nplt.show()\n\n\n\n\n\n\n\n\n\nIn this experiment, the model is used to classify classify nonlinear data generated by make_moons. Initially, with a low gamma value (Œ≥ = 0.01), the model underfit the data, producing a nearly linear decision boundary that failed to capture the curved structure of the classes. By increasing gamma to 10, the kernel returned a more accurate nonlinear decision boundaries. Both separated concentrations of the blue region from the brown.s"
  },
  {
    "objectID": "posts/kernel/index.html#overfitting",
    "href": "posts/kernel/index.html#overfitting",
    "title": "Sparse Kernel Machines",
    "section": "",
    "text": "Code\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import train_test_split\n\n# Generate and split data\nX_over, y_over = classification_data(n_points=1000, noise=0.8)\nX_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.4, random_state=42)\n\n# Fit a model with high gamma (likely to overfit)\nKRO = KernelLogisticRegression(rbf_kernel, lam=1e-5, gamma=1000)\nKRO.fit(X_train, y_train, m_epochs=30000, lr=0.0001)\n\n# Predict probabilities on train and test\nwith torch.no_grad():\n    y_train_scores = KRO.prediction(X_train, recompute_kernel=True)\n    y_test_scores = KRO.prediction(X_test, recompute_kernel=True)\n\n# Convert to NumPy for sklearn\ny_train_np = y_train.numpy()\ny_test_np = y_test.numpy()\ntrain_scores_np = y_train_scores.numpy()\ntest_scores_np = y_test_scores.numpy()\n\n# Compute ROC curves\nfpr_train, tpr_train, _ = roc_curve(y_train_np, train_scores_np)\nfpr_test, tpr_test, _ = roc_curve(y_test_np, test_scores_np)\n\n# Compute AUC\nroc_auc_train = auc(fpr_train, tpr_train)\nroc_auc_test = auc(fpr_test, tpr_test)\n\n# Plot\nplt.figure(figsize=(7, 5))\nplt.plot(fpr_train, tpr_train, label=f\"Train ROC (AUC = {roc_auc_train:.2f})\")\nplt.plot(fpr_test, tpr_test, label=f\"Test ROC (AUC = {roc_auc_test:.2f})\", linestyle='--')\nplt.plot([0, 1], [0, 1], \"k--\", alpha=0.5)\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curves: Overfitting\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nIn this experiment, I simulate the problem of overfitting by training a kernel logistic regression model with extremely high gamma of 1000. This allows the model to fit the training data very closely, but it generalizes poorly to unseen test data.\nThe (AUC) score for training set was near with perfect with 0.99 but the testing set was near 0.72. This large gap between train and test AUCs is a sign that there is overfitting."
  },
  {
    "objectID": "posts/kernel/index.html#discussion",
    "href": "posts/kernel/index.html#discussion",
    "title": "Sparse Kernel Machines",
    "section": "",
    "text": "In this post, I explored the behavior of sparse kernel logistic regression with RBF kernels through several experiments:\n\nSparsity and Regularization: When using a large regularization parameter (ùúÜ = 166), only 1 out of 100 training points had a weight (Œ±) greater than 0.001, demonstrating extreme sparsity. In contrast, with a smaller ùúÜ (e.g., 0.1), a larger fraction of points acted as support vectors, contributing to the decision boundary.\nEffect of Gamma (ùõæ): By varying ùõæ from 1 to 100, I observed that the decision boundary became increasingly complex and less smooth. For example, at ùõæ = 1, the boundary was broad and circular, while at ùõæ = 100, it became highly irregular, closely fitting the training data.\nNonlinear Data: On a challenging, noisy dataset (400 points, noise = 0.9), the kernelized model with ùõæ = 10 was still able to capture the nonlinear patterns.\nOverfitting: Training with a very high ùõæ (1000) and low ùúÜ (1e-5) on a larger dataset (1000 points, noise = 0.8), the model achieved a near-perfect training AUC of 0.99, but the test AUC dropped to 0.72. This large gap quantitatively demonstrates overfitting: the model fits the training data extremely well but fails to generalize."
  },
  {
    "objectID": "posts/kernel/index.html#acknowledgements",
    "href": "posts/kernel/index.html#acknowledgements",
    "title": "Sparse Kernel Machines",
    "section": "",
    "text": "Adapted code from Professor Phil Chodrow at Middlebury College in his class CSCI 0451: Machine Learning."
  },
  {
    "objectID": "posts/pneumonia/Final_Project_BP.html",
    "href": "posts/pneumonia/Final_Project_BP.html",
    "title": "Pnuemonia Detection",
    "section": "",
    "text": "Within our blog post, we created a neural network and implemented three different binary classifers trained on chest x-ray image data to detect pneumonia based on images. We used convolution layers to convert images into latent vectors by which we could feed into our various machine learning models: a transformer, an SVM, and a gradient boosting model. Through analyzing the accuracy of each model, we discovered a similar accuracy between the models of around 78% on testing data.\nHere is the link to our code."
  },
  {
    "objectID": "posts/pneumonia/Final_Project_BP.html#abstract",
    "href": "posts/pneumonia/Final_Project_BP.html#abstract",
    "title": "Pnuemonia Detection",
    "section": "",
    "text": "Within our blog post, we created a neural network and implemented three different binary classifers trained on chest x-ray image data to detect pneumonia based on images. We used convolution layers to convert images into latent vectors by which we could feed into our various machine learning models: a transformer, an SVM, and a gradient boosting model. Through analyzing the accuracy of each model, we discovered a similar accuracy between the models of around 78% on testing data.\nHere is the link to our code."
  },
  {
    "objectID": "posts/pneumonia/Final_Project_BP.html#introduction",
    "href": "posts/pneumonia/Final_Project_BP.html#introduction",
    "title": "Pnuemonia Detection",
    "section": "Introduction",
    "text": "Introduction\nWithin our project, we wanted to compare 3 seperate binary classification machine learning models, seeing which is best for an image classification task. Our project attempts to uncover what types of algorithms are best for binary image classification tasks using the pneumonia chest xray dataset, with our models being trained to discern pneumonia based on chest xray images only. This dataset demonstrates a case where finding the most optimal image classifcation algorithm is very important as it could result in saving a life. Our research could also inform which types of algorithms should be considered other important image classification tasks. We found five studies the explored other work done by scholars\nIn the study by M. R. Rahman, Islam, and Islam (2023), the researchers mainly focus on deep learning algorithms to tackle this same image classification task. Through their research, they discovered the MobileNet CCN gave the best accuracy on two datasets with values of 94.23% and 93.75%.\nIn another study titled Rajpurkar et al. (2017), researchers create their own CNN known as CheXNet that detects pneumonia as well as other chest related illnesses (fibrosis, hernia, etc.) that which accuracies ranging from 0.7 to 0.9. With such a large focus on CNNs for this image classification, ww wanted to determine if other kinds of algorithms good for binary classifcation could also be useful image classifiers.\nRecent research has expanded the exploration of deep learning architectures for pneumonia detection. For instance, a study by Singh, Thomas, and Jaiswal (2021) compared a custom convolutional neural network (CNN) and a multilayer perceptron (MLP) for classifying chest X-ray images. The CNN achieved an accuracy of 92.63%, outperforming the MLP‚Äôs 77.56%, highlighting the efficacy of CNNs in medical image classification tasks (Singh, Thomas, and Jaiswal (2021)).\nAnother study by T. Rahman et al. (2020) employed transfer learning with various pre-trained CNN models, including AlexNet, ResNet18, DenseNet201, and SqueezeNet, to classify chest X-ray images into normal, bacterial pneumonia, and viral pneumonia categories. Their approach achieved classification accuracies of 98% for normal vs.¬†pneumonia, 95% for bacterial vs.¬†viral pneumonia, and 93.3% for normal, bacterial, and viral pneumonia, demonstrating the potential of transfer learning in enhancing diagnostic performance.\nFurthermore, a study by Mabrouk et al. (2023) proposed an ensemble learning approach combining DenseNet169, MobileNetV2, and Vision Transformer models for pneumonia detection in chest X-ray images. Their ensemble model achieved an accuracy of 93.91% and an F1-score of 93.88%, indicating that integrating multiple deep learning architectures can improve classification performance."
  },
  {
    "objectID": "posts/pneumonia/Final_Project_BP.html#values-statement",
    "href": "posts/pneumonia/Final_Project_BP.html#values-statement",
    "title": "Pnuemonia Detection",
    "section": "Values Statement",
    "text": "Values Statement\nThe potential users of our project would be primary care clinicians and radiologists who must regularly discern chest-related illnesses through X-rays. These machine learning models trained on chest X-ray image data may help them make more informed decisions if they are trying to discern specifically pneumonia.\nI believe that our work contributes to AI researchers who are studying how to optimize for performance in image classification tasks, especially regarding medical concerns. If it can inform medical researchers on what machine learning models are best at medical image classification, they and their patients can also benefit from greater accuracy in detecting chest-related illnesses.\nBecause our models are quite poor at predicting images without pneumonia correctly, they could falsely flag patients as having pneumonia, which may lead them to incur unnecessary medical expenses. Based on the background of these patients, this could seriously affect patients who struggle financially.\nOur group personally enjoyed and had an interest in each of the algorithms that we worked on and took this project as a learning experience to expand our knowledge on what image vectorization and binary classification algorithms are out there and how they differ from what we have learned through our class assignments.\nBased on our experiments, we believe if our project can help inform image classification tasks, especially those in the medical field, then the world can become a better place by being able to help people detect illnesses earlier and possibly save lives."
  },
  {
    "objectID": "posts/pneumonia/Final_Project_BP.html#materials",
    "href": "posts/pneumonia/Final_Project_BP.html#materials",
    "title": "Pnuemonia Detection",
    "section": "Materials",
    "text": "Materials\nOur data comes from the Pneumonia Chest X-ray dataset on Kaggle. This data came from the Guangzhou Women and Children‚Äôs Medical Center. Samples were collected from patients and labels were created by pneumonia specialists, with two specialists making labels and then a third corroborating the label of normal or pneumonia. Our data lacks information regarding the severity or time span of the pneumonia for positive cases, meaning that the model has no clear way of understanding which X-rays should be encoded closer or further away from the normal cases. Additionally, the dataset has a 64% / 36% split, with the majority of X-rays containing positive cases of pneumonia. This bias happens to work out well for mitigating false negatives; however, it makes models have more difficulty understanding when an X-ray is normal."
  },
  {
    "objectID": "posts/pneumonia/Final_Project_BP.html#results",
    "href": "posts/pneumonia/Final_Project_BP.html#results",
    "title": "Pnuemonia Detection",
    "section": "Results",
    "text": "Results\n \nAs demonstrated before, the models contained much higher precision rates than recall in order to catch more of the positive pneumonia cases due to their costliness as compared to the costs associated with missing a normal case. Within the models, the transformer did the best, with the highest recall and precision of 93% and 41% respectively. The F-1 score of 57% suggests that the model was beginning to learn differences between the classes but still encountered much difficulty. This is also present in the 3-D PCA plot of the latent vectors where it becomes evident that many of the embeddings are caught in an overlapping region where both classes meet. The results suggest that the image embeddings need more fine-tuning to increase accuracy and recall."
  },
  {
    "objectID": "posts/pneumonia/Final_Project_BP.html#conclusions",
    "href": "posts/pneumonia/Final_Project_BP.html#conclusions",
    "title": "Pnuemonia Detection",
    "section": "Conclusions",
    "text": "Conclusions\nThe project accomplished many of the goals that we set out to accomplish during the duration of this project and also failed to meet others. We got a working convolutional neural network to embed the images and learn important features of those images. We correctly identify 93% of all pneumonia cases. On the other hand, we correctly identify less than half of all normal cases. This project demonstrates the difficulty of complex machine learning tasks without good computational resources. Running and auditing the CNN alone takes two hours per run with a GPU. Due to this constraint, we were unable to readily take advantage of all of the data available. Additionally, the binary classification models also took 5‚Äì15 minutes depending on the model. The most apparent hurdle in this project was creating a complex model while also being able to run it in a reasonable amount of time. Other pneumonia binary classification projects are able to get higher accuracy through the usage of pre-made ResNet models. These models are trained on millions of images and use residual connections to improve the performance of neural networks. If we had more time, we would do a more thorough error analysis of misclassified normal images to understand what features the model is missing and improve the architecture to capture that feature. Additionally, we would utilize more of the training data without run-time constraints and try adopting residual neural network architecture to improve performance."
  },
  {
    "objectID": "posts/pneumonia/Final_Project_BP.html#references",
    "href": "posts/pneumonia/Final_Project_BP.html#references",
    "title": "Pnuemonia Detection",
    "section": "References",
    "text": "References\n\n\nMabrouk, Souhaib, Mohamed Ali Mahjoub, Fatma Hamdi, Slim Messaoud, and Mohamed Jmaiel. 2023. ‚ÄúEnsemble Learning Model for Pneumonia Detection in Chest x-Ray Images Using DenseNet, MobileNet and Vision Transformers.‚Äù arXiv Preprint arXiv:2312.07965. https://arxiv.org/abs/2312.07965.\n\n\nRahman, Md Raihanur, Md Rabiul Islam, and Md Hafizul Islam. 2023. ‚ÄúPneumonia Detection Using MobileNet CNN Model.‚Äù Journal of Healthcare Engineering 2023: 1‚Äì12. https://doi.org/10.1155/2023/6672181.\n\n\nRahman, Tawsifur, Ahsan Khandakar, Yazan Qiblawey, Asmaa Tahir, Serkan Kiranyaz, S. B. M. Kashem, Md. Rashidul Islam, Md. Taufiq Islam, and M. E. H. Chowdhury. 2020. ‚ÄúTransfer Learning with Deep Convolutional Neural Network (CNN) for Pneumonia Detection Using Chest x-Ray.‚Äù arXiv Preprint arXiv:2004.06578. https://arxiv.org/abs/2004.06578.\n\n\nRajpurkar, Pranav, Jeremy Irvin, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy Ding, et al. 2017. ‚ÄúCheXNet: Radiologist-Level Pneumonia Detection on Chest x-Rays with Deep Learning.‚Äù arXiv Preprint arXiv:1711.05225. https://arxiv.org/pdf/1711.05225.\n\n\nSingh, Bhupendra, Supriya Thomas, and Amandeep Jaiswal. 2021. ‚ÄúPneumonia Detection Using Deep Learning.‚Äù International Journal of Engineering Research & Technology (IJERT) 10 (7): 84‚Äì88. https://www.researchgate.net/publication/353590019_Pneumonia_Detection_using_Deep_Learning."
  },
  {
    "objectID": "posts/optimization/index.html",
    "href": "posts/optimization/index.html",
    "title": "Advanced Optimization",
    "section": "",
    "text": "In this blog post, I explore advanced optimization techniques‚ÄîNewton‚Äôs Method and the Adam optimizer‚Äîin the context of logistic regression applied to heart disease prediction. Through a series of experiments on a Kaggle heart dataset, I investigate the convergence behavior, sensitivity to learning rates, and efficiency of these methods. The three optimizers I work with are Newton‚Äôs method, Adam, and gradient descent. The goal is to understand how different optimization algorithms influence model performance and training dynamics in a binary classification tasks.\n\n\nCode\n%load_ext autoreload\n%autoreload 2\n\nfrom newton_logistic import LogisticRegression, NewtonOptimizer, GradientDescentOptimizer\nimport torch\n\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\n\n\n\n\n\nIn this experiment, I apply my Newton logistic regression model to a real-world dataset: the Kaggle heart disease prediction dataset. I preprocess the data, train the model, and evaluate its performance on training, validation, and test sets.\n\n\nCode\nimport kagglehub\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Download dataset from Kaggle\npath = kagglehub.dataset_download(\"shantanugarg274/heart-prediction-dataset-quantum\")\nprint(\"Path to dataset files:\", path)\n\ndata_path = path + \"/Heart Prediction Quantum Dataset.csv\"\ndf = pd.read_csv(data_path)\n# print(df.head())\n\n\nWarning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.8), please consider upgrading to the latest version (0.3.12).\nPath to dataset files: /Users/emmanueltowner/.cache/kagglehub/datasets/shantanugarg274/heart-prediction-dataset-quantum/versions/1\n\n\nThe data was in 1 csv file with 7 columns representing age, gender, blood pressure, cholesterol, heart rate, quantum pattern feature, and heart disease.\n\n\nCode\nX_data = df.drop(\"HeartDisease\", axis=1).values\ny_data = df[\"HeartDisease\"].values\n\n\nSince I intend to predict heart disease, I removed that column from the main dataset and used it in the target set.\n\n\nCode\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nX_data = scaler.fit_transform(X_data)\nX_data = torch.tensor(X_data, dtype=torch.float32)\ny_data = torch.tensor(y_data, dtype=torch.float32)\n\n\nThe data across features widely varied in range and so I used sci-kit learn‚Äôs StandardScaler to standardize the both datasets and then converted them into tensors. The model was trained on the training set and the loss computed for both training and validation.\n\n\nCode\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.4, random_state=42)\n\n\nI also used train_test_split to split the 60% data into training and 40% in test sets.\n\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\n\nLR = LogisticRegression() \nopt = NewtonOptimizer(LR)\n\nloss_train = []\nloss_test = []\n\niterations = 100\nalpha = 0.1\n\n\nfor _ in range(iterations):\n    train_loss = LR.loss(X_train, y_train)\n    loss_train.append(train_loss.item())\n    \n    test_loss = LR.loss(X_test, y_test)\n    loss_test.append(test_loss.item())\n    \n    opt.step(X_train, y_train, alpha)\n\n    \n# Plotting the loss\nfig, ax = plt.subplots(figsize=(6, 6))  # Single axes, adjust figsize if needed\nax.plot(torch.arange(1, iterations + 1), loss_train, color=\"black\")\nax.plot(torch.arange(1, iterations + 1), loss_test, color=\"orange\")\nax.set_xlabel(\"Iterations\")\nax.set_ylabel(\"Loss\")\nax.set_title(\"Loss vs Iterations\")\nax.legend([\"Train Loss\", \"Test Loss\"])\nplt.show()\n\n\n\n\n\n\n\n\n\nWith an alpha of 0.1 both training and testing loss converge in between 20 and 40 iterations. Testing loss converges slightly earlier and at a slightly higher loss than training loss.\n\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\n\nLR = LogisticRegression() \noptn = NewtonOptimizer(LR)\n\nn_loss_train = []\nn_loss_test = []\n\niterations = 100\nalpha = 0.1\n\n\nfor _ in range(iterations):\n    train_loss = LR.loss(X_train, y_train)\n    n_loss_train.append(train_loss.item())\n\n    test_loss = LR.loss(X_test, y_test)\n    n_loss_test.append(test_loss.item())\n    \n    optn.step(X_train, y_train, alpha)\n\nLR = LogisticRegression() \noptg = GradientDescentOptimizer(LR)\n\ng_loss_train = []\ng_loss_test = []\n\niterations = 100\nalpha = 0.1\n\n\nfor _ in range(iterations):\n    train_loss = LR.loss(X_train, y_train)\n    g_loss_train.append(train_loss.item())\n\n    test_loss = LR.loss(X_test, y_test)\n    g_loss_test.append(test_loss.item())\n\n    optg.step(X_train, y_train, alpha, beta=0.9)\n\n# Plotting the loss\nfig, ax = plt.subplots(1, 2, figsize=(12, 6))  # Single axes, adjust figsize if needed\nax[0].plot(torch.arange(1, iterations + 1), n_loss_train, color=\"black\")\nax[0].plot(torch.arange(1, iterations + 1), n_loss_test, color=\"orange\")\nax[0].set_xlabel(\"Iterations\")\nax[0].set_ylabel(\"Loss\")\nax[0].set_title(\"Newton Optimizer Loss\")\nax[0].legend([\"Train Loss\", \"Test Loss\"])\n\nax[1].plot(torch.arange(1, iterations + 1), g_loss_train, color=\"black\")\nax[1].plot(torch.arange(1, iterations + 1), g_loss_test, color=\"orange\")\nax[1].set_xlabel(\"Iterations\")\nax[1].set_ylabel(\"Loss\")\nax[1].set_title(\"Gradient Descent Loss\")\nax[1].legend([\"Train Loss\", \"Test Loss\"])\nplt.show()\n\n\n\n\n\n\n\n\n\nIn this plot, we see that with the Newton Optimizer the loss convergences faster than the gradient descent optimizer. For Newton optimizer, the loss reaches convergence at ~30-35 iterations whereas for the gradient optimizer the loss converges at ~50-60. They both share an alpha of 0.1 while gradient descent has a beta of 0.9.\n\n\n\n\n\nCode\nLR = LogisticRegression() \nopts = NewtonOptimizer(LR)\n\nloss_train = []\nloss_test = []\n\niterations = 100\nalpha = 1.3\n\n\nfor _ in range(iterations):\n    train_loss = LR.loss(X_train, y_train)\n    loss_train.append(train_loss.item())\n    \n    test_loss = LR.loss(X_test, y_test)\n    loss_test.append(test_loss.item())\n    \n    # print(\"Train Loss: \", train_loss.item())\n    opts.step(X_train, y_train, alpha)\n\n    \n# Plotting the loss\nfig, ax = plt.subplots(figsize=(6, 6))  \nax.plot(torch.arange(1, iterations + 1), loss_train, color=\"black\")\nax.plot(torch.arange(1, iterations + 1), loss_test, color=\"orange\")\nax.set_xlabel(\"Iterations\")\nax.set_ylabel(\"Loss\")\nax.set_title(\"Loss vs Iterations\")\nax.legend([\"Train Loss\", \"Test Loss\"])\nplt.show()\n\n\n\n\n\n\n\n\n\nThis model converges for all alpha‚Äôs from up to 1. The original hessian simply returned an error when alpha went above, now with regularization the loss doesn‚Äôt always commpute and returns a broken graph.\n\n\n\n\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\nfrom adam import AdamOptimizer\n\n# Adam optimizer test\n\n\niterations = 100\nbatch_size = 40\n\nalphas = [0.001, 0.01, 0.03, 0.1]\nadam_losses_dict = {}\nfor alpha in alphas:\n    LRA = LogisticRegression()\n    adam = AdamOptimizer(LRA)\n    adam_losses = []\n    for _ in range(iterations):\n        train_loss = LRA.loss(X_train, y_train)\n        adam_losses.append(train_loss.item())\n        adam.optim(X_train, y_train, batch_size=batch_size, alpha=alpha)\n    adam_losses_dict[alpha] = adam_losses\n\n\n# SGD (minibatch) test for different step sizes\n\ngrad_losses_dict = {}\n\nfor alpha in alphas:\n    LRG = LogisticRegression()\n    grad = GradientDescentOptimizer(LRG)\n    grad_losses = []\n    for _ in range(iterations):\n        train_loss = LRG.loss(X_train, y_train)\n        grad_losses.append(train_loss.item())\n        grad.step(X_train, y_train, alpha=alpha, beta=0.0, mini_batch=True)\n    grad_losses_dict[alpha] = grad_losses\n    \n# Plotting the loss\nfig, ax = plt.subplots(1, 2, figsize=(12, 6))  \nfor alpha, losses in adam_losses_dict.items():\n    ax[0].plot(torch.arange(1, iterations + 1), losses, label=f\"Adam (Œ±={alpha})\")\nax[0].set_xlabel(\"Iterations\")\nax[0].set_ylabel(\"Loss\")\nax[0].set_title(\"Adam Optimizer Loss\")\nax[0].legend()\n\nfor alpha, losses in grad_losses_dict.items():\n    ax[1].plot(torch.arange(1, iterations + 1), losses, label=f\"Grad (Œ±={alpha})\")\nax[1].set_xlabel(\"Iterations\")\nax[1].set_ylabel(\"Loss\")\nax[1].set_title(\"Gradient Descent Loss\")\nax[1].legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nThis test compares the performance of the Adam optimizer and mini-batch gradient descent on logistic regression. For each optimizer, the code tests four learning rates (Œ± = 0.001, 0.01, 0.03, 0.1) over 100 iterations, recording the training loss at each step. Adam uses a batch size of 40, while SGD uses mini-batches with no momentum. The results show that Adam consistently shows faster and smoother convergence across all learning rates compared to SGD, which converges more slowly and is more sensitive to the choice of Œ±. This demonstrates Adam‚Äôs advantage in stability and speed for this classification task. Both struggle to converge on low alphas such as 0.01.\n\n\n\n\n\nCode\n\nimport time\n\ntarget_loss = 0.3\nalpha = 0.03\n\n\n# Adam optimizer\nLRA = LogisticRegression() \nadam = AdamOptimizer(LRA)\n\nadam_loss = float('inf')  # large initial value\n\nstart = time.perf_counter()\n\nwhile adam_loss &gt; target_loss:\n    # Compute current loss\n    train_loss = LRA.loss(X_train, y_train)\n    adam_loss = train_loss.item()\n    # print(f\"[Adam] Current loss: {adam_loss:.4f}\")\n    \n    # Perform one round of updates\n    adam.optim(X_train, y_train, batch_size=40, alpha=alpha)\n\nend = time.perf_counter()\nprint(f\"Adam optimizer took {end - start:.4f} seconds\")\nprint(f\"Final Adam loss: {LRA.loss(X_train, y_train).item():.4f}\")\n\n# Newton Optimizer\nLRN = LogisticRegression()\nnewton = NewtonOptimizer(LRN)\n\nnewton_loss = float('inf')  # large initial value\n\nstart = time.perf_counter()\n\nwhile newton_loss &gt; target_loss:\n    # Compute current loss\n    train_loss = LRN.loss(X_train, y_train)\n    newton_loss = train_loss.item()\n    # print(f\"[Newton] Current loss: {newton_loss:.4f}\")\n    # Perform one round of updates\n    newton.step(X_train, y_train, alpha)\n\nend = time.perf_counter()\nprint(f\"Newton optimizer took {end - start:.4f} seconds\")\nprint(f\"Final Newton loss: {LRN.loss(X_train, y_train).item():.4f}\")\n\n\n\n\n\nAdam optimizer took 0.1112 seconds\nFinal Adam loss: 0.2380\nNewton optimizer took 0.0081 seconds\nFinal Newton loss: 0.2965\n\n\nIn the above code, the model was trained using Adam and Newton optimizer with the goal of reducing the training loss below a target value of 0.3. Both optimizers iteratively updated the model parameters, with Adam using adaptive learning rates and mini-batches, while Gradient Descent used momentum and mini-batch updates. The results showed that Adam achieved a lower final loss (0.2379) but took longer to converge (0.1134 seconds), whereas Gradient Descent was significantly faster (0.0062 seconds) but only marginally met the loss target (0.2989).\n\n\n\n\nThe experiments show that different optimizers can perform better in different situations. Newton‚Äôs Method achieved faster convergence than standard gradient descent in terms of iteration count but when alpha became really large it was unable to converge. Gradient descent methods, while slower, offer greater stability across a wider range of learning rates. Adam strikes a balance, providing both great loss rate and rapid convergence. It was faster the mini-batch gradient descent but slower than Newton. In both situations, it had the better loss. \n\n\n\nAdapted code from Professor Phil Chodrow at Middlebury College in his class CSCI 0451: Machine Learning."
  },
  {
    "objectID": "posts/optimization/index.html#abstract",
    "href": "posts/optimization/index.html#abstract",
    "title": "Advanced Optimization",
    "section": "",
    "text": "In this blog post, I explore advanced optimization techniques‚ÄîNewton‚Äôs Method and the Adam optimizer‚Äîin the context of logistic regression applied to heart disease prediction. Through a series of experiments on a Kaggle heart dataset, I investigate the convergence behavior, sensitivity to learning rates, and efficiency of these methods. The three optimizers I work with are Newton‚Äôs method, Adam, and gradient descent. The goal is to understand how different optimization algorithms influence model performance and training dynamics in a binary classification tasks.\n\n\nCode\n%load_ext autoreload\n%autoreload 2\n\nfrom newton_logistic import LogisticRegression, NewtonOptimizer, GradientDescentOptimizer\nimport torch\n\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload"
  },
  {
    "objectID": "posts/optimization/index.html#newton-experiments",
    "href": "posts/optimization/index.html#newton-experiments",
    "title": "Advanced Optimization",
    "section": "",
    "text": "In this experiment, I apply my Newton logistic regression model to a real-world dataset: the Kaggle heart disease prediction dataset. I preprocess the data, train the model, and evaluate its performance on training, validation, and test sets.\n\n\nCode\nimport kagglehub\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Download dataset from Kaggle\npath = kagglehub.dataset_download(\"shantanugarg274/heart-prediction-dataset-quantum\")\nprint(\"Path to dataset files:\", path)\n\ndata_path = path + \"/Heart Prediction Quantum Dataset.csv\"\ndf = pd.read_csv(data_path)\n# print(df.head())\n\n\nWarning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.8), please consider upgrading to the latest version (0.3.12).\nPath to dataset files: /Users/emmanueltowner/.cache/kagglehub/datasets/shantanugarg274/heart-prediction-dataset-quantum/versions/1\n\n\nThe data was in 1 csv file with 7 columns representing age, gender, blood pressure, cholesterol, heart rate, quantum pattern feature, and heart disease.\n\n\nCode\nX_data = df.drop(\"HeartDisease\", axis=1).values\ny_data = df[\"HeartDisease\"].values\n\n\nSince I intend to predict heart disease, I removed that column from the main dataset and used it in the target set.\n\n\nCode\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nX_data = scaler.fit_transform(X_data)\nX_data = torch.tensor(X_data, dtype=torch.float32)\ny_data = torch.tensor(y_data, dtype=torch.float32)\n\n\nThe data across features widely varied in range and so I used sci-kit learn‚Äôs StandardScaler to standardize the both datasets and then converted them into tensors. The model was trained on the training set and the loss computed for both training and validation.\n\n\nCode\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.4, random_state=42)\n\n\nI also used train_test_split to split the 60% data into training and 40% in test sets.\n\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\n\nLR = LogisticRegression() \nopt = NewtonOptimizer(LR)\n\nloss_train = []\nloss_test = []\n\niterations = 100\nalpha = 0.1\n\n\nfor _ in range(iterations):\n    train_loss = LR.loss(X_train, y_train)\n    loss_train.append(train_loss.item())\n    \n    test_loss = LR.loss(X_test, y_test)\n    loss_test.append(test_loss.item())\n    \n    opt.step(X_train, y_train, alpha)\n\n    \n# Plotting the loss\nfig, ax = plt.subplots(figsize=(6, 6))  # Single axes, adjust figsize if needed\nax.plot(torch.arange(1, iterations + 1), loss_train, color=\"black\")\nax.plot(torch.arange(1, iterations + 1), loss_test, color=\"orange\")\nax.set_xlabel(\"Iterations\")\nax.set_ylabel(\"Loss\")\nax.set_title(\"Loss vs Iterations\")\nax.legend([\"Train Loss\", \"Test Loss\"])\nplt.show()\n\n\n\n\n\n\n\n\n\nWith an alpha of 0.1 both training and testing loss converge in between 20 and 40 iterations. Testing loss converges slightly earlier and at a slightly higher loss than training loss.\n\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\n\nLR = LogisticRegression() \noptn = NewtonOptimizer(LR)\n\nn_loss_train = []\nn_loss_test = []\n\niterations = 100\nalpha = 0.1\n\n\nfor _ in range(iterations):\n    train_loss = LR.loss(X_train, y_train)\n    n_loss_train.append(train_loss.item())\n\n    test_loss = LR.loss(X_test, y_test)\n    n_loss_test.append(test_loss.item())\n    \n    optn.step(X_train, y_train, alpha)\n\nLR = LogisticRegression() \noptg = GradientDescentOptimizer(LR)\n\ng_loss_train = []\ng_loss_test = []\n\niterations = 100\nalpha = 0.1\n\n\nfor _ in range(iterations):\n    train_loss = LR.loss(X_train, y_train)\n    g_loss_train.append(train_loss.item())\n\n    test_loss = LR.loss(X_test, y_test)\n    g_loss_test.append(test_loss.item())\n\n    optg.step(X_train, y_train, alpha, beta=0.9)\n\n# Plotting the loss\nfig, ax = plt.subplots(1, 2, figsize=(12, 6))  # Single axes, adjust figsize if needed\nax[0].plot(torch.arange(1, iterations + 1), n_loss_train, color=\"black\")\nax[0].plot(torch.arange(1, iterations + 1), n_loss_test, color=\"orange\")\nax[0].set_xlabel(\"Iterations\")\nax[0].set_ylabel(\"Loss\")\nax[0].set_title(\"Newton Optimizer Loss\")\nax[0].legend([\"Train Loss\", \"Test Loss\"])\n\nax[1].plot(torch.arange(1, iterations + 1), g_loss_train, color=\"black\")\nax[1].plot(torch.arange(1, iterations + 1), g_loss_test, color=\"orange\")\nax[1].set_xlabel(\"Iterations\")\nax[1].set_ylabel(\"Loss\")\nax[1].set_title(\"Gradient Descent Loss\")\nax[1].legend([\"Train Loss\", \"Test Loss\"])\nplt.show()\n\n\n\n\n\n\n\n\n\nIn this plot, we see that with the Newton Optimizer the loss convergences faster than the gradient descent optimizer. For Newton optimizer, the loss reaches convergence at ~30-35 iterations whereas for the gradient optimizer the loss converges at ~50-60. They both share an alpha of 0.1 while gradient descent has a beta of 0.9.\n\n\n\n\n\nCode\nLR = LogisticRegression() \nopts = NewtonOptimizer(LR)\n\nloss_train = []\nloss_test = []\n\niterations = 100\nalpha = 1.3\n\n\nfor _ in range(iterations):\n    train_loss = LR.loss(X_train, y_train)\n    loss_train.append(train_loss.item())\n    \n    test_loss = LR.loss(X_test, y_test)\n    loss_test.append(test_loss.item())\n    \n    # print(\"Train Loss: \", train_loss.item())\n    opts.step(X_train, y_train, alpha)\n\n    \n# Plotting the loss\nfig, ax = plt.subplots(figsize=(6, 6))  \nax.plot(torch.arange(1, iterations + 1), loss_train, color=\"black\")\nax.plot(torch.arange(1, iterations + 1), loss_test, color=\"orange\")\nax.set_xlabel(\"Iterations\")\nax.set_ylabel(\"Loss\")\nax.set_title(\"Loss vs Iterations\")\nax.legend([\"Train Loss\", \"Test Loss\"])\nplt.show()\n\n\n\n\n\n\n\n\n\nThis model converges for all alpha‚Äôs from up to 1. The original hessian simply returned an error when alpha went above, now with regularization the loss doesn‚Äôt always commpute and returns a broken graph."
  },
  {
    "objectID": "posts/optimization/index.html#adam-optimizer",
    "href": "posts/optimization/index.html#adam-optimizer",
    "title": "Advanced Optimization",
    "section": "",
    "text": "Code\nimport matplotlib.pyplot as plt\nfrom adam import AdamOptimizer\n\n# Adam optimizer test\n\n\niterations = 100\nbatch_size = 40\n\nalphas = [0.001, 0.01, 0.03, 0.1]\nadam_losses_dict = {}\nfor alpha in alphas:\n    LRA = LogisticRegression()\n    adam = AdamOptimizer(LRA)\n    adam_losses = []\n    for _ in range(iterations):\n        train_loss = LRA.loss(X_train, y_train)\n        adam_losses.append(train_loss.item())\n        adam.optim(X_train, y_train, batch_size=batch_size, alpha=alpha)\n    adam_losses_dict[alpha] = adam_losses\n\n\n# SGD (minibatch) test for different step sizes\n\ngrad_losses_dict = {}\n\nfor alpha in alphas:\n    LRG = LogisticRegression()\n    grad = GradientDescentOptimizer(LRG)\n    grad_losses = []\n    for _ in range(iterations):\n        train_loss = LRG.loss(X_train, y_train)\n        grad_losses.append(train_loss.item())\n        grad.step(X_train, y_train, alpha=alpha, beta=0.0, mini_batch=True)\n    grad_losses_dict[alpha] = grad_losses\n    \n# Plotting the loss\nfig, ax = plt.subplots(1, 2, figsize=(12, 6))  \nfor alpha, losses in adam_losses_dict.items():\n    ax[0].plot(torch.arange(1, iterations + 1), losses, label=f\"Adam (Œ±={alpha})\")\nax[0].set_xlabel(\"Iterations\")\nax[0].set_ylabel(\"Loss\")\nax[0].set_title(\"Adam Optimizer Loss\")\nax[0].legend()\n\nfor alpha, losses in grad_losses_dict.items():\n    ax[1].plot(torch.arange(1, iterations + 1), losses, label=f\"Grad (Œ±={alpha})\")\nax[1].set_xlabel(\"Iterations\")\nax[1].set_ylabel(\"Loss\")\nax[1].set_title(\"Gradient Descent Loss\")\nax[1].legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nThis test compares the performance of the Adam optimizer and mini-batch gradient descent on logistic regression. For each optimizer, the code tests four learning rates (Œ± = 0.001, 0.01, 0.03, 0.1) over 100 iterations, recording the training loss at each step. Adam uses a batch size of 40, while SGD uses mini-batches with no momentum. The results show that Adam consistently shows faster and smoother convergence across all learning rates compared to SGD, which converges more slowly and is more sensitive to the choice of Œ±. This demonstrates Adam‚Äôs advantage in stability and speed for this classification task. Both struggle to converge on low alphas such as 0.01.\n\n\n\n\n\nCode\n\nimport time\n\ntarget_loss = 0.3\nalpha = 0.03\n\n\n# Adam optimizer\nLRA = LogisticRegression() \nadam = AdamOptimizer(LRA)\n\nadam_loss = float('inf')  # large initial value\n\nstart = time.perf_counter()\n\nwhile adam_loss &gt; target_loss:\n    # Compute current loss\n    train_loss = LRA.loss(X_train, y_train)\n    adam_loss = train_loss.item()\n    # print(f\"[Adam] Current loss: {adam_loss:.4f}\")\n    \n    # Perform one round of updates\n    adam.optim(X_train, y_train, batch_size=40, alpha=alpha)\n\nend = time.perf_counter()\nprint(f\"Adam optimizer took {end - start:.4f} seconds\")\nprint(f\"Final Adam loss: {LRA.loss(X_train, y_train).item():.4f}\")\n\n# Newton Optimizer\nLRN = LogisticRegression()\nnewton = NewtonOptimizer(LRN)\n\nnewton_loss = float('inf')  # large initial value\n\nstart = time.perf_counter()\n\nwhile newton_loss &gt; target_loss:\n    # Compute current loss\n    train_loss = LRN.loss(X_train, y_train)\n    newton_loss = train_loss.item()\n    # print(f\"[Newton] Current loss: {newton_loss:.4f}\")\n    # Perform one round of updates\n    newton.step(X_train, y_train, alpha)\n\nend = time.perf_counter()\nprint(f\"Newton optimizer took {end - start:.4f} seconds\")\nprint(f\"Final Newton loss: {LRN.loss(X_train, y_train).item():.4f}\")\n\n\n\n\n\nAdam optimizer took 0.1112 seconds\nFinal Adam loss: 0.2380\nNewton optimizer took 0.0081 seconds\nFinal Newton loss: 0.2965\n\n\nIn the above code, the model was trained using Adam and Newton optimizer with the goal of reducing the training loss below a target value of 0.3. Both optimizers iteratively updated the model parameters, with Adam using adaptive learning rates and mini-batches, while Gradient Descent used momentum and mini-batch updates. The results showed that Adam achieved a lower final loss (0.2379) but took longer to converge (0.1134 seconds), whereas Gradient Descent was significantly faster (0.0062 seconds) but only marginally met the loss target (0.2989)."
  },
  {
    "objectID": "posts/optimization/index.html#discussion",
    "href": "posts/optimization/index.html#discussion",
    "title": "Advanced Optimization",
    "section": "",
    "text": "The experiments show that different optimizers can perform better in different situations. Newton‚Äôs Method achieved faster convergence than standard gradient descent in terms of iteration count but when alpha became really large it was unable to converge. Gradient descent methods, while slower, offer greater stability across a wider range of learning rates. Adam strikes a balance, providing both great loss rate and rapid convergence. It was faster the mini-batch gradient descent but slower than Newton. In both situations, it had the better loss."
  },
  {
    "objectID": "posts/optimization/index.html#acknowledgements",
    "href": "posts/optimization/index.html#acknowledgements",
    "title": "Advanced Optimization",
    "section": "",
    "text": "Adapted code from Professor Phil Chodrow at Middlebury College in his class CSCI 0451: Machine Learning."
  },
  {
    "objectID": "posts/logistic/index.html",
    "href": "posts/logistic/index.html",
    "title": "Implementing Logistic Regression",
    "section": "",
    "text": "This notebook implements a logistic regression model with a gradient descent optimizer. The model is trained on a synthetic dataset, and in where it is optimized at each iteration and also updates loss. There are four experiments conducted. The first experiment tested the model on with vanilla gradient descent plotting the loss per iteration and a decision boundary. The second experiment compared the loss per iterations between the model when using the vanilla descent and when using momentum descent. The third experiment was to overfit the model to the training data and compare it to the accuracy of the model on the test data. The fourth experiment was to test the model on a heart disease prediction dateset. The dataset was split into training, validation, and test data. The model was trained on the training data and the loss computed for both training and validation. The model was then evaluated on the test data, and the accuracy was reported.\n\n\nCode\n%load_ext autoreload\n%autoreload 2\n\nfrom logistic import LogisticRegression, GradientDescentOptimizer\nimport torch\n\nimport numpy as np\n\ndef classification_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    y = 1.0*y\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n    \n    return X, y\n\nX, y = classification_data(noise = 0.5)\n\n\n\n\nCode\nThe previous cell defines a function `classification_data` that generates synthetic classification data using PyTorch. It creates a dataset with a specified number of points, noise level, and feature dimensions. The function returns feature matrix `X` and label vector `y`. The cell then generates a dataset with added noise and stores the results in `X` and `y`.\n\n\n\n\n\n\n\nIn this experiment, I train a logistic regression model using vanilla gradient descent on synthetic data. I monitor the loss over iterations and visualize the decision boundary to evaluate how well the model learns to classify the data.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\nloss_vec = []\n\nfor _ in range(10000):\n    loss = LR.loss(X, y) \n    loss_vec.append(loss)\n     \n    opt.step(X, y, alpha = 0.1, beta = 0)\n\n  \nplt.plot(torch.arange(1, len(loss_vec)+1), loss_vec, color = \"black\")\nplt.semilogx()\nlabs = plt.gca().set(xlabel = \"Number of gradient descent iterations\", ylabel = \"Loss (binary cross entropy)\")\n\n\n\n\n\n\n\n\n\nThe code above implements a vanilla gradient descent with logistic regression. It is run through a training loop, while keeping track of the loss and storing it in an array called loss_vec. Using loss_vec, I plot a graph showing the loss over gradient iterations. The second graph shows the decision boundary of the data. - Loss: This appears to hit convergence with a loss &lt;0.2 at ~10,000 iterations. - Decision Boundary: The decision boundary appears to correctly classify the data.\n\n\n\nHere, I compare vanilla gradient descent with gradient descent using momentum. By plotting the loss over iterations for both methods, I demonstrate how momentum can accelerate convergence when training logistic regression.\n\n\nCode\nX, y = classification_data(n_points=700, noise = 0.1)\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\nimport torch\n\n# Vanilla gradient descent\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\nloss_vec1 = []\niterations = 5000\nalpha = 0.1\nfor _ in range(iterations):\n    loss = LR.loss(X, y)\n    loss_vec1.append(loss)\n    opt.step(X, y, alpha, beta=0.0)  \n\n# Momentum version\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\nloss_vec2 = []\nfor _ in range(iterations):\n    loss = LR.loss(X, y)\n    loss_vec2.append(loss)\n    opt.step(X, y, alpha, beta=0.9) \n\n\nplt.plot(torch.arange(1, len(loss_vec1) + 1), loss_vec1, color=\"black\", label=f\"alpha={alpha}, beta=0.0\")\nplt.plot(torch.arange(1, len(loss_vec2) + 1), loss_vec2, color=\"orange\", label=f\"alpha={alpha}, beta=0.9\")\nplt.semilogx()\nplt.xlabel(\"Number of gradient descent iterations\")\nplt.ylabel(\"Loss (binary cross entropy)\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nThe code above plots the loss over iterations for both vanilla gradient descent and momentum gradient descent (beta = 0.9) over 5000 iterations with an alpha of 0.1. The loss of both descents begin at ~0.64, but momentum gradient descent drops lower a lot qucker and reaches convergence at ~1000 iterations. Vanilla gradient descent takes ~5000 iterations to reach convergence.\n\n\n\nThis experiment investigates overfitting by training a logistic regression model on high-dimensional data (more features than samples). I compare the model‚Äôs accuracy on the training and test sets to highlight the effects of overfitting.\n\n\nCode\n# Generate training and test data\nX_train, y_train = classification_data(n_points= 60, noise = 0.3, p_dims = 100)\nX_test, y_test = classification_data(n_points= 60, noise = 0.3, p_dims = 100)\n\n\n\n\nCode\n# Initialize the logistic regression model and optimizer\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\n# Train the model using momentum\nfor _ in range(200): \n    opt.step(X_train, y_train, alpha = 0.01, beta = 0.9)\n\n\n\n\nCode\n# Calculate training accuracy\ntrain_predictions = LR.predict(X_train)\ntrain_accuracy = (train_predictions == y_train).float().mean().item()\nprint(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n\n# Calculate testing accuracy\ntest_predictions = LR.predict(X_test)\ntest_accuracy = (test_predictions == y_test).float().mean().item()\nprint(f\"Testing Accuracy: {test_accuracy * 100:.2f}%\")\n\n\nTraining Accuracy: 100.00%\nTesting Accuracy: 93.33%\n\n\nThis experiments creates equal data for train and test set with 60 points, 100 dimensions and a noise of 0.3. The model(alpha = 0.01, beta = 0.9) is trained on the training set for 200 iterations,leading to overfitting and a training accuracy of a 100%. The accuracy of the model on the test set is 96.67%, which is rather good given the model was overfitted.\n\n\n\nIn this experiment, I apply my logistic regression model to a real-world dataset: the Kaggle heart disease prediction dataset. I preprocess the data, train the model, and evaluate its performance on training, validation, and test sets.\n\n\nCode\nimport kagglehub\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Download dataset from Kaggle\npath = kagglehub.dataset_download(\"shantanugarg274/heart-prediction-dataset-quantum\")\nprint(\"Path to dataset files:\", path)\n\ndata_path = path + \"/Heart Prediction Quantum Dataset.csv\"\ndf = pd.read_csv(data_path)\n\n\nWarning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.8), please consider upgrading to the latest version (0.3.12).\nPath to dataset files: /Users/emmanueltowner/.cache/kagglehub/datasets/shantanugarg274/heart-prediction-dataset-quantum/versions/1\n\n\nThe data was in 1 csv file with 7 columns representing age, gender, blood pressure, cholesterol, heart rate, quantum pattern feature, and heart disease.\n\n\nCode\nX_data = df.drop(\"HeartDisease\", axis=1).values\ny_data = df[\"HeartDisease\"].values\n\n\nSince I intend to predict heart disease, I removed that column from the main dataset and used it in the target set.\n\n\nCode\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nX_data = scaler.fit_transform(X_data)\nX_data = torch.tensor(X_data, dtype=torch.float32)\ny_data = torch.tensor(y_data, dtype=torch.float32)\n\n\nThe data across features widely varied in range and so I used sci-kit learn‚Äôs StandardScaler to standardize the both datasets and then converted them into tensors. The model was trained on the training set and the loss computed for both training and validation.\n\n\nCode\nX_train, X_temp, y_train, y_temp = train_test_split(X_data, y_data, test_size=0.4, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n\n\nI also used train_test_split to split the 60% data into training, 20% in validation, and test sets. I had to do this in 2 steps since the you cannot split the data into 3 sets at once.\n\n\nCode\nimport matplotlib.pyplot as plt\nimport torch\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 6))\n\n# Vanilla gradient descent\nLRV = LogisticRegression() \noptv = GradientDescentOptimizer(LRV)\n\nv_loss_train = []\nv_loss_val = []\n\niterations = 100\nalpha = 0.01\nfor _ in range(iterations):\n    train_loss = LRV.loss(X_train, y_train)\n    val_loss = LRV.loss(X_val, y_val)\n    v_loss_train.append(train_loss.item())\n    v_loss_val.append(val_loss.item())\n    optv.step(X_train, y_train, alpha, beta=0.0) \n\n# Momentum version\nLRM = LogisticRegression() \noptm = GradientDescentOptimizer(LRM)\n\nm_loss_train = []\nm_loss_val = []\nfor _ in range(iterations):\n    train_loss = LRM.loss(X_train, y_train)\n    val_loss = LRM.loss(X_val, y_val)\n    m_loss_train.append(train_loss.item())\n    m_loss_val.append(val_loss.item())\n    optm.step(X_train, y_train, alpha, beta=0.9)  \n\nax[0].plot(torch.arange(1, iterations + 1), v_loss_train, color=\"black\", label=\"Vanilla\")\nax[0].plot(torch.arange(1, iterations + 1), m_loss_train, color=\"orange\", label=\"Momentum\")\nax[0].set_xlabel(\"Iterations\")\nax[0].set_ylabel(\"Training Loss\")\nax[0].legend()\nax[0].set_title(\"Training Loss\")\n\nax[1].plot(torch.arange(1, iterations + 1), v_loss_val, color=\"black\", label=\"Vanilla\")\nax[1].plot(torch.arange(1, iterations + 1), m_loss_val, color=\"orange\", label=\"Momentum\")\nax[1].set_xlabel(\"Iterations\")\nax[1].set_ylabel(\"Validation Loss\")\nax[1].legend()\nax[1].set_title(\"Validation Loss\")\n\n\nText(0.5, 1.0, 'Validation Loss')\n\n\n\n\n\n\n\n\n\nThe 2 graphs above show the loss over iterations for both training and validation. The model was trained for 100 iterations with an alpha of 0.01 and mommentum beta of 0.9. The graphs were similar to each other and the only the momentum loss(~0.2 for training and ~0.3 for validation) reached convergence at the end.\n\n\nCode\ntest_loss = LRM.loss(X_test, y_test)\nprint(f\"Testing Loss: {test_loss.item():.4f}\")\n\n# Testing Accuracy\ntest_predictions = LRM.predict(X_test)\ntest_accuracy = (test_predictions == y_test).float().mean().item()\nprint(f\"Testing Accuracy: {test_accuracy * 100:.2f}%\")\n\n\nTesting Loss: 0.3732\nTesting Accuracy: 83.00%\n\n\nMy model had a loss of 0.38 and accuracy of 83% on the test set. While the accuracy is was decent, the loss was a bit high.\n\n\n\n\nIn this blog post, I implemented a logistic regression model with a momentum based optimizer. It successfully achieved convergence with vanilla gradient(beta = 0), then proved the with momentum it could increase speedup. The model was able to overfit the training data and achieve a high accuracy on the test set. The model was also able to learn the heart disease dataset, reach convergence, and achieve a good accuracy. The loss was a bit high, but maybe with more iterations it could be improved."
  },
  {
    "objectID": "posts/logistic/index.html#abstract",
    "href": "posts/logistic/index.html#abstract",
    "title": "Implementing Logistic Regression",
    "section": "",
    "text": "This notebook implements a logistic regression model with a gradient descent optimizer. The model is trained on a synthetic dataset, and in where it is optimized at each iteration and also updates loss. There are four experiments conducted. The first experiment tested the model on with vanilla gradient descent plotting the loss per iteration and a decision boundary. The second experiment compared the loss per iterations between the model when using the vanilla descent and when using momentum descent. The third experiment was to overfit the model to the training data and compare it to the accuracy of the model on the test data. The fourth experiment was to test the model on a heart disease prediction dateset. The dataset was split into training, validation, and test data. The model was trained on the training data and the loss computed for both training and validation. The model was then evaluated on the test data, and the accuracy was reported.\n\n\nCode\n%load_ext autoreload\n%autoreload 2\n\nfrom logistic import LogisticRegression, GradientDescentOptimizer\nimport torch\n\nimport numpy as np\n\ndef classification_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    y = 1.0*y\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n    \n    return X, y\n\nX, y = classification_data(noise = 0.5)\n\n\n\n\nCode\nThe previous cell defines a function `classification_data` that generates synthetic classification data using PyTorch. It creates a dataset with a specified number of points, noise level, and feature dimensions. The function returns feature matrix `X` and label vector `y`. The cell then generates a dataset with added noise and stores the results in `X` and `y`."
  },
  {
    "objectID": "posts/logistic/index.html#experiments",
    "href": "posts/logistic/index.html#experiments",
    "title": "Implementing Logistic Regression",
    "section": "",
    "text": "In this experiment, I train a logistic regression model using vanilla gradient descent on synthetic data. I monitor the loss over iterations and visualize the decision boundary to evaluate how well the model learns to classify the data.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\nloss_vec = []\n\nfor _ in range(10000):\n    loss = LR.loss(X, y) \n    loss_vec.append(loss)\n     \n    opt.step(X, y, alpha = 0.1, beta = 0)\n\n  \nplt.plot(torch.arange(1, len(loss_vec)+1), loss_vec, color = \"black\")\nplt.semilogx()\nlabs = plt.gca().set(xlabel = \"Number of gradient descent iterations\", ylabel = \"Loss (binary cross entropy)\")\n\n\n\n\n\n\n\n\n\nThe code above implements a vanilla gradient descent with logistic regression. It is run through a training loop, while keeping track of the loss and storing it in an array called loss_vec. Using loss_vec, I plot a graph showing the loss over gradient iterations. The second graph shows the decision boundary of the data. - Loss: This appears to hit convergence with a loss &lt;0.2 at ~10,000 iterations. - Decision Boundary: The decision boundary appears to correctly classify the data.\n\n\n\nHere, I compare vanilla gradient descent with gradient descent using momentum. By plotting the loss over iterations for both methods, I demonstrate how momentum can accelerate convergence when training logistic regression.\n\n\nCode\nX, y = classification_data(n_points=700, noise = 0.1)\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\nimport torch\n\n# Vanilla gradient descent\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\nloss_vec1 = []\niterations = 5000\nalpha = 0.1\nfor _ in range(iterations):\n    loss = LR.loss(X, y)\n    loss_vec1.append(loss)\n    opt.step(X, y, alpha, beta=0.0)  \n\n# Momentum version\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\nloss_vec2 = []\nfor _ in range(iterations):\n    loss = LR.loss(X, y)\n    loss_vec2.append(loss)\n    opt.step(X, y, alpha, beta=0.9) \n\n\nplt.plot(torch.arange(1, len(loss_vec1) + 1), loss_vec1, color=\"black\", label=f\"alpha={alpha}, beta=0.0\")\nplt.plot(torch.arange(1, len(loss_vec2) + 1), loss_vec2, color=\"orange\", label=f\"alpha={alpha}, beta=0.9\")\nplt.semilogx()\nplt.xlabel(\"Number of gradient descent iterations\")\nplt.ylabel(\"Loss (binary cross entropy)\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nThe code above plots the loss over iterations for both vanilla gradient descent and momentum gradient descent (beta = 0.9) over 5000 iterations with an alpha of 0.1. The loss of both descents begin at ~0.64, but momentum gradient descent drops lower a lot qucker and reaches convergence at ~1000 iterations. Vanilla gradient descent takes ~5000 iterations to reach convergence.\n\n\n\nThis experiment investigates overfitting by training a logistic regression model on high-dimensional data (more features than samples). I compare the model‚Äôs accuracy on the training and test sets to highlight the effects of overfitting.\n\n\nCode\n# Generate training and test data\nX_train, y_train = classification_data(n_points= 60, noise = 0.3, p_dims = 100)\nX_test, y_test = classification_data(n_points= 60, noise = 0.3, p_dims = 100)\n\n\n\n\nCode\n# Initialize the logistic regression model and optimizer\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\n# Train the model using momentum\nfor _ in range(200): \n    opt.step(X_train, y_train, alpha = 0.01, beta = 0.9)\n\n\n\n\nCode\n# Calculate training accuracy\ntrain_predictions = LR.predict(X_train)\ntrain_accuracy = (train_predictions == y_train).float().mean().item()\nprint(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n\n# Calculate testing accuracy\ntest_predictions = LR.predict(X_test)\ntest_accuracy = (test_predictions == y_test).float().mean().item()\nprint(f\"Testing Accuracy: {test_accuracy * 100:.2f}%\")\n\n\nTraining Accuracy: 100.00%\nTesting Accuracy: 93.33%\n\n\nThis experiments creates equal data for train and test set with 60 points, 100 dimensions and a noise of 0.3. The model(alpha = 0.01, beta = 0.9) is trained on the training set for 200 iterations,leading to overfitting and a training accuracy of a 100%. The accuracy of the model on the test set is 96.67%, which is rather good given the model was overfitted.\n\n\n\nIn this experiment, I apply my logistic regression model to a real-world dataset: the Kaggle heart disease prediction dataset. I preprocess the data, train the model, and evaluate its performance on training, validation, and test sets.\n\n\nCode\nimport kagglehub\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Download dataset from Kaggle\npath = kagglehub.dataset_download(\"shantanugarg274/heart-prediction-dataset-quantum\")\nprint(\"Path to dataset files:\", path)\n\ndata_path = path + \"/Heart Prediction Quantum Dataset.csv\"\ndf = pd.read_csv(data_path)\n\n\nWarning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.8), please consider upgrading to the latest version (0.3.12).\nPath to dataset files: /Users/emmanueltowner/.cache/kagglehub/datasets/shantanugarg274/heart-prediction-dataset-quantum/versions/1\n\n\nThe data was in 1 csv file with 7 columns representing age, gender, blood pressure, cholesterol, heart rate, quantum pattern feature, and heart disease.\n\n\nCode\nX_data = df.drop(\"HeartDisease\", axis=1).values\ny_data = df[\"HeartDisease\"].values\n\n\nSince I intend to predict heart disease, I removed that column from the main dataset and used it in the target set.\n\n\nCode\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nX_data = scaler.fit_transform(X_data)\nX_data = torch.tensor(X_data, dtype=torch.float32)\ny_data = torch.tensor(y_data, dtype=torch.float32)\n\n\nThe data across features widely varied in range and so I used sci-kit learn‚Äôs StandardScaler to standardize the both datasets and then converted them into tensors. The model was trained on the training set and the loss computed for both training and validation.\n\n\nCode\nX_train, X_temp, y_train, y_temp = train_test_split(X_data, y_data, test_size=0.4, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n\n\nI also used train_test_split to split the 60% data into training, 20% in validation, and test sets. I had to do this in 2 steps since the you cannot split the data into 3 sets at once.\n\n\nCode\nimport matplotlib.pyplot as plt\nimport torch\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 6))\n\n# Vanilla gradient descent\nLRV = LogisticRegression() \noptv = GradientDescentOptimizer(LRV)\n\nv_loss_train = []\nv_loss_val = []\n\niterations = 100\nalpha = 0.01\nfor _ in range(iterations):\n    train_loss = LRV.loss(X_train, y_train)\n    val_loss = LRV.loss(X_val, y_val)\n    v_loss_train.append(train_loss.item())\n    v_loss_val.append(val_loss.item())\n    optv.step(X_train, y_train, alpha, beta=0.0) \n\n# Momentum version\nLRM = LogisticRegression() \noptm = GradientDescentOptimizer(LRM)\n\nm_loss_train = []\nm_loss_val = []\nfor _ in range(iterations):\n    train_loss = LRM.loss(X_train, y_train)\n    val_loss = LRM.loss(X_val, y_val)\n    m_loss_train.append(train_loss.item())\n    m_loss_val.append(val_loss.item())\n    optm.step(X_train, y_train, alpha, beta=0.9)  \n\nax[0].plot(torch.arange(1, iterations + 1), v_loss_train, color=\"black\", label=\"Vanilla\")\nax[0].plot(torch.arange(1, iterations + 1), m_loss_train, color=\"orange\", label=\"Momentum\")\nax[0].set_xlabel(\"Iterations\")\nax[0].set_ylabel(\"Training Loss\")\nax[0].legend()\nax[0].set_title(\"Training Loss\")\n\nax[1].plot(torch.arange(1, iterations + 1), v_loss_val, color=\"black\", label=\"Vanilla\")\nax[1].plot(torch.arange(1, iterations + 1), m_loss_val, color=\"orange\", label=\"Momentum\")\nax[1].set_xlabel(\"Iterations\")\nax[1].set_ylabel(\"Validation Loss\")\nax[1].legend()\nax[1].set_title(\"Validation Loss\")\n\n\nText(0.5, 1.0, 'Validation Loss')\n\n\n\n\n\n\n\n\n\nThe 2 graphs above show the loss over iterations for both training and validation. The model was trained for 100 iterations with an alpha of 0.01 and mommentum beta of 0.9. The graphs were similar to each other and the only the momentum loss(~0.2 for training and ~0.3 for validation) reached convergence at the end.\n\n\nCode\ntest_loss = LRM.loss(X_test, y_test)\nprint(f\"Testing Loss: {test_loss.item():.4f}\")\n\n# Testing Accuracy\ntest_predictions = LRM.predict(X_test)\ntest_accuracy = (test_predictions == y_test).float().mean().item()\nprint(f\"Testing Accuracy: {test_accuracy * 100:.2f}%\")\n\n\nTesting Loss: 0.3732\nTesting Accuracy: 83.00%\n\n\nMy model had a loss of 0.38 and accuracy of 83% on the test set. While the accuracy is was decent, the loss was a bit high."
  },
  {
    "objectID": "posts/logistic/index.html#discussion",
    "href": "posts/logistic/index.html#discussion",
    "title": "Implementing Logistic Regression",
    "section": "",
    "text": "In this blog post, I implemented a logistic regression model with a momentum based optimizer. It successfully achieved convergence with vanilla gradient(beta = 0), then proved the with momentum it could increase speedup. The model was able to overfit the training data and achieve a high accuracy on the test set. The model was also able to learn the heart disease dataset, reach convergence, and achieve a good accuracy. The loss was a bit high, but maybe with more iterations it could be improved."
  },
  {
    "objectID": "posts/palmer/index.html",
    "href": "posts/palmer/index.html",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "Image source: @gabednick\n\n\n\n\nIn this blog post, I analyze the Palmer Penguins dataset to identify the best features for determining penguin species based on their measurements. First, I create two figures and a table to explore the relationships between different features. Next, I utilize Scikit-learn‚Äôs feature selection methods, employing chi-squared tests to select two numerical features and one categorical feature. With these features, I train and test a logistic regression model. The model demonstrates reasonable accuracy; however, to gain a better understanding of the results, I visualize the decision regions and present a confusion matrix.st features to be used to determine the species of a penguin based on its measurements. Firstly, I create two figures and a table to analysize the relationships between features. Then I use sci-kit learns feature selection with chi-squared tests to pick 2 numerical features and 1 categorical feature. Then using those features, I train and test a logistic regression model. The model was fairly accurate but to understand the results better, I plot the decision regions and use a confusion matrix.\n\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\n\n\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN\n\n\n\n\n\n\n\n\n\n\nThis code is from Professor Phil‚Äôs website. It removes unused columns and NA values, converts categorical feature columns into ‚Äúone-hot encoded‚Äù 0-1 columns, and saves the resulting DataFrame as X_train. Additionally, the ‚ÄúSpecies‚Äù column is encoded using LabelEncoder and stored as y_train.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\n\nWe can check what the columns look like now.\n\nX_train.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nStage_Adult, 1 Egg Stage\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40.9\n16.6\n187.0\n3200.0\n9.08458\n-24.54903\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n1\n49.0\n19.5\n210.0\n3950.0\n9.53262\n-24.66867\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n2\n50.0\n15.2\n218.0\n5700.0\n8.25540\n-25.40075\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n3\n45.8\n14.6\n210.0\n4200.0\n7.79958\n-25.62618\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n4\n51.0\n18.8\n203.0\n4100.0\n9.23196\n-24.17282\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n\n\n\n\n\n\n\n\n\n\nI created two graphs each two quantative columns and one qualitative columns. Plot 1 shows the relationship with the body mass and flipper length between different penguin species. Plot 2 shows the difference in Culmen Length and depth across different penguin species.\n\n# Get the unencoded columns for easier graphing.\nqual = train[[\"Island\", \"Sex\", \"Species\"]].dropna()\n\n# Shorten species label for the legend\nqual[\"Species\"] = qual[\"Species\"].apply(lambda x: \"Chinstrap\" if x == \"Chinstrap penguin (Pygoscelis antarctica)\" \n                                         else (\"Gentoo\" if x == \"Gentoo penguin (Pygoscelis papua)\" \n                                               else \"Adelie\"))\n\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nplt.style.use('seaborn-v0_8-whitegrid')\n\nfig, ax = plt.subplots(1, 2, figsize = (10, 4))\n   \np1 = sns.scatterplot(X_train, x = \"Body Mass (g)\", y = \"Flipper Length (mm)\", hue=qual[\"Species\"], ax = ax[0])\np2 = sns.scatterplot(X_train, x = \"Culmen Length (mm)\", y = \"Culmen Depth (mm)\", hue=qual[\"Species\"], ax = ax[1])\n\n\n\n\n\n\n\n\nPlot 1 (Left): This graph shows the relationship between body mass and flipper length among different penguin species. Gentoo penguins are the largest, while Chinstrap and Adelie penguins overlap considerably in size. Adelie penguins show slightly more variation in mass for a given flipper length compared to Chinstraps.\nPlot 2 (Right): This graph illustrates the differences in culmen length and depth among the species. Adelie penguins have the deepest but shortest culmen, Gentoo penguins have longer but less deep culmens, and Chinstraps are in between. These differences in beak size are significant for distinguishing penguin species.\n\n\n\nNow I create a summary table of the penguins measurements based on clutch completetion.\n\ntable = X_train[[\"Clutch Completion_Yes\", \"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\", \"Body Mass (g)\"]]\ntable.groupby(\"Clutch Completion_Yes\").aggregate(['min', 'median', 'max'])\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\n\n\n\nmin\nmedian\nmax\nmin\nmedian\nmax\nmin\nmedian\nmax\nmin\nmedian\nmax\n\n\nClutch Completion_Yes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFalse\n35.9\n43.35\n58.0\n13.7\n17.85\n19.9\n172.0\n195.0\n225.0\n2700.0\n3737.5\n5700.0\n\n\nTrue\n34.0\n45.10\n55.9\n13.1\n17.20\n21.5\n176.0\n198.0\n230.0\n2850.0\n4100.0\n6300.0\n\n\n\n\n\n\n\nTable 1: This table shows that the most significant difference between penguins that had a full clutch and those that did not is their weight. Most of the penguins that produced two eggs weighed approximately 300 grams more. While there may be a correlation between clutch completion and weight, it is unlikely that there is a direct causation. Since clutch completion does not appear to impact this data significantly, it may not be a feature worth further investigation.\n\n\n\n\nHere I used the SelectKBest function from the sci-kit-learn library to choose the three features that I will include in my model. I separated feature selection because all three selected features are numerical. SelectKBest identifies the k best features based on a user-specified scoring function. I chose the chi-squared scoring function, as my features are intended for classification and are non-negative\n\nfrom sklearn.feature_selection import SelectKBest, chi2\n\n# Selecting 2 numerical feature\nquant = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']\nsel1 = SelectKBest(chi2, k=2)\nsel1.fit_transform(X_train[quant], y_train)\nf1 = sel1.get_feature_names_out()\n\n# Selecting 1 categorical feature\nqual = [\"Clutch Completion_Yes\", \"Clutch Completion_No\", \"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\", \"Sex_FEMALE\", \"Sex_MALE\"]\nsel2 = SelectKBest(chi2, k=1)\nsel2.fit_transform(X_train[qual], y_train)\nf2 = sel2.get_feature_names_out()\n\nThis function is so that I can get all the variations of the categorical feature.\n\ndef get_feat(f1, cat):\n    cols = list(f1)\n    clutch = [\"Clutch Completion_Yes\", \"Clutch Completion_No\"]\n    island = [\"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\"]\n    sex = [\"Sex_FEMALE\", \"Sex_MALE\"]\n    \n    if cat in clutch: return cols + clutch\n    if cat in island: return cols + island\n    if cat in sex: return cols + sex\n\n\ncols = get_feat(f1, f2[0])\ncols\n\n['Flipper Length (mm)',\n 'Body Mass (g)',\n 'Island_Biscoe',\n 'Island_Dream',\n 'Island_Torgersen']\n\n\nAlthough the culmen sizes initially appeared to be better features, the statistical tests indicated that flipper length and body mass were, in fact, the more significant features.\n\n\n\nThe model is trained on the data with features determined from above. I had to use StandardScalar to avoid a convergence error. I used the Logistic Regression model as it is a good fit for classification.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n\npipe = make_pipeline(StandardScaler(), LogisticRegression())\npipe.fit(X_train[cols], y_train)\npipe.score(X_train[cols], y_train)\n\n0.8984375\n\n\n\n\n\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\npipe.score(X_test[cols], y_test)\n\n0.8970588235294118\n\n\n\n\n\n\n\nMost of this code is adapted from Prof.¬†Phil‚Äôs website.\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (8, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\nRegions for training set:\n\nplot_regions(pipe, X_train[cols], y_train)\n\n\n\n\n\n\n\n\nRegions for testing set:\n\nplot_regions(pipe, X_test[cols], y_test)\n\n\n\n\n\n\n\n\nLooking at the decision plots, we can see that our model is quite successful in distinguishing between Gentoo and Adelie penguins on the Biscoe and Torgersen islands. However, on Dream Island, where there is a mixture of Gentoo and Chinstrap penguins, the model struggles to differentiate between the two species.\n\n\n\n\nfrom sklearn.metrics import confusion_matrix\n\ny_test_pred = pipe.predict(X_test[cols])\nconfusion_matrix(y_test, y_test_pred)\n\narray([[26,  5,  0],\n       [ 2,  9,  0],\n       [ 0,  0, 26]])\n\n\nOnce again, this shows that model struggled the most with Gentoo and Chinstrap.\n\n\n\n\nThe model achieved a training accuracy of 0.89, which is the same as its testing accuracy. This indicates that the model is quite effective at predicting penguin species based on flipper length, body mass, and island. However, the decision regions suggest that the model had difficulty distinguishing between Chinstrap and Gentoo penguins on Dream Island. It appears that these two species have similar sizes, making them challenging to differentiate.\n\n\n\n\nAdapted code from Professor Phil Chodrow at Middlebury College in his class CSCI 0451: Machine Learning."
  },
  {
    "objectID": "posts/palmer/index.html#abstract",
    "href": "posts/palmer/index.html#abstract",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "In this blog post, I analyze the Palmer Penguins dataset to identify the best features for determining penguin species based on their measurements. First, I create two figures and a table to explore the relationships between different features. Next, I utilize Scikit-learn‚Äôs feature selection methods, employing chi-squared tests to select two numerical features and one categorical feature. With these features, I train and test a logistic regression model. The model demonstrates reasonable accuracy; however, to gain a better understanding of the results, I visualize the decision regions and present a confusion matrix.st features to be used to determine the species of a penguin based on its measurements. Firstly, I create two figures and a table to analysize the relationships between features. Then I use sci-kit learns feature selection with chi-squared tests to pick 2 numerical features and 1 categorical feature. Then using those features, I train and test a logistic regression model. The model was fairly accurate but to understand the results better, I plot the decision regions and use a confusion matrix.\n\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\n\n\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN"
  },
  {
    "objectID": "posts/palmer/index.html#data-preparation",
    "href": "posts/palmer/index.html#data-preparation",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "This code is from Professor Phil‚Äôs website. It removes unused columns and NA values, converts categorical feature columns into ‚Äúone-hot encoded‚Äù 0-1 columns, and saves the resulting DataFrame as X_train. Additionally, the ‚ÄúSpecies‚Äù column is encoded using LabelEncoder and stored as y_train.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\n\nWe can check what the columns look like now.\n\nX_train.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nStage_Adult, 1 Egg Stage\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40.9\n16.6\n187.0\n3200.0\n9.08458\n-24.54903\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n1\n49.0\n19.5\n210.0\n3950.0\n9.53262\n-24.66867\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n2\n50.0\n15.2\n218.0\n5700.0\n8.25540\n-25.40075\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n3\n45.8\n14.6\n210.0\n4200.0\n7.79958\n-25.62618\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n4\n51.0\n18.8\n203.0\n4100.0\n9.23196\n-24.17282\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue"
  },
  {
    "objectID": "posts/palmer/index.html#data-visualization",
    "href": "posts/palmer/index.html#data-visualization",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "I created two graphs each two quantative columns and one qualitative columns. Plot 1 shows the relationship with the body mass and flipper length between different penguin species. Plot 2 shows the difference in Culmen Length and depth across different penguin species.\n\n# Get the unencoded columns for easier graphing.\nqual = train[[\"Island\", \"Sex\", \"Species\"]].dropna()\n\n# Shorten species label for the legend\nqual[\"Species\"] = qual[\"Species\"].apply(lambda x: \"Chinstrap\" if x == \"Chinstrap penguin (Pygoscelis antarctica)\" \n                                         else (\"Gentoo\" if x == \"Gentoo penguin (Pygoscelis papua)\" \n                                               else \"Adelie\"))\n\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nplt.style.use('seaborn-v0_8-whitegrid')\n\nfig, ax = plt.subplots(1, 2, figsize = (10, 4))\n   \np1 = sns.scatterplot(X_train, x = \"Body Mass (g)\", y = \"Flipper Length (mm)\", hue=qual[\"Species\"], ax = ax[0])\np2 = sns.scatterplot(X_train, x = \"Culmen Length (mm)\", y = \"Culmen Depth (mm)\", hue=qual[\"Species\"], ax = ax[1])\n\n\n\n\n\n\n\n\nPlot 1 (Left): This graph shows the relationship between body mass and flipper length among different penguin species. Gentoo penguins are the largest, while Chinstrap and Adelie penguins overlap considerably in size. Adelie penguins show slightly more variation in mass for a given flipper length compared to Chinstraps.\nPlot 2 (Right): This graph illustrates the differences in culmen length and depth among the species. Adelie penguins have the deepest but shortest culmen, Gentoo penguins have longer but less deep culmens, and Chinstraps are in between. These differences in beak size are significant for distinguishing penguin species.\n\n\n\nNow I create a summary table of the penguins measurements based on clutch completetion.\n\ntable = X_train[[\"Clutch Completion_Yes\", \"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\", \"Body Mass (g)\"]]\ntable.groupby(\"Clutch Completion_Yes\").aggregate(['min', 'median', 'max'])\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\n\n\n\nmin\nmedian\nmax\nmin\nmedian\nmax\nmin\nmedian\nmax\nmin\nmedian\nmax\n\n\nClutch Completion_Yes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFalse\n35.9\n43.35\n58.0\n13.7\n17.85\n19.9\n172.0\n195.0\n225.0\n2700.0\n3737.5\n5700.0\n\n\nTrue\n34.0\n45.10\n55.9\n13.1\n17.20\n21.5\n176.0\n198.0\n230.0\n2850.0\n4100.0\n6300.0\n\n\n\n\n\n\n\nTable 1: This table shows that the most significant difference between penguins that had a full clutch and those that did not is their weight. Most of the penguins that produced two eggs weighed approximately 300 grams more. While there may be a correlation between clutch completion and weight, it is unlikely that there is a direct causation. Since clutch completion does not appear to impact this data significantly, it may not be a feature worth further investigation."
  },
  {
    "objectID": "posts/palmer/index.html#feature-selection",
    "href": "posts/palmer/index.html#feature-selection",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "Here I used the SelectKBest function from the sci-kit-learn library to choose the three features that I will include in my model. I separated feature selection because all three selected features are numerical. SelectKBest identifies the k best features based on a user-specified scoring function. I chose the chi-squared scoring function, as my features are intended for classification and are non-negative\n\nfrom sklearn.feature_selection import SelectKBest, chi2\n\n# Selecting 2 numerical feature\nquant = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']\nsel1 = SelectKBest(chi2, k=2)\nsel1.fit_transform(X_train[quant], y_train)\nf1 = sel1.get_feature_names_out()\n\n# Selecting 1 categorical feature\nqual = [\"Clutch Completion_Yes\", \"Clutch Completion_No\", \"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\", \"Sex_FEMALE\", \"Sex_MALE\"]\nsel2 = SelectKBest(chi2, k=1)\nsel2.fit_transform(X_train[qual], y_train)\nf2 = sel2.get_feature_names_out()\n\nThis function is so that I can get all the variations of the categorical feature.\n\ndef get_feat(f1, cat):\n    cols = list(f1)\n    clutch = [\"Clutch Completion_Yes\", \"Clutch Completion_No\"]\n    island = [\"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\"]\n    sex = [\"Sex_FEMALE\", \"Sex_MALE\"]\n    \n    if cat in clutch: return cols + clutch\n    if cat in island: return cols + island\n    if cat in sex: return cols + sex\n\n\ncols = get_feat(f1, f2[0])\ncols\n\n['Flipper Length (mm)',\n 'Body Mass (g)',\n 'Island_Biscoe',\n 'Island_Dream',\n 'Island_Torgersen']\n\n\nAlthough the culmen sizes initially appeared to be better features, the statistical tests indicated that flipper length and body mass were, in fact, the more significant features."
  },
  {
    "objectID": "posts/palmer/index.html#training",
    "href": "posts/palmer/index.html#training",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "The model is trained on the data with features determined from above. I had to use StandardScalar to avoid a convergence error. I used the Logistic Regression model as it is a good fit for classification.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n\npipe = make_pipeline(StandardScaler(), LogisticRegression())\npipe.fit(X_train[cols], y_train)\npipe.score(X_train[cols], y_train)\n\n0.8984375"
  },
  {
    "objectID": "posts/palmer/index.html#testing",
    "href": "posts/palmer/index.html#testing",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "test_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\npipe.score(X_test[cols], y_test)\n\n0.8970588235294118"
  },
  {
    "objectID": "posts/palmer/index.html#results",
    "href": "posts/palmer/index.html#results",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "Most of this code is adapted from Prof.¬†Phil‚Äôs website.\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (8, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\nRegions for training set:\n\nplot_regions(pipe, X_train[cols], y_train)\n\n\n\n\n\n\n\n\nRegions for testing set:\n\nplot_regions(pipe, X_test[cols], y_test)\n\n\n\n\n\n\n\n\nLooking at the decision plots, we can see that our model is quite successful in distinguishing between Gentoo and Adelie penguins on the Biscoe and Torgersen islands. However, on Dream Island, where there is a mixture of Gentoo and Chinstrap penguins, the model struggles to differentiate between the two species.\n\n\n\n\nfrom sklearn.metrics import confusion_matrix\n\ny_test_pred = pipe.predict(X_test[cols])\nconfusion_matrix(y_test, y_test_pred)\n\narray([[26,  5,  0],\n       [ 2,  9,  0],\n       [ 0,  0, 26]])\n\n\nOnce again, this shows that model struggled the most with Gentoo and Chinstrap."
  },
  {
    "objectID": "posts/palmer/index.html#discussion",
    "href": "posts/palmer/index.html#discussion",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "The model achieved a training accuracy of 0.89, which is the same as its testing accuracy. This indicates that the model is quite effective at predicting penguin species based on flipper length, body mass, and island. However, the decision regions suggest that the model had difficulty distinguishing between Chinstrap and Gentoo penguins on Dream Island. It appears that these two species have similar sizes, making them challenging to differentiate."
  },
  {
    "objectID": "posts/palmer/index.html#acknowledgements",
    "href": "posts/palmer/index.html#acknowledgements",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "Adapted code from Professor Phil Chodrow at Middlebury College in his class CSCI 0451: Machine Learning."
  },
  {
    "objectID": "posts/audit/index.html",
    "href": "posts/audit/index.html",
    "title": "Auditing Bias",
    "section": "",
    "text": "My goal was to make a predicition of employment status based on various demographic excluding race using a subset of data from the American Community Service focused on Massachusetts residents in 2023. Based on the data of the 58,500 residents, only half were employed. Most of the time men, people without disabilities, and people who born abroad or with no citizensip had higher proportions of employment. The model I used was sklearns Decision Tree Classifier because results are easy to interpret. I tuned complexity by I using GridSearchCV which cross-validated that the best depth out of the numbers I provided was 10 which overall accuracy 0.82. The different group accuracies weren‚Äôt that much different. Auditing my model showed that white people lead in PPV and FNR while Asians lead in TPR and FPR rates. In these summary I left races 5 and 6 because their data often had many missing values. Based on those values, my model failed approximate error balance and statistical parity but satisfied calibration. The plot that used the fixed PPV values and p values to graph feasible FPR and FNR combinations between Black and White residents.\n\n\nCode\nfrom folktables import ACSDataSource, ACSEmployment, BasicProblem, adult_filter\nimport numpy as np\n\nSTATE = \"MA\" \n\ndata_source = ACSDataSource(survey_year='2023', # Get more recent data\n                            horizon='1-Year', \n                            survey='person')\n\nacs_data = data_source.get_data(states=[STATE], download=True)\n\nacs_data.head()\n\n\n\n\n\n\n\n\n\nRT\nSERIALNO\nDIVISION\nSPORDER\nPUMA\nREGION\nSTATE\nADJINC\nPWGTP\nAGEP\n...\nPWGTP71\nPWGTP72\nPWGTP73\nPWGTP74\nPWGTP75\nPWGTP76\nPWGTP77\nPWGTP78\nPWGTP79\nPWGTP80\n\n\n\n\n0\nP\n2023GQ0000077\n1\n1\n503\n1\n25\n1019518\n11\n89\n...\n12\n13\n13\n13\n13\n13\n13\n12\n13\n13\n\n\n1\nP\n2023GQ0000098\n1\n1\n613\n1\n25\n1019518\n11\n20\n...\n3\n4\n2\n20\n13\n9\n2\n20\n13\n2\n\n\n2\nP\n2023GQ0000109\n1\n1\n613\n1\n25\n1019518\n80\n68\n...\n28\n34\n78\n73\n34\n68\n82\n15\n17\n79\n\n\n3\nP\n2023GQ0000114\n1\n1\n801\n1\n25\n1019518\n69\n21\n...\n60\n74\n161\n11\n127\n57\n11\n12\n11\n12\n\n\n4\nP\n2023GQ0000135\n1\n1\n1201\n1\n25\n1019518\n27\n84\n...\n27\n28\n27\n29\n27\n29\n27\n27\n28\n27\n\n\n\n\n5 rows √ó 287 columns\n\n\n\n\n\nCode\n# No RELP avaiable \npossible_features=['AGEP', 'SCHL', 'MAR', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC', 'NATIVITY', 'DEAR', 'DEYE', 'DREM', 'SEX', 'RAC1P', 'ESR']\nacs_data[possible_features].head()\n\n\n\n\n\n\n\n\n\nAGEP\nSCHL\nMAR\nDIS\nESP\nCIT\nMIG\nMIL\nANC\nNATIVITY\nDEAR\nDEYE\nDREM\nSEX\nRAC1P\nESR\n\n\n\n\n0\n89\n16.0\n2\n1\nNaN\n1\n1.0\n4.0\n3\n1\n1\n1\n1.0\n2\n1\n6.0\n\n\n1\n20\n16.0\n5\n2\nNaN\n1\n1.0\n4.0\n1\n1\n2\n2\n2.0\n1\n9\n6.0\n\n\n2\n68\n18.0\n5\n1\nNaN\n1\n1.0\n4.0\n1\n1\n1\n2\n2.0\n1\n1\n6.0\n\n\n3\n21\n19.0\n5\n2\nNaN\n1\n1.0\n4.0\n1\n1\n2\n2\n2.0\n2\n1\n1.0\n\n\n4\n84\n16.0\n1\n1\nNaN\n1\n3.0\n4.0\n3\n1\n2\n1\n1.0\n2\n1\n6.0\n\n\n\n\n\n\n\n\n\n\n\n\nAdapted from Professor Phil‚Äôs code.\n\n\nCode\nfeatures_to_use = [f for f in possible_features if f not in [\"ESR\", \"RAC1P\"]]\n\n\n\n\nCode\nEmploymentProblem = BasicProblem(\n    features=features_to_use,\n    target='ESR',\n    target_transform=lambda x: x == 1,\n    group='RAC1P',\n    preprocess=lambda x: x,\n    postprocess=lambda x: np.nan_to_num(x, -1),\n)\n\nfeatures, label, group = EmploymentProblem.df_to_numpy(acs_data)\n\nfor obj in [features, label, group]:\n  print(obj.shape)\n\n\n(73126, 14)\n(73126,)\n(73126,)\n\n\n\n\nCode\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n    features, label, group, test_size=0.2, random_state=0)\n\n\n\n\nCode\n\nimport pandas as pd\ndf = pd.DataFrame(X_train, columns = features_to_use)\ndf[\"race\"] = group_train\ndf[\"label\"] = y_train\n\n\nThis method allows the conversion of race numbers to more helpful categorical labels. Some of them have been shortened because they were too long. 1. SPAA - ‚ÄúAmerican Indian and Alaska Native tribes specified, or American Indian or AlaskaNative, not specified and no other races‚Äù. 2. NPI - Native Hawaiian and Other Pacific Islander alone\n\n\nCode\ndef convert_race(df: pd.DataFrame):\n    df = df.sort_values(by='race')\n    df['race'] = df['race'].replace({1: \"White\", 2: \"Black\", 3: \"N. American\", 4:\"N. Alaskan\", \n                        5:\"SPAA\", \n                        6:'Asian', 7: 'NPI', 8:'Other', 9: 'Multi'})\n\n    df['race'] = pd.Categorical(df['race'])\n    return df\n    \n\n\n\n\n\n\n\nCode\n# Save to the original for calculations and copying\nrelabeled = df.copy() \nrelabeled = convert_race(relabeled)\nrelabeled\n\n\n\n\n\n\n\n\n\nAGEP\nSCHL\nMAR\nDIS\nESP\nCIT\nMIG\nMIL\nANC\nNATIVITY\nDEAR\nDEYE\nDREM\nSEX\nrace\nlabel\n\n\n\n\n0\n69.0\n19.0\n1.0\n2.0\n0.0\n1.0\n1.0\n4.0\n1.0\n1.0\n2.0\n2.0\n2.0\n2.0\nWhite\nFalse\n\n\n35997\n12.0\n9.0\n5.0\n2.0\n1.0\n1.0\n1.0\n0.0\n1.0\n1.0\n2.0\n2.0\n2.0\n2.0\nWhite\nFalse\n\n\n35999\n70.0\n24.0\n1.0\n2.0\n0.0\n1.0\n1.0\n4.0\n2.0\n1.0\n2.0\n2.0\n2.0\n1.0\nWhite\nTrue\n\n\n36000\n74.0\n22.0\n1.0\n2.0\n0.0\n1.0\n1.0\n4.0\n2.0\n1.0\n2.0\n2.0\n2.0\n1.0\nWhite\nFalse\n\n\n36001\n68.0\n23.0\n2.0\n2.0\n0.0\n1.0\n1.0\n4.0\n1.0\n1.0\n2.0\n2.0\n2.0\n2.0\nWhite\nTrue\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n51260\n6.0\n3.0\n5.0\n2.0\n2.0\n1.0\n1.0\n0.0\n1.0\n1.0\n2.0\n2.0\n2.0\n2.0\nMulti\nFalse\n\n\n51257\n7.0\n4.0\n5.0\n2.0\n7.0\n1.0\n1.0\n0.0\n1.0\n1.0\n2.0\n2.0\n2.0\n2.0\nMulti\nFalse\n\n\n5335\n14.0\n11.0\n5.0\n2.0\n3.0\n1.0\n1.0\n0.0\n3.0\n1.0\n2.0\n2.0\n2.0\n1.0\nMulti\nFalse\n\n\n34217\n18.0\n14.0\n5.0\n2.0\n0.0\n1.0\n1.0\n4.0\n1.0\n1.0\n2.0\n2.0\n2.0\n2.0\nMulti\nFalse\n\n\n40473\n18.0\n18.0\n5.0\n2.0\n0.0\n1.0\n3.0\n4.0\n4.0\n1.0\n2.0\n2.0\n2.0\n1.0\nMulti\nTrue\n\n\n\n\n58500 rows √ó 16 columns\n\n\n\n\nThe number of indiviuals in this dataframe are:\n\n\n\nCode\nprint(\"The number of indiviuals in this df are\", df.shape[0])\n\n\nThe number of indiviuals in this df are 58500\n\n\n\nThe proportion of employed individuals are:\n\n\n\nCode\nemp = df[df['label'] == True][[\"label\"]].size # 29703\ntotal = df['label'].size # 58500\nemp_prop = emp / total\nprint(\"The proportion of employed indiviuals are\", emp_prop)\n\n\nThe proportion of employed indiviuals are 0.5077435897435898\n\n\n\nThe population of each group is:\n\n\n\nCode\nrelabeled.groupby('race')[['label']].aggregate('sum')\n\n\n\n\n\n\n\n\n\nlabel\n\n\nrace\n\n\n\n\n\nAsian\n2399\n\n\nBlack\n1529\n\n\nMulti\n2478\n\n\nN. American\n52\n\n\nNPI\n15\n\n\nOther\n1284\n\n\nSPAA\n26\n\n\nWhite\n21920\n\n\n\n\n\n\n\nBased on this, I might consider whether groups with less than 30 labels provide an adequate sample size.\n\nThe proportion of employed people in each group are:\n\n\n\nCode\nrelabeled.groupby('race')[['label']].aggregate('mean')\n\n\n\n\n\n\n\n\n\nlabel\n\n\nrace\n\n\n\n\n\nAsian\n0.540315\n\n\nBlack\n0.473668\n\n\nMulti\n0.456270\n\n\nN. American\n0.530612\n\n\nNPI\n0.625000\n\n\nOther\n0.486364\n\n\nSPAA\n0.520000\n\n\nWhite\n0.514687\n\n\n\n\n\n\n\n\nIntersectional Trends\n\n\n\nCode\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nfig, ax = plt.subplots(1, 2, figsize = (14, 4))\n\ncolors = [\"#1f77b4\", \"#ff7f0e\"]\nplt1 = sns.barplot(relabeled, x = \"race\", y = \"label\", hue=\"SEX\", palette=colors, ax=ax[0])\nplt1.set_xlabel(\"Race\")\nplt1.set_ylabel(\"Employment\")\nhandles, _ = plt1.get_legend_handles_labels()\nplt1.legend(handles=handles, title='Sex', labels=['Male', 'Female'])\n\nplt2 = sns.barplot(relabeled, x = \"race\", y = \"label\", hue=\"DIS\", palette=colors, ax=ax[1])\nplt2.set_xlabel(\"Race\")\nplt2.set_ylabel(\"Employment\")\nhandles, _ = plt2.get_legend_handles_labels()\nplt2.legend(handles=handles, title='Disability', labels=['Has disability', 'No disability'])\nplt.show()\n\n\n\n\n\n\n\n\n\nIn these graphs, we observe the intersectionality of employment rates based on gender and disability status. Generally, men and individuals without disabilities tend to be more likely to secure jobs. Several factors contribute to this disparity. For one, women and people with disabilities often face discrimination from employers. Additionally, the number of applicants from these groups could also play a role; even though more women are entering the workforce, many continue to take on childcare responsibilities at home. Moreover, ‚Äúdisability‚Äù encompasses a wide range of conditions, making it difficult to determine which individuals are capable of working and which are not. This uncertainty likely contributes to the lower employment rates among these groups. Interestingly, it‚Äôs worth noting that for Black Americans, Native Americans, and SPAA, there are more women employed than men.In this we see intersectionality between employment based on the sex of the person or whether they have a disability. As we can see in both graphs generally male and able bodied people are more likely to be employed. Multiple factors can contribute to this desparity. One is that women and people with disabilities are discriminated against by employers. Another is also considering how many of them are applying for jobs. For women, even with more of them joining the workforce, they may be more likely to doing childcare at home. Because disabilites is such a broad it‚Äôs hard which may be capable of working and those that aren‚Äôt. This probably a big factor why relatively few are employed. Something I noticed is that for Black Americans, Native Americans and SPAA more females are employed than males.\n\n\nCode\nplt3 = sns.barplot(relabeled, x = \"race\", y = \"label\", hue=\"CIT\")\nplt3.set_xlabel(\"Race\")\nplt3.set_ylabel(\"Employment\")\nhandles, _ = plt3.get_legend_handles_labels()\nstatus = ['Born in US', 'Born in US Territories', 'Born Abroad', 'US by naturalization', 'Not a citizen']\nplt3.legend(handles=handles, title='Citizenship', labels=status, loc='center left', bbox_to_anchor=(1, 0.5))\nplt.show()\n\n\n\n\n\n\n\n\n\nThis graph shows that individuals born in the U.S. or its territories have a lower percentage of employment compared to those born abroad or through naturalization. I suspect this may be due to the smaller population size and the fact that immigrants often come with specific job opportunities in mind.\n\n\n\nThe decision tree classifier was one of the recommedations given by the professor and scikit-learn said the results are easy to interpret. In order to find the best depth for the model training, I used GridSearchCV which cross validated the best parameters to use.\n\n\nCode\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix\n\nparam_grid = {\n    'max_depth': [1, 3, 5, 10]\n}\n\nmodel = DecisionTreeClassifier() \ngrid = GridSearchCV(model, param_grid, scoring=\"accuracy\")\ngrid.fit(X_train, y_train)\n\nprint(\"Best params\", grid.best_params_)\n\nbest_dtree = grid.best_estimator_\n\nbest_dtree.predict(X_train)\nbest_dtree.score(X_train, y_train)\n\n\nBest params {'max_depth': 10}\n\n\n0.8346666666666667\n\n\nThe best depth was 10 and gave us a solid accuracy.\n\n\n\n\n\nCode\npred = best_dtree.predict(X_test)\nscore = best_dtree.score(X_test, y_test)\n\nprint(\"Test score\", score)\n\n\nTest score 0.821892520169561\n\n\n\n\n\n\n\n\nThe overall accuracy:\n\n\nCode\n(pred == y_test).mean()\n\n\nnp.float64(0.821892520169561)\n\n\nHere we calculate the PPV, the false negative and false positive rate\n\n\nCode\ntn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n\nppv = tp / (tp + fp)\nfnr = fn / (fn + tp)\nfpr = tp / (tp + tn)\n\nprint(\"Overall PPV:\", ppv)\nprint(\"Overall false negative rate:\", fnr)\nprint(\"Overall false positive rate:\", fpr)\n\n\nOverall PPV: 0.7938385705483673\nOverall false negative rate: 0.12639001898562516\nOverall false positive rate: 0.5358955161800183\n\n\nBased on this the model is pretty good at predicting who‚Äôs not employed but seems to overestimate the amount of people employed.\n\n\n\nThis is the accuracy by group:\n\n\nCode\ngroups = df[\"race\"].unique() # Need race as numbers in order to compare with group_test\naudit = pd.DataFrame(groups, columns=[\"race\"])\n\naccuracies = []\nfor group in groups:\n   accuracy = (pred == y_test)[group_test == group].mean()\n   accuracies.append(accuracy)\n\naudit[\"accuracy\"] = accuracies\naudit = convert_race(audit)\naudit\n\n\n\n\n\n\n\n\n\nrace\naccuracy\n\n\n\n\n0\nWhite\n0.824150\n\n\n3\nBlack\n0.799747\n\n\n7\nN. American\n0.812500\n\n\n6\nSPAA\n1.000000\n\n\n4\nAsian\n0.821859\n\n\n5\nNPI\n0.500000\n\n\n1\nOther\n0.807092\n\n\n2\nMulti\n0.825095\n\n\n\n\n\n\n\nBasides NPI and SPAA, the accuracies are rather similar to each other.\nThis is the PPV, the false negative and false positive rate by group:\n\n\nCode\nppvs = []\ntprs = []\nfnrs = []\nfprs = []\n\nfor group in groups:\n    tp = int(0)\n    fp = int(0)\n    tn = int(0)\n    fn = int(0)\n    for n, m, grp in zip(y_test, pred, group_test):\n        if(grp == group):\n            if m == n:\n                if n == True:\n                    tp += 1\n                if n == False:\n                    tn += 1\n            if m != n:\n                if n == True:\n                    fn += 1\n                if n == False:\n                    fp += 1\n    ppv = tp / (tp + fp) if (tp + fp) &gt; 0 else 0\n    ppvs.append(ppv)\n    fnr = fn / (fn + tp)  if (fn + tp) &gt; 0 else 0\n    fnrs.append(fnr)\n    fpr = fp / (fp + tn) if (fp + tn) &gt; 0 else 0 \n    fprs.append(fpr)\n    tpr = tp / (tp + fn) if (tp + fn) &gt; 0 else 0\n    tprs.append(tpr)\n    \n\naudit[\"ppv\"] = ppvs\naudit[\"tpr\"] = tprs\naudit[\"fpr\"] = fprs\naudit[\"fnr\"] = fnrs\naudit\n\n\n\n\n\n\n\n\n\nrace\naccuracy\nppv\ntpr\nfpr\nfnr\n\n\n\n\n0\nWhite\n0.824150\n0.802322\n0.868922\n0.222350\n0.131078\n\n\n3\nBlack\n0.799747\n0.750630\n0.889552\n0.267568\n0.110448\n\n\n7\nN. American\n0.812500\n0.769345\n0.873311\n0.214385\n0.126689\n\n\n6\nSPAA\n1.000000\n0.739631\n0.877049\n0.267139\n0.122951\n\n\n4\nAsian\n0.821859\n0.807588\n0.901664\n0.283433\n0.098336\n\n\n5\nNPI\n0.500000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\n1\nOther\n0.807092\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n2\nMulti\n0.825095\n0.625000\n1.000000\n0.272727\n0.000000\n\n\n\n\n\n\n\n\n\n\nUsing code adapted from from Machine Learning Master and sklearn documentation, I used a sci-kit learn‚Äôs calibration curve to diagnose the calibration:\n\n\nCode\nfrom sklearn.calibration import calibration_curve \n\ny_prob = best_dtree.predict_proba(X_test)[:, 1] # Gets the probability of positive values\nprob_true, prob_pred = calibration_curve(y_test, y_prob, n_bins=10)\n\navgs = []\nactuals = []\nfor group in groups:\n    # P(Y = 1 | S = {0,1}, R = r) \n    avg_pred_prob = y_prob[group_test == group].mean()\n    avgs.append(avg_pred_prob)\n    actual_employment_rate = (y_test == 1)[group_test == group].mean()\n    actuals.append(actual_employment_rate)\n\ncalibrate= pd.DataFrame(groups, columns=[\"race\"])\ncalibrate[\"employed\"] = actuals\ncalibrate[\"avg_predicted_probs\"] = avgs\nprint(calibrate)\n\ncal = plt\ncal.plot([0, 1], [0, 1], linestyle='--') # Actual values\ncal.plot(prob_pred, prob_true, marker='.') # Predicted values\ncal.title(\"Model Calibration\")\ncal.xlabel(\"Average Probability\")\ncal.ylabel(\"Fraction of Positive\")\ncal.show()\n\n\n   race  employed  avg_predicted_probs\n0     1  0.509466             0.510189\n1     8  0.475177             0.486277\n2     9  0.450190             0.449267\n3     2  0.463878             0.482898\n4     6  0.568847             0.571642\n5     7  0.500000             0.336508\n6     5  0.000000             0.094724\n7     3  0.312500             0.424606\n\n\n\n\n\n\n\n\n\nThe above graph and table shows that my model is nearly calibrated, meaning that the model usually predicts probabilites that are the same as the real probabilities.\nApproximate error balance rate: Looking at the table above we can see that the model does not meet approximate error rate balance for groups. The groups differ in true and false positive rates. The code below double checks.\n\n\nCode\nfor i, row1 in audit.iterrows():\n    equal = True;\n    race1 = row1['race']\n    tpr1 = row1['tpr']\n    fpr1 = row1['fpr']\n    for j, row2 in audit.iterrows():\n        race2 = row2['race']\n        tpr2 = row2['tpr']\n        fpr2 = row2['fpr']\n        if(tpr1 != tpr2 or fpr1 != fpr2):\n            equal = False\n            print(f\"{race1} did not have an equal TPR or FPR as {race2}\")\n            break\n    if(equal != True):\n        break\n\n\nWhite did not have an equal TPR or FPR as Black\n\n\nStatistical parity:\n\n\nCode\nprobs = []\nfor group in groups:\n    prob = (pred == True)[group_test == group].mean()\n    probs.append(prob)\n\nparity= pd.DataFrame(groups, columns=[\"race\"])\nparity[\"prob\"] = probs\nparity\n\n\n\n\n\n\n\n\n\nrace\nprob\n\n\n\n\n0\n1\n0.551757\n\n\n1\n8\n0.563121\n\n\n2\n9\n0.511027\n\n\n3\n2\n0.550063\n\n\n4\n6\n0.635112\n\n\n5\n7\n0.000000\n\n\n6\n5\n0.000000\n\n\n7\n3\n0.500000\n\n\n\n\n\n\n\nThe model does not meet statistical parity which means not all groups have an equal change of achieving favorable odds. Therefore we can assume that the probability of predicting employment is not independent of race.\n\n\n\nAdd prevalance to data table\n\n\nCode\naudit[\"p\"] = (1 + (audit[\"tpr\"] / audit[\"fpr\"]) * ((1 - audit[\"ppv\"])/(audit[\"ppv\"]))) ** -1\naudit[\"p\"] = audit[\"p\"].fillna(0)\naudit\nprint(audit)\n\n\n          race  accuracy       ppv       tpr       fpr       fnr         p\n0        White  0.824338  0.802492  0.869107  0.222158  0.130893  0.509466\n3        Black  0.798479  0.752525  0.889552  0.264865  0.110448  0.475177\n7  N. American  0.843750  0.769001  0.871622  0.214385  0.128378  0.450190\n6         SPAA  1.000000  0.739030  0.874317  0.267139  0.125683  0.463878\n4        Asian  0.821859  0.807588  0.901664  0.283433  0.098336  0.568847\n5          NPI  0.500000  0.000000  0.000000  0.000000  1.000000  0.000000\n1        Other  0.808511  0.000000  0.000000  0.000000  0.000000  0.000000\n2        Multi  0.824335  0.666667  1.000000  0.227273  0.000000  0.312500\n\n\nHere I plot the feasibility of FPR and FNR for Black and White groups.\n\n\nCode\nimport seaborn as sns\n\n# Filter to only include Black and White groups\nfiltered = audit[audit[\"race\"].isin([\"Black\", \"White\"])]\n\norange_color = \"#E69F00\"\nblack_color = \"#000000\"\n\n# A cleaner table\nfeasible = filtered[[\"race\", \"fpr\", \"fnr\", \"p\"]].copy() \nlines = []\n\n# Make fixed ppv based on the black ppv\nfixed_ppv = filtered.loc[filtered[\"race\"] == \"Black\", \"ppv\"].values[0]\nfnr_range = np.linspace(0, 1, 100)\n\n# Compute feasible FPR for different FNR values\nfor i, row in feasible.iterrows():\n    race = row[\"race\"]\n    p = row[\"p\"]  \n    \n    fprs = (p / (1 - p)) * ((1 - fixed_ppv) / fixed_ppv) * (1 - fnr_range)\n\n    for fnr, fpr in zip(fnr_range, fprs):\n        lines.append({\"race\": race, \"fnr\": fnr, \"fpr\": fpr})\n\nlines_df = pd.DataFrame(lines)\n\nplt.figure(figsize=(7, 5))\nsns.set_style(\"whitegrid\")\n\n# Plot observed (fnr, fpr)\nfor i, row in feasible.iterrows():\n    color = orange_color if row[\"race\"] == \"White\" else black_color\n    plt.scatter(row[\"fnr\"], row[\"fpr\"], color=color)\n\n# Plot feasible (fnr, fpr) line\nfor race, color in zip([\"White\", \"Black\"], [orange_color, black_color]):\n    line = lines_df[lines_df[\"race\"] == race]\n    plt.plot(line[\"fnr\"], line[\"fpr\"], color=color)\n\nplt.xlabel(\"False Negative Rate\")\nplt.ylabel(\"False Positive Rate\")\nplt.title(\"Feasible (FNR, FPR) combinations\")\nplt.show()\n\n\n\n\n\n\n\n\n\nBased on this plot, to get equal false positive rates we would need to reduce \\(\\mathrm{FNR}_w\\) by about 0.04.\n\n\n\n\n\nAdapted code from Professor Phil Chodrow at Middlebury College in his class CSCI 0451: Machine Learning."
  },
  {
    "objectID": "posts/audit/index.html#abstract",
    "href": "posts/audit/index.html#abstract",
    "title": "Auditing Bias",
    "section": "",
    "text": "My goal was to make a predicition of employment status based on various demographic excluding race using a subset of data from the American Community Service focused on Massachusetts residents in 2023. Based on the data of the 58,500 residents, only half were employed. Most of the time men, people without disabilities, and people who born abroad or with no citizensip had higher proportions of employment. The model I used was sklearns Decision Tree Classifier because results are easy to interpret. I tuned complexity by I using GridSearchCV which cross-validated that the best depth out of the numbers I provided was 10 which overall accuracy 0.82. The different group accuracies weren‚Äôt that much different. Auditing my model showed that white people lead in PPV and FNR while Asians lead in TPR and FPR rates. In these summary I left races 5 and 6 because their data often had many missing values. Based on those values, my model failed approximate error balance and statistical parity but satisfied calibration. The plot that used the fixed PPV values and p values to graph feasible FPR and FNR combinations between Black and White residents.\n\n\nCode\nfrom folktables import ACSDataSource, ACSEmployment, BasicProblem, adult_filter\nimport numpy as np\n\nSTATE = \"MA\" \n\ndata_source = ACSDataSource(survey_year='2023', # Get more recent data\n                            horizon='1-Year', \n                            survey='person')\n\nacs_data = data_source.get_data(states=[STATE], download=True)\n\nacs_data.head()\n\n\n\n\n\n\n\n\n\nRT\nSERIALNO\nDIVISION\nSPORDER\nPUMA\nREGION\nSTATE\nADJINC\nPWGTP\nAGEP\n...\nPWGTP71\nPWGTP72\nPWGTP73\nPWGTP74\nPWGTP75\nPWGTP76\nPWGTP77\nPWGTP78\nPWGTP79\nPWGTP80\n\n\n\n\n0\nP\n2023GQ0000077\n1\n1\n503\n1\n25\n1019518\n11\n89\n...\n12\n13\n13\n13\n13\n13\n13\n12\n13\n13\n\n\n1\nP\n2023GQ0000098\n1\n1\n613\n1\n25\n1019518\n11\n20\n...\n3\n4\n2\n20\n13\n9\n2\n20\n13\n2\n\n\n2\nP\n2023GQ0000109\n1\n1\n613\n1\n25\n1019518\n80\n68\n...\n28\n34\n78\n73\n34\n68\n82\n15\n17\n79\n\n\n3\nP\n2023GQ0000114\n1\n1\n801\n1\n25\n1019518\n69\n21\n...\n60\n74\n161\n11\n127\n57\n11\n12\n11\n12\n\n\n4\nP\n2023GQ0000135\n1\n1\n1201\n1\n25\n1019518\n27\n84\n...\n27\n28\n27\n29\n27\n29\n27\n27\n28\n27\n\n\n\n\n5 rows √ó 287 columns\n\n\n\n\n\nCode\n# No RELP avaiable \npossible_features=['AGEP', 'SCHL', 'MAR', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC', 'NATIVITY', 'DEAR', 'DEYE', 'DREM', 'SEX', 'RAC1P', 'ESR']\nacs_data[possible_features].head()\n\n\n\n\n\n\n\n\n\nAGEP\nSCHL\nMAR\nDIS\nESP\nCIT\nMIG\nMIL\nANC\nNATIVITY\nDEAR\nDEYE\nDREM\nSEX\nRAC1P\nESR\n\n\n\n\n0\n89\n16.0\n2\n1\nNaN\n1\n1.0\n4.0\n3\n1\n1\n1\n1.0\n2\n1\n6.0\n\n\n1\n20\n16.0\n5\n2\nNaN\n1\n1.0\n4.0\n1\n1\n2\n2\n2.0\n1\n9\n6.0\n\n\n2\n68\n18.0\n5\n1\nNaN\n1\n1.0\n4.0\n1\n1\n1\n2\n2.0\n1\n1\n6.0\n\n\n3\n21\n19.0\n5\n2\nNaN\n1\n1.0\n4.0\n1\n1\n2\n2\n2.0\n2\n1\n1.0\n\n\n4\n84\n16.0\n1\n1\nNaN\n1\n3.0\n4.0\n3\n1\n2\n1\n1.0\n2\n1\n6.0"
  },
  {
    "objectID": "posts/audit/index.html#model",
    "href": "posts/audit/index.html#model",
    "title": "Auditing Bias",
    "section": "",
    "text": "Adapted from Professor Phil‚Äôs code.\n\n\nCode\nfeatures_to_use = [f for f in possible_features if f not in [\"ESR\", \"RAC1P\"]]\n\n\n\n\nCode\nEmploymentProblem = BasicProblem(\n    features=features_to_use,\n    target='ESR',\n    target_transform=lambda x: x == 1,\n    group='RAC1P',\n    preprocess=lambda x: x,\n    postprocess=lambda x: np.nan_to_num(x, -1),\n)\n\nfeatures, label, group = EmploymentProblem.df_to_numpy(acs_data)\n\nfor obj in [features, label, group]:\n  print(obj.shape)\n\n\n(73126, 14)\n(73126,)\n(73126,)\n\n\n\n\nCode\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n    features, label, group, test_size=0.2, random_state=0)\n\n\n\n\nCode\n\nimport pandas as pd\ndf = pd.DataFrame(X_train, columns = features_to_use)\ndf[\"race\"] = group_train\ndf[\"label\"] = y_train\n\n\nThis method allows the conversion of race numbers to more helpful categorical labels. Some of them have been shortened because they were too long. 1. SPAA - ‚ÄúAmerican Indian and Alaska Native tribes specified, or American Indian or AlaskaNative, not specified and no other races‚Äù. 2. NPI - Native Hawaiian and Other Pacific Islander alone\n\n\nCode\ndef convert_race(df: pd.DataFrame):\n    df = df.sort_values(by='race')\n    df['race'] = df['race'].replace({1: \"White\", 2: \"Black\", 3: \"N. American\", 4:\"N. Alaskan\", \n                        5:\"SPAA\", \n                        6:'Asian', 7: 'NPI', 8:'Other', 9: 'Multi'})\n\n    df['race'] = pd.Categorical(df['race'])\n    return df\n    \n\n\n\n\n\n\n\nCode\n# Save to the original for calculations and copying\nrelabeled = df.copy() \nrelabeled = convert_race(relabeled)\nrelabeled\n\n\n\n\n\n\n\n\n\nAGEP\nSCHL\nMAR\nDIS\nESP\nCIT\nMIG\nMIL\nANC\nNATIVITY\nDEAR\nDEYE\nDREM\nSEX\nrace\nlabel\n\n\n\n\n0\n69.0\n19.0\n1.0\n2.0\n0.0\n1.0\n1.0\n4.0\n1.0\n1.0\n2.0\n2.0\n2.0\n2.0\nWhite\nFalse\n\n\n35997\n12.0\n9.0\n5.0\n2.0\n1.0\n1.0\n1.0\n0.0\n1.0\n1.0\n2.0\n2.0\n2.0\n2.0\nWhite\nFalse\n\n\n35999\n70.0\n24.0\n1.0\n2.0\n0.0\n1.0\n1.0\n4.0\n2.0\n1.0\n2.0\n2.0\n2.0\n1.0\nWhite\nTrue\n\n\n36000\n74.0\n22.0\n1.0\n2.0\n0.0\n1.0\n1.0\n4.0\n2.0\n1.0\n2.0\n2.0\n2.0\n1.0\nWhite\nFalse\n\n\n36001\n68.0\n23.0\n2.0\n2.0\n0.0\n1.0\n1.0\n4.0\n1.0\n1.0\n2.0\n2.0\n2.0\n2.0\nWhite\nTrue\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n51260\n6.0\n3.0\n5.0\n2.0\n2.0\n1.0\n1.0\n0.0\n1.0\n1.0\n2.0\n2.0\n2.0\n2.0\nMulti\nFalse\n\n\n51257\n7.0\n4.0\n5.0\n2.0\n7.0\n1.0\n1.0\n0.0\n1.0\n1.0\n2.0\n2.0\n2.0\n2.0\nMulti\nFalse\n\n\n5335\n14.0\n11.0\n5.0\n2.0\n3.0\n1.0\n1.0\n0.0\n3.0\n1.0\n2.0\n2.0\n2.0\n1.0\nMulti\nFalse\n\n\n34217\n18.0\n14.0\n5.0\n2.0\n0.0\n1.0\n1.0\n4.0\n1.0\n1.0\n2.0\n2.0\n2.0\n2.0\nMulti\nFalse\n\n\n40473\n18.0\n18.0\n5.0\n2.0\n0.0\n1.0\n3.0\n4.0\n4.0\n1.0\n2.0\n2.0\n2.0\n1.0\nMulti\nTrue\n\n\n\n\n58500 rows √ó 16 columns\n\n\n\n\nThe number of indiviuals in this dataframe are:\n\n\n\nCode\nprint(\"The number of indiviuals in this df are\", df.shape[0])\n\n\nThe number of indiviuals in this df are 58500\n\n\n\nThe proportion of employed individuals are:\n\n\n\nCode\nemp = df[df['label'] == True][[\"label\"]].size # 29703\ntotal = df['label'].size # 58500\nemp_prop = emp / total\nprint(\"The proportion of employed indiviuals are\", emp_prop)\n\n\nThe proportion of employed indiviuals are 0.5077435897435898\n\n\n\nThe population of each group is:\n\n\n\nCode\nrelabeled.groupby('race')[['label']].aggregate('sum')\n\n\n\n\n\n\n\n\n\nlabel\n\n\nrace\n\n\n\n\n\nAsian\n2399\n\n\nBlack\n1529\n\n\nMulti\n2478\n\n\nN. American\n52\n\n\nNPI\n15\n\n\nOther\n1284\n\n\nSPAA\n26\n\n\nWhite\n21920\n\n\n\n\n\n\n\nBased on this, I might consider whether groups with less than 30 labels provide an adequate sample size.\n\nThe proportion of employed people in each group are:\n\n\n\nCode\nrelabeled.groupby('race')[['label']].aggregate('mean')\n\n\n\n\n\n\n\n\n\nlabel\n\n\nrace\n\n\n\n\n\nAsian\n0.540315\n\n\nBlack\n0.473668\n\n\nMulti\n0.456270\n\n\nN. American\n0.530612\n\n\nNPI\n0.625000\n\n\nOther\n0.486364\n\n\nSPAA\n0.520000\n\n\nWhite\n0.514687\n\n\n\n\n\n\n\n\nIntersectional Trends\n\n\n\nCode\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nfig, ax = plt.subplots(1, 2, figsize = (14, 4))\n\ncolors = [\"#1f77b4\", \"#ff7f0e\"]\nplt1 = sns.barplot(relabeled, x = \"race\", y = \"label\", hue=\"SEX\", palette=colors, ax=ax[0])\nplt1.set_xlabel(\"Race\")\nplt1.set_ylabel(\"Employment\")\nhandles, _ = plt1.get_legend_handles_labels()\nplt1.legend(handles=handles, title='Sex', labels=['Male', 'Female'])\n\nplt2 = sns.barplot(relabeled, x = \"race\", y = \"label\", hue=\"DIS\", palette=colors, ax=ax[1])\nplt2.set_xlabel(\"Race\")\nplt2.set_ylabel(\"Employment\")\nhandles, _ = plt2.get_legend_handles_labels()\nplt2.legend(handles=handles, title='Disability', labels=['Has disability', 'No disability'])\nplt.show()\n\n\n\n\n\n\n\n\n\nIn these graphs, we observe the intersectionality of employment rates based on gender and disability status. Generally, men and individuals without disabilities tend to be more likely to secure jobs. Several factors contribute to this disparity. For one, women and people with disabilities often face discrimination from employers. Additionally, the number of applicants from these groups could also play a role; even though more women are entering the workforce, many continue to take on childcare responsibilities at home. Moreover, ‚Äúdisability‚Äù encompasses a wide range of conditions, making it difficult to determine which individuals are capable of working and which are not. This uncertainty likely contributes to the lower employment rates among these groups. Interestingly, it‚Äôs worth noting that for Black Americans, Native Americans, and SPAA, there are more women employed than men.In this we see intersectionality between employment based on the sex of the person or whether they have a disability. As we can see in both graphs generally male and able bodied people are more likely to be employed. Multiple factors can contribute to this desparity. One is that women and people with disabilities are discriminated against by employers. Another is also considering how many of them are applying for jobs. For women, even with more of them joining the workforce, they may be more likely to doing childcare at home. Because disabilites is such a broad it‚Äôs hard which may be capable of working and those that aren‚Äôt. This probably a big factor why relatively few are employed. Something I noticed is that for Black Americans, Native Americans and SPAA more females are employed than males.\n\n\nCode\nplt3 = sns.barplot(relabeled, x = \"race\", y = \"label\", hue=\"CIT\")\nplt3.set_xlabel(\"Race\")\nplt3.set_ylabel(\"Employment\")\nhandles, _ = plt3.get_legend_handles_labels()\nstatus = ['Born in US', 'Born in US Territories', 'Born Abroad', 'US by naturalization', 'Not a citizen']\nplt3.legend(handles=handles, title='Citizenship', labels=status, loc='center left', bbox_to_anchor=(1, 0.5))\nplt.show()\n\n\n\n\n\n\n\n\n\nThis graph shows that individuals born in the U.S. or its territories have a lower percentage of employment compared to those born abroad or through naturalization. I suspect this may be due to the smaller population size and the fact that immigrants often come with specific job opportunities in mind.\n\n\n\nThe decision tree classifier was one of the recommedations given by the professor and scikit-learn said the results are easy to interpret. In order to find the best depth for the model training, I used GridSearchCV which cross validated the best parameters to use.\n\n\nCode\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix\n\nparam_grid = {\n    'max_depth': [1, 3, 5, 10]\n}\n\nmodel = DecisionTreeClassifier() \ngrid = GridSearchCV(model, param_grid, scoring=\"accuracy\")\ngrid.fit(X_train, y_train)\n\nprint(\"Best params\", grid.best_params_)\n\nbest_dtree = grid.best_estimator_\n\nbest_dtree.predict(X_train)\nbest_dtree.score(X_train, y_train)\n\n\nBest params {'max_depth': 10}\n\n\n0.8346666666666667\n\n\nThe best depth was 10 and gave us a solid accuracy.\n\n\n\n\n\nCode\npred = best_dtree.predict(X_test)\nscore = best_dtree.score(X_test, y_test)\n\nprint(\"Test score\", score)\n\n\nTest score 0.821892520169561"
  },
  {
    "objectID": "posts/audit/index.html#bias-audit",
    "href": "posts/audit/index.html#bias-audit",
    "title": "Auditing Bias",
    "section": "",
    "text": "The overall accuracy:\n\n\nCode\n(pred == y_test).mean()\n\n\nnp.float64(0.821892520169561)\n\n\nHere we calculate the PPV, the false negative and false positive rate\n\n\nCode\ntn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n\nppv = tp / (tp + fp)\nfnr = fn / (fn + tp)\nfpr = tp / (tp + tn)\n\nprint(\"Overall PPV:\", ppv)\nprint(\"Overall false negative rate:\", fnr)\nprint(\"Overall false positive rate:\", fpr)\n\n\nOverall PPV: 0.7938385705483673\nOverall false negative rate: 0.12639001898562516\nOverall false positive rate: 0.5358955161800183\n\n\nBased on this the model is pretty good at predicting who‚Äôs not employed but seems to overestimate the amount of people employed.\n\n\n\nThis is the accuracy by group:\n\n\nCode\ngroups = df[\"race\"].unique() # Need race as numbers in order to compare with group_test\naudit = pd.DataFrame(groups, columns=[\"race\"])\n\naccuracies = []\nfor group in groups:\n   accuracy = (pred == y_test)[group_test == group].mean()\n   accuracies.append(accuracy)\n\naudit[\"accuracy\"] = accuracies\naudit = convert_race(audit)\naudit\n\n\n\n\n\n\n\n\n\nrace\naccuracy\n\n\n\n\n0\nWhite\n0.824150\n\n\n3\nBlack\n0.799747\n\n\n7\nN. American\n0.812500\n\n\n6\nSPAA\n1.000000\n\n\n4\nAsian\n0.821859\n\n\n5\nNPI\n0.500000\n\n\n1\nOther\n0.807092\n\n\n2\nMulti\n0.825095\n\n\n\n\n\n\n\nBasides NPI and SPAA, the accuracies are rather similar to each other.\nThis is the PPV, the false negative and false positive rate by group:\n\n\nCode\nppvs = []\ntprs = []\nfnrs = []\nfprs = []\n\nfor group in groups:\n    tp = int(0)\n    fp = int(0)\n    tn = int(0)\n    fn = int(0)\n    for n, m, grp in zip(y_test, pred, group_test):\n        if(grp == group):\n            if m == n:\n                if n == True:\n                    tp += 1\n                if n == False:\n                    tn += 1\n            if m != n:\n                if n == True:\n                    fn += 1\n                if n == False:\n                    fp += 1\n    ppv = tp / (tp + fp) if (tp + fp) &gt; 0 else 0\n    ppvs.append(ppv)\n    fnr = fn / (fn + tp)  if (fn + tp) &gt; 0 else 0\n    fnrs.append(fnr)\n    fpr = fp / (fp + tn) if (fp + tn) &gt; 0 else 0 \n    fprs.append(fpr)\n    tpr = tp / (tp + fn) if (tp + fn) &gt; 0 else 0\n    tprs.append(tpr)\n    \n\naudit[\"ppv\"] = ppvs\naudit[\"tpr\"] = tprs\naudit[\"fpr\"] = fprs\naudit[\"fnr\"] = fnrs\naudit\n\n\n\n\n\n\n\n\n\nrace\naccuracy\nppv\ntpr\nfpr\nfnr\n\n\n\n\n0\nWhite\n0.824150\n0.802322\n0.868922\n0.222350\n0.131078\n\n\n3\nBlack\n0.799747\n0.750630\n0.889552\n0.267568\n0.110448\n\n\n7\nN. American\n0.812500\n0.769345\n0.873311\n0.214385\n0.126689\n\n\n6\nSPAA\n1.000000\n0.739631\n0.877049\n0.267139\n0.122951\n\n\n4\nAsian\n0.821859\n0.807588\n0.901664\n0.283433\n0.098336\n\n\n5\nNPI\n0.500000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\n1\nOther\n0.807092\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n2\nMulti\n0.825095\n0.625000\n1.000000\n0.272727\n0.000000\n\n\n\n\n\n\n\n\n\n\nUsing code adapted from from Machine Learning Master and sklearn documentation, I used a sci-kit learn‚Äôs calibration curve to diagnose the calibration:\n\n\nCode\nfrom sklearn.calibration import calibration_curve \n\ny_prob = best_dtree.predict_proba(X_test)[:, 1] # Gets the probability of positive values\nprob_true, prob_pred = calibration_curve(y_test, y_prob, n_bins=10)\n\navgs = []\nactuals = []\nfor group in groups:\n    # P(Y = 1 | S = {0,1}, R = r) \n    avg_pred_prob = y_prob[group_test == group].mean()\n    avgs.append(avg_pred_prob)\n    actual_employment_rate = (y_test == 1)[group_test == group].mean()\n    actuals.append(actual_employment_rate)\n\ncalibrate= pd.DataFrame(groups, columns=[\"race\"])\ncalibrate[\"employed\"] = actuals\ncalibrate[\"avg_predicted_probs\"] = avgs\nprint(calibrate)\n\ncal = plt\ncal.plot([0, 1], [0, 1], linestyle='--') # Actual values\ncal.plot(prob_pred, prob_true, marker='.') # Predicted values\ncal.title(\"Model Calibration\")\ncal.xlabel(\"Average Probability\")\ncal.ylabel(\"Fraction of Positive\")\ncal.show()\n\n\n   race  employed  avg_predicted_probs\n0     1  0.509466             0.510189\n1     8  0.475177             0.486277\n2     9  0.450190             0.449267\n3     2  0.463878             0.482898\n4     6  0.568847             0.571642\n5     7  0.500000             0.336508\n6     5  0.000000             0.094724\n7     3  0.312500             0.424606\n\n\n\n\n\n\n\n\n\nThe above graph and table shows that my model is nearly calibrated, meaning that the model usually predicts probabilites that are the same as the real probabilities.\nApproximate error balance rate: Looking at the table above we can see that the model does not meet approximate error rate balance for groups. The groups differ in true and false positive rates. The code below double checks.\n\n\nCode\nfor i, row1 in audit.iterrows():\n    equal = True;\n    race1 = row1['race']\n    tpr1 = row1['tpr']\n    fpr1 = row1['fpr']\n    for j, row2 in audit.iterrows():\n        race2 = row2['race']\n        tpr2 = row2['tpr']\n        fpr2 = row2['fpr']\n        if(tpr1 != tpr2 or fpr1 != fpr2):\n            equal = False\n            print(f\"{race1} did not have an equal TPR or FPR as {race2}\")\n            break\n    if(equal != True):\n        break\n\n\nWhite did not have an equal TPR or FPR as Black\n\n\nStatistical parity:\n\n\nCode\nprobs = []\nfor group in groups:\n    prob = (pred == True)[group_test == group].mean()\n    probs.append(prob)\n\nparity= pd.DataFrame(groups, columns=[\"race\"])\nparity[\"prob\"] = probs\nparity\n\n\n\n\n\n\n\n\n\nrace\nprob\n\n\n\n\n0\n1\n0.551757\n\n\n1\n8\n0.563121\n\n\n2\n9\n0.511027\n\n\n3\n2\n0.550063\n\n\n4\n6\n0.635112\n\n\n5\n7\n0.000000\n\n\n6\n5\n0.000000\n\n\n7\n3\n0.500000\n\n\n\n\n\n\n\nThe model does not meet statistical parity which means not all groups have an equal change of achieving favorable odds. Therefore we can assume that the probability of predicting employment is not independent of race.\n\n\n\nAdd prevalance to data table\n\n\nCode\naudit[\"p\"] = (1 + (audit[\"tpr\"] / audit[\"fpr\"]) * ((1 - audit[\"ppv\"])/(audit[\"ppv\"]))) ** -1\naudit[\"p\"] = audit[\"p\"].fillna(0)\naudit\nprint(audit)\n\n\n          race  accuracy       ppv       tpr       fpr       fnr         p\n0        White  0.824338  0.802492  0.869107  0.222158  0.130893  0.509466\n3        Black  0.798479  0.752525  0.889552  0.264865  0.110448  0.475177\n7  N. American  0.843750  0.769001  0.871622  0.214385  0.128378  0.450190\n6         SPAA  1.000000  0.739030  0.874317  0.267139  0.125683  0.463878\n4        Asian  0.821859  0.807588  0.901664  0.283433  0.098336  0.568847\n5          NPI  0.500000  0.000000  0.000000  0.000000  1.000000  0.000000\n1        Other  0.808511  0.000000  0.000000  0.000000  0.000000  0.000000\n2        Multi  0.824335  0.666667  1.000000  0.227273  0.000000  0.312500\n\n\nHere I plot the feasibility of FPR and FNR for Black and White groups.\n\n\nCode\nimport seaborn as sns\n\n# Filter to only include Black and White groups\nfiltered = audit[audit[\"race\"].isin([\"Black\", \"White\"])]\n\norange_color = \"#E69F00\"\nblack_color = \"#000000\"\n\n# A cleaner table\nfeasible = filtered[[\"race\", \"fpr\", \"fnr\", \"p\"]].copy() \nlines = []\n\n# Make fixed ppv based on the black ppv\nfixed_ppv = filtered.loc[filtered[\"race\"] == \"Black\", \"ppv\"].values[0]\nfnr_range = np.linspace(0, 1, 100)\n\n# Compute feasible FPR for different FNR values\nfor i, row in feasible.iterrows():\n    race = row[\"race\"]\n    p = row[\"p\"]  \n    \n    fprs = (p / (1 - p)) * ((1 - fixed_ppv) / fixed_ppv) * (1 - fnr_range)\n\n    for fnr, fpr in zip(fnr_range, fprs):\n        lines.append({\"race\": race, \"fnr\": fnr, \"fpr\": fpr})\n\nlines_df = pd.DataFrame(lines)\n\nplt.figure(figsize=(7, 5))\nsns.set_style(\"whitegrid\")\n\n# Plot observed (fnr, fpr)\nfor i, row in feasible.iterrows():\n    color = orange_color if row[\"race\"] == \"White\" else black_color\n    plt.scatter(row[\"fnr\"], row[\"fpr\"], color=color)\n\n# Plot feasible (fnr, fpr) line\nfor race, color in zip([\"White\", \"Black\"], [orange_color, black_color]):\n    line = lines_df[lines_df[\"race\"] == race]\n    plt.plot(line[\"fnr\"], line[\"fpr\"], color=color)\n\nplt.xlabel(\"False Negative Rate\")\nplt.ylabel(\"False Positive Rate\")\nplt.title(\"Feasible (FNR, FPR) combinations\")\nplt.show()\n\n\n\n\n\n\n\n\n\nBased on this plot, to get equal false positive rates we would need to reduce \\(\\mathrm{FNR}_w\\) by about 0.04."
  },
  {
    "objectID": "posts/audit/index.html#acknowledgements",
    "href": "posts/audit/index.html#acknowledgements",
    "title": "Auditing Bias",
    "section": "",
    "text": "Adapted code from Professor Phil Chodrow at Middlebury College in his class CSCI 0451: Machine Learning."
  },
  {
    "objectID": "posts/descent/index.html",
    "href": "posts/descent/index.html",
    "title": "Overfitting and Double Descents",
    "section": "",
    "text": "In this blog post, I explore the deep learning phenomenon of overfitting and the resulting double descent. First, I created a linear regression model and an overparameterized optimizer that could fit the model to the data. For the first visualization, I tested model predictions after fitting it to the data. Then I used my model to calculate the number of corruptions in an image. To measure model performance, I calculated mean squared error (MSE) and graphed how it changes as the number of features increased. In this visualization, I observed double descent on the testing set. I found that the optimal number of features was beyond the interpolation threshold at 192 features with an MSE of 301s.\n\n\nCode\n%load_ext autoreload\n%autoreload 2\n\n\n\n\n\n\nCode\nimport torch\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef sig(x): \n    return 1/(1+torch.exp(-x))\n\ndef square(x): \n    return x**2\n\nclass RandomFeatures:\n    \"\"\"\n    Random sigmoidal feature map. This feature map must be \"fit\" before use, like this: \n\n    phi = RandomFeatures(n_features = 10)\n    phi.fit(X_train)\n    X_train_phi = phi.transform(X_train)\n    X_test_phi = phi.transform(X_test)\n\n    model.fit(X_train_phi, y_train)\n    model.score(X_test_phi, y_test)\n\n    It is important to fit the feature map once on the training set and zero times on the test set. \n    \"\"\"\n\n    def __init__(self, n_features, activation = sig):\n        self.n_features = n_features\n        self.u = None\n        self.b = None\n        self.activation = activation\n\n    def fit(self, X):\n        self.u = torch.randn((X.size()[1], self.n_features), dtype = torch.float64)\n        self.b = torch.rand((self.n_features), dtype = torch.float64) \n\n    def transform(self, X: torch.Tensor):\n        return self.activation(X @ self.u + self.b)\n\n\n\n\n\n\n\n\n\nCode\nfrom MyLinearRegression import MyLinearRegression, OverParameterizedLinearRegressionOptimizer\n\nX = torch.tensor(np.linspace(-3, 3, 100).reshape(-1, 1), dtype = torch.float64)\ny = X**4 - 4*X + torch.normal(0, 5, size=X.shape)\n\nphi = RandomFeatures(n_features= 100)\nphi.fit(X)\nX_train_features = phi.transform(X)\n\nLR = MyLinearRegression()\nopt = OverParameterizedLinearRegressionOptimizer(LR)\nopt.fit(X_train_features, y)\npred = LR.predict(X_train_features)\nline = pred.numpy() \n\nplt.scatter(X, y, color='darkgrey', label='Data')\nplt.plot(X, line, color='lightblue', label=\"Predictions\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nI tested the linear regression model on 1D data. The model seemed to produce accurate predictions.\n\n\n\nCells 5 to 9 were adapted from Prof.¬†Phil‚Äôs code as background for the corrupted flower images.\n\n\nCode\nfrom sklearn.datasets import load_sample_images\nfrom scipy.ndimage import zoom\n\ndataset = load_sample_images()     \nX = dataset.images[1]\nX = zoom(X, .2) # decimate resolution\nX = X.sum(axis = 2)\nX = X.max() - X \nX = X / X.max()\nflower = torch.tensor(X, dtype = torch.float64)\n\nfig, ax = plt.subplots(1, 1, figsize=(6, 6))\nax.imshow(flower)\noff = ax.axis(\"off\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\ndef corrupted_image(im, mean_patches = 5): \n    n_pixels = im.size()\n    num_pixels_to_corrupt = torch.round(mean_patches*torch.rand(1))\n    num_added = 0\n\n    X = im.clone()\n\n    for _ in torch.arange(num_pixels_to_corrupt.item()): \n        \n        try: \n            x = torch.randint(0, n_pixels[0], (2,))\n\n            x = torch.randint(0, n_pixels[0], (1,))\n            y = torch.randint(0, n_pixels[1], (1,))\n\n            s = torch.randint(5, 10, (1,))\n            \n            patch = torch.zeros((s.item(), s.item()), dtype = torch.float64) + 0.5\n\n            # place patch in base image X\n            X[x:x+s.item(), y:y+s.item()] = patch\n            num_added += 1\n\n            \n        except: \n            pass\n\n    return X, num_added\n\n\n\n\nCode\nX, y = corrupted_image(flower, mean_patches = 50)\nfig, ax = plt.subplots(1, 1, figsize=(6, 6))\nax.imshow(X.numpy(), vmin = 0, vmax = 1)\nax.set(title = f\"Corrupted Image: {y} patches\")\noff = plt.gca().axis(\"off\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nn_samples = 200\n\nX = torch.zeros((n_samples, flower.size()[0], flower.size()[1]), dtype = torch.float64)\ny = torch.zeros(n_samples, dtype = torch.float64)\nfor i in range(n_samples): \n    X[i], y[i] = corrupted_image(flower, mean_patches = 100)\n\n\n\n\nCode\nfrom sklearn.model_selection import train_test_split\n\nX = X.reshape(n_samples, -1)\n# X.reshape(n_samples, -1).size()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n\n\n\n\nHere I assess the performance of my model by calculating the mean squared error (MSE) and plotting it against the number of features for both training and testing sets.\n\n\nCode\nn_features = 200\n\ntrain_loss_vec = []\ntest_loss_vec = []\n\nn = X_train.size()[0] \n\n# Loop over different numbers of random features\nfor i in range(n_features):\n    # Initialize the random feature transformation\n    phi = RandomFeatures(n_features = i, activation = square)\n    phi.fit(X_train) # Fit the random features to the training data\n    \n    # Transform both training and test data using the fitted feature map\n    X_train_phi = phi.transform(X_train)\n    X_test_phi = phi.transform(X_test)\n    \n    # Initialize the linear regression model and optimizer\n    LR = MyLinearRegression()\n    opt = OverParameterizedLinearRegressionOptimizer(LR)\n    \n    # Fit the model to the transformed training data\n    opt.fit(X_train_phi, y_train)\n    \n    # Compute training and testing loss (MSE)\n    train_loss = LR.loss(X_train_phi, y_train).item()\n    test_loss = LR.loss(X_test_phi, y_test).item()\n    \n    # Append the losses to the respective lists\n    train_loss_vec.append(train_loss)\n    test_loss_vec.append(test_loss)\n\n\n\n\nCode\nfig, ax = plt.subplots(1, 2, figsize=(14, 6))  \n\n# Plot training loss\nax[0].scatter(range(n_features), train_loss_vec, color='darkgrey')\nax[0].set_yscale('log')\nax[0].axvline(n, color='black', linewidth = 1)\nax[0].set_xlabel(\"Number of features\")\nax[0].set_ylabel(\"Mean Squared Error (Training)\")\n\n# Plot testing loss\nax[1].scatter(range(n_features), test_loss_vec, color='darkred')\nax[1].set_yscale('log')\nax[1].axvline(n, color='black', linewidth = 1)\nax[1].set_xlabel(\"Number of features\")\nax[1].set_ylabel(\"Mean Squared Error (Testing)\")\n\nplt.tight_layout()\nplt.show()\n\n# Find the best number of features with the lowest test loss\nbest_idx = torch.tensor(test_loss_vec).argmin().item() # convert vector to tensor and get index of minimum\nbest_features = best_idx + 1 \nbest_loss = test_loss_vec[best_idx]\n\nprint(f\"Lowest test loss: {best_loss:.4f} at {best_features} features.\")\n\n\n\n\n\n\n\n\n\nLowest test loss: 300.5068 at 192 features.\n\n\nFor the training data, I observed that as the number of features increased, the MSE decreased. In particular, at 100 features, which was the interpolation threshold, the MSE dropped dramatically from approximately \\(10^{-4}\\) to \\(10^{-22}\\).\nFor the testing data, I observed that the MSE decreased as the number of features increased, but then increased again after a certain point, indicating overfitting. Following the interpolation threshold, the error started to decrease again. The best error rate for the testing set was around 301 at 192 features, which was after the interpolation threshold.\n\n\n\n\nMy most important finding was that my model does achieve double descent. For training loss, the MSE continued to trend downward as the number of features increased. For testing loss, there was an initial decrease in loss, but then the loss rose when it reached near the interpolation threshold due to overfitting. After the interpolation threshold, the loss decreased again, reaching a second minimum.\nBased on my results, 192 features achieved the lowest MSE of 301."
  },
  {
    "objectID": "posts/descent/index.html#abstract",
    "href": "posts/descent/index.html#abstract",
    "title": "Overfitting and Double Descents",
    "section": "",
    "text": "In this blog post, I explore the deep learning phenomenon of overfitting and the resulting double descent. First, I created a linear regression model and an overparameterized optimizer that could fit the model to the data. For the first visualization, I tested model predictions after fitting it to the data. Then I used my model to calculate the number of corruptions in an image. To measure model performance, I calculated mean squared error (MSE) and graphed how it changes as the number of features increased. In this visualization, I observed double descent on the testing set. I found that the optimal number of features was beyond the interpolation threshold at 192 features with an MSE of 301s.\n\n\nCode\n%load_ext autoreload\n%autoreload 2\n\n\n\n\n\n\nCode\nimport torch\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef sig(x): \n    return 1/(1+torch.exp(-x))\n\ndef square(x): \n    return x**2\n\nclass RandomFeatures:\n    \"\"\"\n    Random sigmoidal feature map. This feature map must be \"fit\" before use, like this: \n\n    phi = RandomFeatures(n_features = 10)\n    phi.fit(X_train)\n    X_train_phi = phi.transform(X_train)\n    X_test_phi = phi.transform(X_test)\n\n    model.fit(X_train_phi, y_train)\n    model.score(X_test_phi, y_test)\n\n    It is important to fit the feature map once on the training set and zero times on the test set. \n    \"\"\"\n\n    def __init__(self, n_features, activation = sig):\n        self.n_features = n_features\n        self.u = None\n        self.b = None\n        self.activation = activation\n\n    def fit(self, X):\n        self.u = torch.randn((X.size()[1], self.n_features), dtype = torch.float64)\n        self.b = torch.rand((self.n_features), dtype = torch.float64) \n\n    def transform(self, X: torch.Tensor):\n        return self.activation(X @ self.u + self.b)"
  },
  {
    "objectID": "posts/descent/index.html#testing-mylinearregression-model",
    "href": "posts/descent/index.html#testing-mylinearregression-model",
    "title": "Overfitting and Double Descents",
    "section": "",
    "text": "Code\nfrom MyLinearRegression import MyLinearRegression, OverParameterizedLinearRegressionOptimizer\n\nX = torch.tensor(np.linspace(-3, 3, 100).reshape(-1, 1), dtype = torch.float64)\ny = X**4 - 4*X + torch.normal(0, 5, size=X.shape)\n\nphi = RandomFeatures(n_features= 100)\nphi.fit(X)\nX_train_features = phi.transform(X)\n\nLR = MyLinearRegression()\nopt = OverParameterizedLinearRegressionOptimizer(LR)\nopt.fit(X_train_features, y)\npred = LR.predict(X_train_features)\nline = pred.numpy() \n\nplt.scatter(X, y, color='darkgrey', label='Data')\nplt.plot(X, line, color='lightblue', label=\"Predictions\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nI tested the linear regression model on 1D data. The model seemed to produce accurate predictions."
  },
  {
    "objectID": "posts/descent/index.html#corrupted-flower-images",
    "href": "posts/descent/index.html#corrupted-flower-images",
    "title": "Overfitting and Double Descents",
    "section": "",
    "text": "Cells 5 to 9 were adapted from Prof.¬†Phil‚Äôs code as background for the corrupted flower images.\n\n\nCode\nfrom sklearn.datasets import load_sample_images\nfrom scipy.ndimage import zoom\n\ndataset = load_sample_images()     \nX = dataset.images[1]\nX = zoom(X, .2) # decimate resolution\nX = X.sum(axis = 2)\nX = X.max() - X \nX = X / X.max()\nflower = torch.tensor(X, dtype = torch.float64)\n\nfig, ax = plt.subplots(1, 1, figsize=(6, 6))\nax.imshow(flower)\noff = ax.axis(\"off\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\ndef corrupted_image(im, mean_patches = 5): \n    n_pixels = im.size()\n    num_pixels_to_corrupt = torch.round(mean_patches*torch.rand(1))\n    num_added = 0\n\n    X = im.clone()\n\n    for _ in torch.arange(num_pixels_to_corrupt.item()): \n        \n        try: \n            x = torch.randint(0, n_pixels[0], (2,))\n\n            x = torch.randint(0, n_pixels[0], (1,))\n            y = torch.randint(0, n_pixels[1], (1,))\n\n            s = torch.randint(5, 10, (1,))\n            \n            patch = torch.zeros((s.item(), s.item()), dtype = torch.float64) + 0.5\n\n            # place patch in base image X\n            X[x:x+s.item(), y:y+s.item()] = patch\n            num_added += 1\n\n            \n        except: \n            pass\n\n    return X, num_added\n\n\n\n\nCode\nX, y = corrupted_image(flower, mean_patches = 50)\nfig, ax = plt.subplots(1, 1, figsize=(6, 6))\nax.imshow(X.numpy(), vmin = 0, vmax = 1)\nax.set(title = f\"Corrupted Image: {y} patches\")\noff = plt.gca().axis(\"off\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nn_samples = 200\n\nX = torch.zeros((n_samples, flower.size()[0], flower.size()[1]), dtype = torch.float64)\ny = torch.zeros(n_samples, dtype = torch.float64)\nfor i in range(n_samples): \n    X[i], y[i] = corrupted_image(flower, mean_patches = 100)\n\n\n\n\nCode\nfrom sklearn.model_selection import train_test_split\n\nX = X.reshape(n_samples, -1)\n# X.reshape(n_samples, -1).size()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n\n\n\n\nHere I assess the performance of my model by calculating the mean squared error (MSE) and plotting it against the number of features for both training and testing sets.\n\n\nCode\nn_features = 200\n\ntrain_loss_vec = []\ntest_loss_vec = []\n\nn = X_train.size()[0] \n\n# Loop over different numbers of random features\nfor i in range(n_features):\n    # Initialize the random feature transformation\n    phi = RandomFeatures(n_features = i, activation = square)\n    phi.fit(X_train) # Fit the random features to the training data\n    \n    # Transform both training and test data using the fitted feature map\n    X_train_phi = phi.transform(X_train)\n    X_test_phi = phi.transform(X_test)\n    \n    # Initialize the linear regression model and optimizer\n    LR = MyLinearRegression()\n    opt = OverParameterizedLinearRegressionOptimizer(LR)\n    \n    # Fit the model to the transformed training data\n    opt.fit(X_train_phi, y_train)\n    \n    # Compute training and testing loss (MSE)\n    train_loss = LR.loss(X_train_phi, y_train).item()\n    test_loss = LR.loss(X_test_phi, y_test).item()\n    \n    # Append the losses to the respective lists\n    train_loss_vec.append(train_loss)\n    test_loss_vec.append(test_loss)\n\n\n\n\nCode\nfig, ax = plt.subplots(1, 2, figsize=(14, 6))  \n\n# Plot training loss\nax[0].scatter(range(n_features), train_loss_vec, color='darkgrey')\nax[0].set_yscale('log')\nax[0].axvline(n, color='black', linewidth = 1)\nax[0].set_xlabel(\"Number of features\")\nax[0].set_ylabel(\"Mean Squared Error (Training)\")\n\n# Plot testing loss\nax[1].scatter(range(n_features), test_loss_vec, color='darkred')\nax[1].set_yscale('log')\nax[1].axvline(n, color='black', linewidth = 1)\nax[1].set_xlabel(\"Number of features\")\nax[1].set_ylabel(\"Mean Squared Error (Testing)\")\n\nplt.tight_layout()\nplt.show()\n\n# Find the best number of features with the lowest test loss\nbest_idx = torch.tensor(test_loss_vec).argmin().item() # convert vector to tensor and get index of minimum\nbest_features = best_idx + 1 \nbest_loss = test_loss_vec[best_idx]\n\nprint(f\"Lowest test loss: {best_loss:.4f} at {best_features} features.\")\n\n\n\n\n\n\n\n\n\nLowest test loss: 300.5068 at 192 features.\n\n\nFor the training data, I observed that as the number of features increased, the MSE decreased. In particular, at 100 features, which was the interpolation threshold, the MSE dropped dramatically from approximately \\(10^{-4}\\) to \\(10^{-22}\\).\nFor the testing data, I observed that the MSE decreased as the number of features increased, but then increased again after a certain point, indicating overfitting. Following the interpolation threshold, the error started to decrease again. The best error rate for the testing set was around 301 at 192 features, which was after the interpolation threshold."
  },
  {
    "objectID": "posts/descent/index.html#discussion",
    "href": "posts/descent/index.html#discussion",
    "title": "Overfitting and Double Descents",
    "section": "",
    "text": "My most important finding was that my model does achieve double descent. For training loss, the MSE continued to trend downward as the number of features increased. For testing loss, there was an initial decrease in loss, but then the loss rose when it reached near the interpolation threshold due to overfitting. After the interpolation threshold, the loss decreased again, reaching a second minimum.\nBased on my results, 192 features achieved the lowest MSE of 301."
  },
  {
    "objectID": "projects/bank/bank_app.html",
    "href": "projects/bank/bank_app.html",
    "title": "Bank App",
    "section": "",
    "text": "This was my first project: a full-stack web application that simulates the functions of a bank website. The backend was built with Java Spring Boot and MongoDB as the database. The frontend uses React, with Axios as the API client between it and the local server."
  },
  {
    "objectID": "projects/bank/bank_app.html#overview",
    "href": "projects/bank/bank_app.html#overview",
    "title": "Bank App",
    "section": "",
    "text": "This was my first project: a full-stack web application that simulates the functions of a bank website. The backend was built with Java Spring Boot and MongoDB as the database. The frontend uses React, with Axios as the API client between it and the local server."
  },
  {
    "objectID": "projects/bank/bank_app.html#features",
    "href": "projects/bank/bank_app.html#features",
    "title": "Bank App",
    "section": "Features",
    "text": "Features\n\nProfile:\n\nUsername\nPassword\nBank accounts (Checking/Savings)\n\nBanking features:\n\nDeposit\nWithdraw\nTransfer\n\nPie chart representing the balance of each account\nTransaction history table and graph for each account\nDatabase for storing user information"
  },
  {
    "objectID": "projects/bank/bank_app.html#technologies",
    "href": "projects/bank/bank_app.html#technologies",
    "title": "Bank App",
    "section": "Technologies",
    "text": "Technologies\n\nFrontend\nReact, Bootstrap, Axios\n\n\nBackend\nJava, Spring Boot, MongoDB"
  },
  {
    "objectID": "projects/bank/bank_app.html#links",
    "href": "projects/bank/bank_app.html#links",
    "title": "Bank App",
    "section": "Links",
    "text": "Links\n\nüì¶ GitHub Repository\n\n\n\n\nBank App Main Page"
  },
  {
    "objectID": "projects/middhousing/middhousing.html",
    "href": "projects/middhousing/middhousing.html",
    "title": "MiddHousing",
    "section": "",
    "text": "MiddHousing is a web app that allows students to find accurate information about individual dorm rooms and rate rooms they have previously lived in. Students can also sort their searches based on specific preferences and view the campus map for specific locations."
  },
  {
    "objectID": "projects/middhousing/middhousing.html#app-description",
    "href": "projects/middhousing/middhousing.html#app-description",
    "title": "MiddHousing",
    "section": "",
    "text": "MiddHousing is a web app that allows students to find accurate information about individual dorm rooms and rate rooms they have previously lived in. Students can also sort their searches based on specific preferences and view the campus map for specific locations."
  },
  {
    "objectID": "projects/middhousing/middhousing.html#my-role",
    "href": "projects/middhousing/middhousing.html#my-role",
    "title": "MiddHousing",
    "section": "My Role",
    "text": "My Role\nI implemented both the main and dorm search bars, allowing users to view all dorms and filter by preferences. I also created the review functionality, enabling users to rate rooms out of five stars and write about their room experiences in a text box. Furthermore, I utilized the API to access backend information about rooms, such as size and room type. I also assisted in the development and testing of the Knex.js models."
  },
  {
    "objectID": "projects/middhousing/middhousing.html#features",
    "href": "projects/middhousing/middhousing.html#features",
    "title": "MiddHousing",
    "section": "Features",
    "text": "Features\n\nInteractive Leaflet map with campus map\nDorm and room search functionality\n\nFloor plans\nRoom pages\n\nReviews:\n\nRate rooms with stars\nText box for experiences\n\nProfile:\n\nUser name, email, and password\nSaved preferences and rooms\n\nPostgreSQL database for storing user information\nKnex.js for database queries\nGoogle Authentication system"
  },
  {
    "objectID": "projects/middhousing/middhousing.html#technologies",
    "href": "projects/middhousing/middhousing.html#technologies",
    "title": "MiddHousing",
    "section": "Technologies",
    "text": "Technologies\n\nFrontend\nReact, Bootstrap, Leaflet\n\n\nBackend\nKnex.js, Next.js, Docker"
  },
  {
    "objectID": "projects/middhousing/middhousing.html#links",
    "href": "projects/middhousing/middhousing.html#links",
    "title": "MiddHousing",
    "section": "Links",
    "text": "Links\n\nüì¶ GitHub Repository\n\n\n\n\nMiddHousing Main Page"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hello! I‚Äôm Emmanuel Towner, a computer science major at Middlebury College."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nMiddlebury College | Middlebury, VT\nBA in Computer Science | Sept 2021 ‚Äì Jan 2026"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About",
    "section": "Experience",
    "text": "Experience\nNatural Language Processing Course Grader\nMiddlebury College | Middlebury, VT | February 2025 ‚Äì May 2025\nSoftware Developer\nLigerBots | Newton, MA | September 2024 ‚Äì December 2024\nMachine Learning Research Assistant\nMiddlebury College | Middlebury, VT | June 2024 ‚Äì August 2024\nIntern\nNewton Housing Authority | Newton, MA | July 2021 ‚Äì August 2021"
  }
]