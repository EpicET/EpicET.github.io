[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hello! I’m Emmanuel Towner, a computer science major at Middlebury College. This site shows work from my courses and solo projects."
  },
  {
    "objectID": "posts/pneumonia/Final_Project_BP.html",
    "href": "posts/pneumonia/Final_Project_BP.html",
    "title": "Pnuemonia Detection",
    "section": "",
    "text": "Within our blog post, we created a neural network and implemented three different binary classifers trained on chest x-ray image data to detect pneumonia based on images. We used convolution layers to convert images into latent vectors by which we could feed into our various machine learning models: a transformer, an SVM, and a gradient boosting model. Through analyzing the accuracy of each model, we discovered a similar accuracy between the models of around 78% on testing data.\nHere is the link our code."
  },
  {
    "objectID": "posts/pneumonia/Final_Project_BP.html#abstract",
    "href": "posts/pneumonia/Final_Project_BP.html#abstract",
    "title": "Pnuemonia Detection",
    "section": "",
    "text": "Within our blog post, we created a neural network and implemented three different binary classifers trained on chest x-ray image data to detect pneumonia based on images. We used convolution layers to convert images into latent vectors by which we could feed into our various machine learning models: a transformer, an SVM, and a gradient boosting model. Through analyzing the accuracy of each model, we discovered a similar accuracy between the models of around 78% on testing data.\nHere is the link our code."
  },
  {
    "objectID": "posts/pneumonia/Final_Project_BP.html#introduction",
    "href": "posts/pneumonia/Final_Project_BP.html#introduction",
    "title": "Pnuemonia Detection",
    "section": "Introduction",
    "text": "Introduction\nWithin our project, we wanted to compare 3 seperate binary classification machine learning models, seeing which is best for an image classification task. Our project attempts to uncover what types of algorithms are best for binary image classification tasks using the pneumonia chest xray dataset, with our models being trained to discern pneumonia based on chest xray images only. This dataset demonstrates a case where finding the most optimal image classifcation algorithm is very important as it could result in saving a life. Our research could also inform which types of algorithms should be considered other important image classification tasks. We found five studies the explored other work done by scholars\nIn the study by M. R. Rahman, Islam, and Islam (2023), the researchers mainly focus on deep learning algorithms to tackle this same image classification task. Through their research, they discovered the MobileNet CCN gave the best accuracy on two datasets with values of 94.23% and 93.75%.\nIn another study titled Rajpurkar et al. (2017), researchers create their own CNN known as CheXNet that detects pneumonia as well as other chest related illnesses (fibrosis, hernia, etc.) that which accuracies ranging from 0.7 to 0.9. With such a large focus on CNNs for this image classification, ww wanted to determine if other kinds of algorithms good for binary classifcation could also be useful image classifiers.\nRecent research has expanded the exploration of deep learning architectures for pneumonia detection. For instance, a study by Singh, Thomas, and Jaiswal (2021) compared a custom convolutional neural network (CNN) and a multilayer perceptron (MLP) for classifying chest X-ray images. The CNN achieved an accuracy of 92.63%, outperforming the MLP’s 77.56%, highlighting the efficacy of CNNs in medical image classification tasks (Singh, Thomas, and Jaiswal (2021)).\nAnother study by T. Rahman et al. (2020) employed transfer learning with various pre-trained CNN models, including AlexNet, ResNet18, DenseNet201, and SqueezeNet, to classify chest X-ray images into normal, bacterial pneumonia, and viral pneumonia categories. Their approach achieved classification accuracies of 98% for normal vs. pneumonia, 95% for bacterial vs. viral pneumonia, and 93.3% for normal, bacterial, and viral pneumonia, demonstrating the potential of transfer learning in enhancing diagnostic performance.\nFurthermore, a study by Mabrouk et al. (2023) proposed an ensemble learning approach combining DenseNet169, MobileNetV2, and Vision Transformer models for pneumonia detection in chest X-ray images. Their ensemble model achieved an accuracy of 93.91% and an F1-score of 93.88%, indicating that integrating multiple deep learning architectures can improve classification performance."
  },
  {
    "objectID": "posts/pneumonia/Final_Project_BP.html#values-statement",
    "href": "posts/pneumonia/Final_Project_BP.html#values-statement",
    "title": "Pnuemonia Detection",
    "section": "Values Statement",
    "text": "Values Statement\nThe potential users of our project would be primary care clinicians and radiologists who must regularly discern chest-related illnesses through X-rays. These machine learning models trained on chest X-ray image data may help them make more informed decisions if they are trying to discern specifically pneumonia.\nI believe that our work contributes to AI researchers who are studying how to optimize for performance in image classification tasks, especially regarding medical concerns. If it can inform medical researchers on what machine learning models are best at medical image classification, they and their patients can also benefit from greater accuracy in detecting chest-related illnesses.\nBecause our models are quite poor at predicting images without pneumonia correctly, they could falsely flag patients as having pneumonia, which may lead them to incur unnecessary medical expenses. Based on the background of these patients, this could seriously affect patients who struggle financially.\nOur group personally enjoyed and had an interest in each of the algorithms that we worked on and took this project as a learning experience to expand our knowledge on what image vectorization and binary classification algorithms are out there and how they differ from what we have learned through our class assignments.\nBased on our experiments, we believe if our project can help inform image classification tasks, especially those in the medical field, then the world can become a better place by being able to help people detect illnesses earlier and possibly save lives."
  },
  {
    "objectID": "posts/pneumonia/Final_Project_BP.html#materials",
    "href": "posts/pneumonia/Final_Project_BP.html#materials",
    "title": "Pnuemonia Detection",
    "section": "Materials",
    "text": "Materials\nOur data comes from the Pneumonia Chest X-ray dataset on Kaggle. This data came from the Guangzhou Women and Children’s Medical Center. Samples were collected from patients and labels were created by pneumonia specialists, with two specialists making labels and then a third corroborating the label of normal or pneumonia. Our data lacks information regarding the severity or time span of the pneumonia for positive cases, meaning that the model has no clear way of understanding which X-rays should be encoded closer or further away from the normal cases. Additionally, the dataset has a 64% / 36% split, with the majority of X-rays containing positive cases of pneumonia. This bias happens to work out well for mitigating false negatives; however, it makes models have more difficulty understanding when an X-ray is normal."
  },
  {
    "objectID": "posts/pneumonia/Final_Project_BP.html#results",
    "href": "posts/pneumonia/Final_Project_BP.html#results",
    "title": "Pnuemonia Detection",
    "section": "Results",
    "text": "Results\n \nAs demonstrated before, the models contained much higher precision rates than recall in order to catch more of the positive pneumonia cases due to their costliness as compared to the costs associated with missing a normal case. Within the models, the transformer did the best, with the highest recall and precision of 93% and 41% respectively. The F-1 score of 57% suggests that the model was beginning to learn differences between the classes but still encountered much difficulty. This is also present in the 3-D PCA plot of the latent vectors where it becomes evident that many of the embeddings are caught in an overlapping region where both classes meet. The results suggest that the image embeddings need more fine-tuning to increase accuracy and recall."
  },
  {
    "objectID": "posts/pneumonia/Final_Project_BP.html#conclusions",
    "href": "posts/pneumonia/Final_Project_BP.html#conclusions",
    "title": "Pnuemonia Detection",
    "section": "Conclusions",
    "text": "Conclusions\nThe project accomplished many of the goals that we set out to accomplish during the duration of this project and also failed to meet others. We got a working convolutional neural network to embed the images and learn important features of those images. We correctly identify 93% of all pneumonia cases. On the other hand, we correctly identify less than half of all normal cases. This project demonstrates the difficulty of complex machine learning tasks without good computational resources. Running and auditing the CNN alone takes two hours per run with a GPU. Due to this constraint, we were unable to readily take advantage of all of the data available. Additionally, the binary classification models also took 5–15 minutes depending on the model. The most apparent hurdle in this project was creating a complex model while also being able to run it in a reasonable amount of time. Other pneumonia binary classification projects are able to get higher accuracy through the usage of pre-made ResNet models. These models are trained on millions of images and use residual connections to improve the performance of neural networks. If we had more time, we would do a more thorough error analysis of misclassified normal images to understand what features the model is missing and improve the architecture to capture that feature. Additionally, we would utilize more of the training data without run-time constraints and try adopting residual neural network architecture to improve performance."
  },
  {
    "objectID": "posts/pneumonia/Final_Project_BP.html#group-contributions",
    "href": "posts/pneumonia/Final_Project_BP.html#group-contributions",
    "title": "Pnuemonia Detection",
    "section": "Group Contributions:",
    "text": "Group Contributions:\nLia did the data preprocessing for the images and all visualizations such as the PCA plot. Furthermore, she made the the contrastive autoencoder, latent vectors, and worked on evaluation metrics for the models. For the blog posts she did the material and methods, results, and conclusions. Cameron worked on XGBoost Model in the project and wrote the introduction, abstract, and values statement of the blog post. Robsan worked on the Support Vector Machine. Emmanuel created the transformer and worked on model evaluation. Broadly adapted code imported from Google colab to be functional on the notebook. For the blog post, he added to the introduction and make did the reference implementation."
  },
  {
    "objectID": "posts/pneumonia/Final_Project_BP.html#personal-reflection",
    "href": "posts/pneumonia/Final_Project_BP.html#personal-reflection",
    "title": "Pnuemonia Detection",
    "section": "Personal Reflection:",
    "text": "Personal Reflection:\nThroughout this process, I found myself engaging in quite a bit of research on models similar to mine. I also had to learn how to gather information from various sources to create a transformer tailored to my specific needs. My perspective on executing machine learning projects has shifted as well; I had never considered employing pipelining models or leveraging multiple models to generate predictions on a dataset.\nOverall, I take pride in this project. I believe the topic struck an excellent balance between being intriguing, challenging, and relevant. The fact that we were able to successfully implement it and achieve solid accuracy is incredibly rewarding.\nAdditionally, I’ve enhanced my skills with GitHub and gained a better understanding of setting rules and branch protections, which will undoubtedly be valuable in the future. Moving forward, I plan to focus more on organizing pair programming sessions and fostering improved code review practices."
  },
  {
    "objectID": "posts/pneumonia/Final_Project_BP.html#references",
    "href": "posts/pneumonia/Final_Project_BP.html#references",
    "title": "Pnuemonia Detection",
    "section": "References",
    "text": "References\n\n\nMabrouk, Souhaib, Mohamed Ali Mahjoub, Fatma Hamdi, Slim Messaoud, and Mohamed Jmaiel. 2023. “Ensemble Learning Model for Pneumonia Detection in Chest x-Ray Images Using DenseNet, MobileNet and Vision Transformers.” arXiv Preprint arXiv:2312.07965. https://arxiv.org/abs/2312.07965.\n\n\nRahman, Md Raihanur, Md Rabiul Islam, and Md Hafizul Islam. 2023. “Pneumonia Detection Using MobileNet CNN Model.” Journal of Healthcare Engineering 2023: 1–12. https://doi.org/10.1155/2023/6672181.\n\n\nRahman, Tawsifur, Ahsan Khandakar, Yazan Qiblawey, Asmaa Tahir, Serkan Kiranyaz, S. B. M. Kashem, Md. Rashidul Islam, Md. Taufiq Islam, and M. E. H. Chowdhury. 2020. “Transfer Learning with Deep Convolutional Neural Network (CNN) for Pneumonia Detection Using Chest x-Ray.” arXiv Preprint arXiv:2004.06578. https://arxiv.org/abs/2004.06578.\n\n\nRajpurkar, Pranav, Jeremy Irvin, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy Ding, et al. 2017. “CheXNet: Radiologist-Level Pneumonia Detection on Chest x-Rays with Deep Learning.” arXiv Preprint arXiv:1711.05225. https://arxiv.org/pdf/1711.05225.\n\n\nSingh, Bhupendra, Supriya Thomas, and Amandeep Jaiswal. 2021. “Pneumonia Detection Using Deep Learning.” International Journal of Engineering Research & Technology (IJERT) 10 (7): 84–88. https://www.researchgate.net/publication/353590019_Pneumonia_Detection_using_Deep_Learning."
  },
  {
    "objectID": "posts/palmer/index.html",
    "href": "posts/palmer/index.html",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "Image source: @gabednick\n\n\n\n\nIn this blog post, I analyze the Palmer Penguins dataset to identify the best features for determining penguin species based on their measurements. First, I create two figures and a table to explore the relationships between different features. Next, I utilize Scikit-learn’s feature selection methods, employing chi-squared tests to select two numerical features and one categorical feature. With these features, I train and test a logistic regression model. The model demonstrates reasonable accuracy; however, to gain a better understanding of the results, I visualize the decision regions and present a confusion matrix.st features to be used to determine the species of a penguin based on its measurements. Firstly, I create two figures and a table to analysize the relationships between features. Then I use sci-kit learns feature selection with chi-squared tests to pick 2 numerical features and 1 categorical feature. Then using those features, I train and test a logistic regression model. The model was fairly accurate but to understand the results better, I plot the decision regions and use a confusion matrix.\n\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\n\n\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN\n\n\n\n\n\n\n\n\n\n\nThis code is from Professor Phil’s website. It removes unused columns and NA values, converts categorical feature columns into “one-hot encoded” 0-1 columns, and saves the resulting DataFrame as X_train. Additionally, the “Species” column is encoded using LabelEncoder and stored as y_train.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\n\nWe can check what the columns look like now.\n\nX_train.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nStage_Adult, 1 Egg Stage\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40.9\n16.6\n187.0\n3200.0\n9.08458\n-24.54903\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n1\n49.0\n19.5\n210.0\n3950.0\n9.53262\n-24.66867\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n2\n50.0\n15.2\n218.0\n5700.0\n8.25540\n-25.40075\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n3\n45.8\n14.6\n210.0\n4200.0\n7.79958\n-25.62618\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n4\n51.0\n18.8\n203.0\n4100.0\n9.23196\n-24.17282\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n\n\n\n\n\n\n\n\n\n\nI created two graphs each two quantative columns and one qualitative columns. Plot 1 shows the relationship with the body mass and flipper length between different penguin species. Plot 2 shows the difference in Culmen Length and depth across different penguin species.\n\n# Get the unencoded columns for easier graphing.\nqual = train[[\"Island\", \"Sex\", \"Species\"]].dropna()\n\n# Shorten species label for the legend\nqual[\"Species\"] = qual[\"Species\"].apply(lambda x: \"Chinstrap\" if x == \"Chinstrap penguin (Pygoscelis antarctica)\" \n                                         else (\"Gentoo\" if x == \"Gentoo penguin (Pygoscelis papua)\" \n                                               else \"Adelie\"))\n\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nplt.style.use('seaborn-v0_8-whitegrid')\n\nfig, ax = plt.subplots(1, 2, figsize = (10, 4))\n   \np1 = sns.scatterplot(X_train, x = \"Body Mass (g)\", y = \"Flipper Length (mm)\", hue=qual[\"Species\"], ax = ax[0])\np2 = sns.scatterplot(X_train, x = \"Culmen Length (mm)\", y = \"Culmen Depth (mm)\", hue=qual[\"Species\"], ax = ax[1])\n\n\n\n\n\n\n\n\nPlot 1 (Left): This graph shows the relationship between body mass and flipper length among different penguin species. Gentoo penguins are the largest, while Chinstrap and Adelie penguins overlap considerably in size. Adelie penguins show slightly more variation in mass for a given flipper length compared to Chinstraps.\nPlot 2 (Right): This graph illustrates the differences in culmen length and depth among the species. Adelie penguins have the deepest but shortest culmen, Gentoo penguins have longer but less deep culmens, and Chinstraps are in between. These differences in beak size are significant for distinguishing penguin species.\n\n\n\nNow I create a summary table of the penguins measurements based on clutch completetion.\n\ntable = X_train[[\"Clutch Completion_Yes\", \"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\", \"Body Mass (g)\"]]\ntable.groupby(\"Clutch Completion_Yes\").aggregate(['min', 'median', 'max'])\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\n\n\n\nmin\nmedian\nmax\nmin\nmedian\nmax\nmin\nmedian\nmax\nmin\nmedian\nmax\n\n\nClutch Completion_Yes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFalse\n35.9\n43.35\n58.0\n13.7\n17.85\n19.9\n172.0\n195.0\n225.0\n2700.0\n3737.5\n5700.0\n\n\nTrue\n34.0\n45.10\n55.9\n13.1\n17.20\n21.5\n176.0\n198.0\n230.0\n2850.0\n4100.0\n6300.0\n\n\n\n\n\n\n\nTable 1: This table shows that the most significant difference between penguins that had a full clutch and those that did not is their weight. Most of the penguins that produced two eggs weighed approximately 300 grams more. While there may be a correlation between clutch completion and weight, it is unlikely that there is a direct causation. Since clutch completion does not appear to impact this data significantly, it may not be a feature worth further investigation.\n\n\n\n\nHere I used the SelectKBest function from the sci-kit-learn library to choose the three features that I will include in my model. I separated feature selection because all three selected features are numerical. SelectKBest identifies the k best features based on a user-specified scoring function. I chose the chi-squared scoring function, as my features are intended for classification and are non-negative\n\nfrom sklearn.feature_selection import SelectKBest, chi2\n\n# Selecting 2 numerical feature\nquant = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']\nsel1 = SelectKBest(chi2, k=2)\nsel1.fit_transform(X_train[quant], y_train)\nf1 = sel1.get_feature_names_out()\n\n# Selecting 1 categorical feature\nqual = [\"Clutch Completion_Yes\", \"Clutch Completion_No\", \"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\", \"Sex_FEMALE\", \"Sex_MALE\"]\nsel2 = SelectKBest(chi2, k=1)\nsel2.fit_transform(X_train[qual], y_train)\nf2 = sel2.get_feature_names_out()\n\nThis function is so that I can get all the variations of the categorical feature.\n\ndef get_feat(f1, cat):\n    cols = list(f1)\n    clutch = [\"Clutch Completion_Yes\", \"Clutch Completion_No\"]\n    island = [\"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\"]\n    sex = [\"Sex_FEMALE\", \"Sex_MALE\"]\n    \n    if cat in clutch: return cols + clutch\n    if cat in island: return cols + island\n    if cat in sex: return cols + sex\n\n\ncols = get_feat(f1, f2[0])\ncols\n\n['Flipper Length (mm)',\n 'Body Mass (g)',\n 'Island_Biscoe',\n 'Island_Dream',\n 'Island_Torgersen']\n\n\nAlthough the culmen sizes initially appeared to be better features, the statistical tests indicated that flipper length and body mass were, in fact, the more significant features.\n\n\n\nThe model is trained on the data with features determined from above. I had to use StandardScalar to avoid a convergence error. I used the Logistic Regression model as it is a good fit for classification.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n\npipe = make_pipeline(StandardScaler(), LogisticRegression())\npipe.fit(X_train[cols], y_train)\npipe.score(X_train[cols], y_train)\n\n0.8984375\n\n\n\n\n\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\npipe.score(X_test[cols], y_test)\n\n0.8970588235294118\n\n\n\n\n\n\n\nMost of this code is adapted from Prof. Phil’s website.\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (8, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\nRegions for training set:\n\nplot_regions(pipe, X_train[cols], y_train)\n\n\n\n\n\n\n\n\nRegions for testing set:\n\nplot_regions(pipe, X_test[cols], y_test)\n\n\n\n\n\n\n\n\nLooking at the decision plots, we can see that our model is quite successful in distinguishing between Gentoo and Adelie penguins on the Biscoe and Torgersen islands. However, on Dream Island, where there is a mixture of Gentoo and Chinstrap penguins, the model struggles to differentiate between the two species.\n\n\n\n\nfrom sklearn.metrics import confusion_matrix\n\ny_test_pred = pipe.predict(X_test[cols])\nconfusion_matrix(y_test, y_test_pred)\n\narray([[26,  5,  0],\n       [ 2,  9,  0],\n       [ 0,  0, 26]])\n\n\nOnce again, this shows that model struggled the most with Gentoo and Chinstrap.\n\n\n\n\nThe model achieved a training accuracy of 0.89, which is the same as its testing accuracy. This indicates that the model is quite effective at predicting penguin species based on flipper length, body mass, and island. However, the decision regions suggest that the model had difficulty distinguishing between Chinstrap and Gentoo penguins on Dream Island. It appears that these two species have similar sizes, making them challenging to differentiate.\nIn this blog post, the two main things I learned were the importance of feature selection and the need to normalize data before feeding it into a model. When it came to feature selection, I explored several methods offered by Scikit-learn, including variance thresholds, statistical tests, and recursive feature elimination. I chose statistical testing because it felt more thorough than relying on variance alone, yet not as complex as recursion.I also ran into a convergence error while training a model, which led me to learn about data normalization. After some investigating, I realized the error might be due to some features not being normally distributed. I used Scikit-learn’s recommended scaling function to standardize the data, and the model was trained without any further issues. Lastly, I got more comfortable working with DataFrames—especially when it came to selecting and modifying data."
  },
  {
    "objectID": "posts/palmer/index.html#abstract",
    "href": "posts/palmer/index.html#abstract",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "In this blog post, I analyze the Palmer Penguins dataset to identify the best features for determining penguin species based on their measurements. First, I create two figures and a table to explore the relationships between different features. Next, I utilize Scikit-learn’s feature selection methods, employing chi-squared tests to select two numerical features and one categorical feature. With these features, I train and test a logistic regression model. The model demonstrates reasonable accuracy; however, to gain a better understanding of the results, I visualize the decision regions and present a confusion matrix.st features to be used to determine the species of a penguin based on its measurements. Firstly, I create two figures and a table to analysize the relationships between features. Then I use sci-kit learns feature selection with chi-squared tests to pick 2 numerical features and 1 categorical feature. Then using those features, I train and test a logistic regression model. The model was fairly accurate but to understand the results better, I plot the decision regions and use a confusion matrix.\n\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\n\n\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN"
  },
  {
    "objectID": "posts/palmer/index.html#data-preparation",
    "href": "posts/palmer/index.html#data-preparation",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "This code is from Professor Phil’s website. It removes unused columns and NA values, converts categorical feature columns into “one-hot encoded” 0-1 columns, and saves the resulting DataFrame as X_train. Additionally, the “Species” column is encoded using LabelEncoder and stored as y_train.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\n\nWe can check what the columns look like now.\n\nX_train.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nStage_Adult, 1 Egg Stage\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40.9\n16.6\n187.0\n3200.0\n9.08458\n-24.54903\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n1\n49.0\n19.5\n210.0\n3950.0\n9.53262\n-24.66867\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n2\n50.0\n15.2\n218.0\n5700.0\n8.25540\n-25.40075\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n3\n45.8\n14.6\n210.0\n4200.0\n7.79958\n-25.62618\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n4\n51.0\n18.8\n203.0\n4100.0\n9.23196\n-24.17282\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue"
  },
  {
    "objectID": "posts/palmer/index.html#data-visualization",
    "href": "posts/palmer/index.html#data-visualization",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "I created two graphs each two quantative columns and one qualitative columns. Plot 1 shows the relationship with the body mass and flipper length between different penguin species. Plot 2 shows the difference in Culmen Length and depth across different penguin species.\n\n# Get the unencoded columns for easier graphing.\nqual = train[[\"Island\", \"Sex\", \"Species\"]].dropna()\n\n# Shorten species label for the legend\nqual[\"Species\"] = qual[\"Species\"].apply(lambda x: \"Chinstrap\" if x == \"Chinstrap penguin (Pygoscelis antarctica)\" \n                                         else (\"Gentoo\" if x == \"Gentoo penguin (Pygoscelis papua)\" \n                                               else \"Adelie\"))\n\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nplt.style.use('seaborn-v0_8-whitegrid')\n\nfig, ax = plt.subplots(1, 2, figsize = (10, 4))\n   \np1 = sns.scatterplot(X_train, x = \"Body Mass (g)\", y = \"Flipper Length (mm)\", hue=qual[\"Species\"], ax = ax[0])\np2 = sns.scatterplot(X_train, x = \"Culmen Length (mm)\", y = \"Culmen Depth (mm)\", hue=qual[\"Species\"], ax = ax[1])\n\n\n\n\n\n\n\n\nPlot 1 (Left): This graph shows the relationship between body mass and flipper length among different penguin species. Gentoo penguins are the largest, while Chinstrap and Adelie penguins overlap considerably in size. Adelie penguins show slightly more variation in mass for a given flipper length compared to Chinstraps.\nPlot 2 (Right): This graph illustrates the differences in culmen length and depth among the species. Adelie penguins have the deepest but shortest culmen, Gentoo penguins have longer but less deep culmens, and Chinstraps are in between. These differences in beak size are significant for distinguishing penguin species.\n\n\n\nNow I create a summary table of the penguins measurements based on clutch completetion.\n\ntable = X_train[[\"Clutch Completion_Yes\", \"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\", \"Body Mass (g)\"]]\ntable.groupby(\"Clutch Completion_Yes\").aggregate(['min', 'median', 'max'])\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\n\n\n\nmin\nmedian\nmax\nmin\nmedian\nmax\nmin\nmedian\nmax\nmin\nmedian\nmax\n\n\nClutch Completion_Yes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFalse\n35.9\n43.35\n58.0\n13.7\n17.85\n19.9\n172.0\n195.0\n225.0\n2700.0\n3737.5\n5700.0\n\n\nTrue\n34.0\n45.10\n55.9\n13.1\n17.20\n21.5\n176.0\n198.0\n230.0\n2850.0\n4100.0\n6300.0\n\n\n\n\n\n\n\nTable 1: This table shows that the most significant difference between penguins that had a full clutch and those that did not is their weight. Most of the penguins that produced two eggs weighed approximately 300 grams more. While there may be a correlation between clutch completion and weight, it is unlikely that there is a direct causation. Since clutch completion does not appear to impact this data significantly, it may not be a feature worth further investigation."
  },
  {
    "objectID": "posts/palmer/index.html#feature-selection",
    "href": "posts/palmer/index.html#feature-selection",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "Here I used the SelectKBest function from the sci-kit-learn library to choose the three features that I will include in my model. I separated feature selection because all three selected features are numerical. SelectKBest identifies the k best features based on a user-specified scoring function. I chose the chi-squared scoring function, as my features are intended for classification and are non-negative\n\nfrom sklearn.feature_selection import SelectKBest, chi2\n\n# Selecting 2 numerical feature\nquant = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']\nsel1 = SelectKBest(chi2, k=2)\nsel1.fit_transform(X_train[quant], y_train)\nf1 = sel1.get_feature_names_out()\n\n# Selecting 1 categorical feature\nqual = [\"Clutch Completion_Yes\", \"Clutch Completion_No\", \"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\", \"Sex_FEMALE\", \"Sex_MALE\"]\nsel2 = SelectKBest(chi2, k=1)\nsel2.fit_transform(X_train[qual], y_train)\nf2 = sel2.get_feature_names_out()\n\nThis function is so that I can get all the variations of the categorical feature.\n\ndef get_feat(f1, cat):\n    cols = list(f1)\n    clutch = [\"Clutch Completion_Yes\", \"Clutch Completion_No\"]\n    island = [\"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\"]\n    sex = [\"Sex_FEMALE\", \"Sex_MALE\"]\n    \n    if cat in clutch: return cols + clutch\n    if cat in island: return cols + island\n    if cat in sex: return cols + sex\n\n\ncols = get_feat(f1, f2[0])\ncols\n\n['Flipper Length (mm)',\n 'Body Mass (g)',\n 'Island_Biscoe',\n 'Island_Dream',\n 'Island_Torgersen']\n\n\nAlthough the culmen sizes initially appeared to be better features, the statistical tests indicated that flipper length and body mass were, in fact, the more significant features."
  },
  {
    "objectID": "posts/palmer/index.html#training",
    "href": "posts/palmer/index.html#training",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "The model is trained on the data with features determined from above. I had to use StandardScalar to avoid a convergence error. I used the Logistic Regression model as it is a good fit for classification.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n\npipe = make_pipeline(StandardScaler(), LogisticRegression())\npipe.fit(X_train[cols], y_train)\npipe.score(X_train[cols], y_train)\n\n0.8984375"
  },
  {
    "objectID": "posts/palmer/index.html#testing",
    "href": "posts/palmer/index.html#testing",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "test_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\npipe.score(X_test[cols], y_test)\n\n0.8970588235294118"
  },
  {
    "objectID": "posts/palmer/index.html#results",
    "href": "posts/palmer/index.html#results",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "Most of this code is adapted from Prof. Phil’s website.\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (8, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\nRegions for training set:\n\nplot_regions(pipe, X_train[cols], y_train)\n\n\n\n\n\n\n\n\nRegions for testing set:\n\nplot_regions(pipe, X_test[cols], y_test)\n\n\n\n\n\n\n\n\nLooking at the decision plots, we can see that our model is quite successful in distinguishing between Gentoo and Adelie penguins on the Biscoe and Torgersen islands. However, on Dream Island, where there is a mixture of Gentoo and Chinstrap penguins, the model struggles to differentiate between the two species.\n\n\n\n\nfrom sklearn.metrics import confusion_matrix\n\ny_test_pred = pipe.predict(X_test[cols])\nconfusion_matrix(y_test, y_test_pred)\n\narray([[26,  5,  0],\n       [ 2,  9,  0],\n       [ 0,  0, 26]])\n\n\nOnce again, this shows that model struggled the most with Gentoo and Chinstrap."
  },
  {
    "objectID": "posts/palmer/index.html#discussion",
    "href": "posts/palmer/index.html#discussion",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "The model achieved a training accuracy of 0.89, which is the same as its testing accuracy. This indicates that the model is quite effective at predicting penguin species based on flipper length, body mass, and island. However, the decision regions suggest that the model had difficulty distinguishing between Chinstrap and Gentoo penguins on Dream Island. It appears that these two species have similar sizes, making them challenging to differentiate.\nIn this blog post, the two main things I learned were the importance of feature selection and the need to normalize data before feeding it into a model. When it came to feature selection, I explored several methods offered by Scikit-learn, including variance thresholds, statistical tests, and recursive feature elimination. I chose statistical testing because it felt more thorough than relying on variance alone, yet not as complex as recursion.I also ran into a convergence error while training a model, which led me to learn about data normalization. After some investigating, I realized the error might be due to some features not being normally distributed. I used Scikit-learn’s recommended scaling function to standardize the data, and the model was trained without any further issues. Lastly, I got more comfortable working with DataFrames—especially when it came to selecting and modifying data."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Emmanuel’s GitHub Blog",
    "section": "",
    "text": "Pnuemonia Detection\n\n\n\n\n\nIn this project, we built a convolutional neural network to embed chest X-ray images into a latent space, then compared three binary classifiers—Support Vector Machine, XGBoost, and Transformer—on their ability to detect pneumonia. Using contrastive learning and a variational autoencoder, we trained models on the Pneumonia Chest X-ray dataset from Kaggle. All models achieved around 78% accuracy, with high precision (up to 93%) but lower recall (as low as 37%). Our results highlight both the potential and limitations of non-CNN classifiers in medical image classification, particularly in contexts where false negatives carry high risk.\n\n\n\n\n\nMay 19, 2025\n\n\nLia Smith, Cameron Hudson, Robsan Dinka, Emmanuel Towner\n\n\n\n\n\n\n\n\n\n\n\n\nClassifying Palmer Penguins\n\n\n\n\n\nIn this blog post, I analyze the Palmer Penguins dataset to identify the best features for determining penguin species based on their measurements.\n\n\n\n\n\nFeb 12, 2025\n\n\nEmmanuel Towner\n\n\n\n\n\n\nNo matching items"
  }
]