{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Implementing the Perceptron Algorithm\n",
    "author: Emmanuel Towner\n",
    "date: '2025-03-31'\n",
    "description: \"Blog Post 4\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "Link to [perceptron source code](https://github.com/EpicET/EpicET.github.io/blob/main/posts/blog4/perceptron.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from perceptron import Perceptron, PerceptronOptimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cells 1 to 7 has been directly adapted from Prof. Phil's code. Cell 8 is slightly modified from the original code.\n",
    "The code below in the sets up the necessary functions to implement a perceptron algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "def perceptron_data(n_points = 300, noise = 0.2, p_dims = 2):\n",
    "    \n",
    "    y = torch.arange(n_points) >= int(n_points/2)\n",
    "    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n",
    "    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n",
    "\n",
    "    # convert y from {0, 1} to {-1, 1}\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = perceptron_data(n_points = 300, noise = 0.2)\n",
    "\n",
    "def plot_perceptron_data(X: torch.Tensor, y: torch.Tensor, ax):\n",
    "    assert X.shape[1] == 3, \"This function only works for data created with p_dims == 2\"\n",
    "    targets = [0, 1]\n",
    "    markers = [\"o\" , \",\"]\n",
    "    for i in range(2):\n",
    "        ix = y == targets[i]\n",
    "        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = 2*y[ix]-1, facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -2, vmax = 2, alpha = 0.5, marker = markers[i])\n",
    "    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n",
    "\n",
    "def draw_line(w: torch.Tensor, x_min: int, x_max: int, ax, **kwargs):\n",
    "    w_ = w.flatten()\n",
    "    x = torch.linspace(x_min, x_max, 101)\n",
    "    y = -(w_[0]*x + w_[2])/w_[1]\n",
    "    l = ax.plot(x, y, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Perceptron Algorithm\n",
    "This tests the Perceptron to see if the loss does reach 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a model and an optimizer\n",
    "p = Perceptron() \n",
    "opt = PerceptronOptimizer(p)\n",
    "\n",
    "loss = 1.0\n",
    "\n",
    "# for keeping track of loss values\n",
    "loss_vec = []\n",
    "\n",
    "n = X.size()[0]\n",
    "\n",
    "while loss > 0: # dangerous -- only terminates if data is linearly separable\n",
    "    \n",
    "    # not part of the update: just for tracking our progress    \n",
    "    loss = p.loss(X, y) \n",
    "    loss_vec.append(loss)\n",
    "    \n",
    "    # pick a random data point\n",
    "    i = torch.randint(n, size = (1,))\n",
    "    x_i = X[[i],:]\n",
    "    y_i = y[i]\n",
    "    \n",
    "    # perform a perceptron update using the random data point\n",
    "    opt.step(x_i, y_i)\n",
    "\n",
    "plt.plot(loss_vec, color = \"slategrey\")\n",
    "plt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\n",
    "labs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "This plots the decision boundary and the data points over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234567)\n",
    "\n",
    "# initialize a perceptron \n",
    "p = Perceptron()\n",
    "opt = PerceptronOptimizer(p)\n",
    "p.loss(X, y)\n",
    "\n",
    "# set up the figure\n",
    "plt.rcParams[\"figure.figsize\"] = (7, 5)\n",
    "fig, axarr = plt.subplots(2, 3, sharex = True, sharey = True)\n",
    "markers = [\"o\", \",\"]\n",
    "marker_map = {-1 : 0, 1 : 1}\n",
    "\n",
    "# initialize for main loop\n",
    "current_ax = 0\n",
    "loss = 1\n",
    "loss_vec = []\n",
    "\n",
    "while loss > 0:\n",
    "    \n",
    "    # Making sure we don't run out of axes\n",
    "    if current_ax >= len(axarr.ravel()):\n",
    "        print(\"Ran out of axes to plot. Stopping early.\")\n",
    "        break\n",
    "    \n",
    "    ax = axarr.ravel()[current_ax]\n",
    "\n",
    "    # save the old value of w for plotting later\n",
    "    old_w = torch.clone(p.w)\n",
    "    \n",
    "\n",
    "    # make an optimization step -- this is where the update actually happens\n",
    "    # now p.w is the new value \n",
    "\n",
    "    i = torch.randint(n, size = (1,))\n",
    "    x_i = X[[i],:]\n",
    "    y_i = y[i]\n",
    "    local_loss = p.loss(x_i, y_i).item()\n",
    "\n",
    "    if local_loss > 0:\n",
    "        opt.step(x_i, y_i)\n",
    "    \n",
    "    # if a change was made, plot the old and new decision boundaries\n",
    "    # also add the new loss to loss_vec for plotting below\n",
    "    if local_loss > 0:\n",
    "        plot_perceptron_data(X, y, ax)\n",
    "        draw_line(old_w, x_min = -1, x_max = 2, ax = ax, color = \"black\", linestyle = \"dashed\")\n",
    "        loss = p.loss(X, y).item()\n",
    "        loss_vec.append(loss)\n",
    "        draw_line(p.w, x_min = -1, x_max = 2, ax = ax, color = \"black\")\n",
    "        ax.scatter(X[i,0],X[i,1], color = \"black\", facecolors = \"none\", edgecolors = \"black\", marker = markers[marker_map[2*(y[i].item())-1]])\n",
    "        # draw_line(w, -10, 10, ax, color = \"black\")\n",
    "        ax.set_title(f\"loss = {loss:.3f}\")\n",
    "        ax.set(xlim = (-1, 2), ylim = (-1, 2))\n",
    "        current_ax += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create non-linearly separable data\n",
    "X, y = perceptron_data(n_points = 300, noise = 0.5)\n",
    "n = X.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234567)\n",
    "\n",
    "# initialize a perceptron \n",
    "p = Perceptron()\n",
    "opt = PerceptronOptimizer(p)\n",
    "p.loss(X, y)\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2, figsize=(12, 6))\n",
    "current_ax = 0\n",
    "\n",
    "loss = 1\n",
    "score_vec = [] \n",
    "\n",
    "while loss > 0 and len(score_vec) <= 1000:\n",
    "\n",
    "    # save the old value of w for plotting later\n",
    "    old_w = torch.clone(p.w)\n",
    "    \n",
    "    # make an optimization step -- this is where the update actually happens\n",
    "    # now p.w is the new value \n",
    "\n",
    "    i = torch.randint(n, size = (1,))\n",
    "    x_i = X[[i],:]\n",
    "    y_i = y[i]\n",
    "    local_loss = p.loss(x_i, y_i).item()\n",
    "    score = p.score(X).mean()\n",
    "\n",
    "    if local_loss > 0:\n",
    "        opt.step(x_i, y_i)\n",
    "    \n",
    "    if local_loss > 0:\n",
    "        loss = p.loss(X, y).item()\n",
    "        score = p.score(X).mean()\n",
    "        score_vec.append(score)\n",
    "\n",
    "# plot the score over iterations\n",
    "axarr[0].plot(range(len(score_vec)), score_vec, color=\"steelblue\", label=\"Score\")\n",
    "axarr[0].set_title(\"Score vs. Iterations\")\n",
    "axarr[0].set_xlabel(\"Iteration\")\n",
    "axarr[0].set_ylabel(\"Score\")\n",
    "\n",
    "# Plot the final decision boundary\n",
    "plot_perceptron_data(X, y, axarr[1])\n",
    "draw_line(p.w, x_min=-1, x_max=2, ax=axarr[1], color=\"black\")\n",
    "axarr[1].set_title(f\"Final Decision Boundary (Loss = {loss:.3f})\")\n",
    "axarr[1].set(xlim=(-1, 2), ylim=(-1, 2))\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = perceptron_data(n_points = 300, noise = 0.2, p_dims=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234567)\n",
    "\n",
    "# initialize a perceptron \n",
    "p = Perceptron()\n",
    "opt = PerceptronOptimizer(p)\n",
    "p.loss(X, y)\n",
    "\n",
    "loss = 1\n",
    "score_vec = [] \n",
    "\n",
    "while loss > 0 and len(score_vec) <= 1000:\n",
    "\n",
    "    # save the old value of w for plotting later\n",
    "    old_w = torch.clone(p.w)\n",
    "    \n",
    "    # make an optimization step -- this is where the update actually happens\n",
    "    # now p.w is the new value \n",
    "    prev_length = len(score_vec)\n",
    "    i = torch.randint(n, size = (1,))\n",
    "    x_i = X[[i],:]\n",
    "    y_i = y[i]\n",
    "    local_loss = p.loss(x_i, y_i).item()\n",
    "    score = p.score(X).mean()\n",
    "\n",
    "    if local_loss > 0:\n",
    "        opt.step(x_i, y_i)\n",
    "    \n",
    "    if local_loss > 0:\n",
    "        loss = p.loss(X, y).item()\n",
    "        loss_vec.append(loss)\n",
    "        score = p.score(X).mean()\n",
    "        score_vec.append(score)\n",
    "    \n",
    "    if(len(score_vec) != prev_length):\n",
    "        print(f\"Iteration {len(score_vec)}: Loss = {loss:.3f}, Score = {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minibatch Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_perceptron_training(X: torch.Tensor, y: torch.Tensor, model, optimizer, k: int = 0, \n",
    "                             max_iters: int = 1000, alpha: float =  0.1):\n",
    "\n",
    "    # Initialize model and optimizer\n",
    "    p = model()\n",
    "    opt = optimizer(p)\n",
    "    p.loss(X, y)\n",
    "\n",
    "    fig, axarr = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    loss = 1\n",
    "    loss_vec = []\n",
    "    score_vec = []\n",
    "\n",
    "    iteration = 0\n",
    "\n",
    "    while loss > 0 and iteration <= max_iters:\n",
    "\n",
    "        if k == 0:\n",
    "            i = torch.randint(X.size(0), size=(1,))\n",
    "            x_i = X[[i],:]\n",
    "            y_i = y[i]\n",
    "        else:\n",
    "            ix = torch.randperm(X.size(0))[:k]\n",
    "            x_i = X[ix,:]\n",
    "            y_i = y[ix]\n",
    "\n",
    "        local_loss = p.loss(x_i, y_i).item()\n",
    "        score = p.score(X).mean()\n",
    "\n",
    "        if local_loss > 0:\n",
    "            if k == 0:\n",
    "                opt.step(x_i, y_i)\n",
    "            else:\n",
    "                opt.step(x_i, y_i, alpha=alpha, mini_batch = True)\n",
    "\n",
    "            loss = p.loss(X, y).item()\n",
    "            loss_vec.append(loss)\n",
    "            score_vec.append(score)\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    # Plot score over iterations\n",
    "    axarr[0].plot(range(len(score_vec)), score_vec, color=\"steelblue\", label=\"Score\")\n",
    "    axarr[0].set_title(\"Score vs. Iterations\")\n",
    "    axarr[0].set_xlabel(\"Iteration\")\n",
    "    axarr[0].set_ylabel(\"Score\")\n",
    "\n",
    "    # Plot loss over iterations\n",
    "    axarr[1].plot(range(len(loss_vec)), loss_vec, color=\"steelblue\", label=\"Loss\")\n",
    "    axarr[1].set_title(\"Loss vs. Iterations\")\n",
    "    axarr[1].set_xlabel(\"Iteration\")\n",
    "    axarr[1].set_ylabel(\"Loss\")\n",
    "\n",
    "    # Plot final decision boundary\n",
    "    plot_perceptron_data(X, y, axarr[2])\n",
    "    draw_line(p.w, x_min=-1, x_max=2, ax=axarr[2], color=\"black\")\n",
    "    axarr[2].set_title(f\"Final Decision Boundary (Loss = {loss:.3f})\")\n",
    "    axarr[2].set(xlim=(-1, 2), ylim=(-1, 2))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234567)\n",
    "X, y = perceptron_data(n_points = 300, noise = 0.2, p_dims=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regualar Perceptron\n",
    "plot_perceptron_training(X, y, Perceptron, PerceptronOptimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-batch k = 1\n",
    "plot_perceptron_training(X, y, Perceptron, PerceptronOptimizer, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_perceptron_training(X, y, Perceptron, PerceptronOptimizer, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: k = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create non-linearly separable data\n",
    "X, y = perceptron_data(n_points = 300, noise = 0.7, p_dims=2)\n",
    "n = X.size(0)\n",
    "\n",
    "# Plot the non-linearly separable data\n",
    "fig, ax = plt.subplots(1, 1, figsize = (4, 4))\n",
    "ax.set(xlim = (-1, 2), ylim = (-1, 2))\n",
    "plot_perceptron_data(X, y, ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234567)\n",
    "\n",
    "# initialize a perceptron \n",
    "p = Perceptron()\n",
    "opt = PerceptronOptimizer(p)\n",
    "p.loss(X, y)\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "loss = 1\n",
    "loss_vec = [] \n",
    "k = n\n",
    "\n",
    "while loss > 0:\n",
    "    ix = torch.randperm(X.size(0))[:k]\n",
    "    x_i = X[ix,:]\n",
    "    y_i = y[ix]\n",
    "    local_loss = p.loss(x_i, y_i).item()\n",
    "    score = p.score(X).mean()\n",
    "\n",
    "    if local_loss > 0:\n",
    "        opt.step(x_i, y_i, alpha=0.0001, mini_batch = True)\n",
    "    \n",
    "    if local_loss > 0:\n",
    "        loss = p.loss(X, y).item()\n",
    "        score = p.score(X).mean()\n",
    "        score_vec.append(score)\n",
    "        loss_vec.append(loss)\n",
    "\n",
    "# plot the loss over iterations\n",
    "axarr[0].plot(range(len(loss_vec)), loss_vec, color=\"steelblue\", label=\"Loss\")\n",
    "axarr[0].set_title(\"Loss vs. Iterations\")\n",
    "axarr[0].set_xlabel(\"Iteration\")\n",
    "axarr[0].set_ylabel(\"Loss\")\n",
    "\n",
    "# Plot the final decision boundary\n",
    "plot_perceptron_data(X, y, axarr[1])\n",
    "draw_line(p.w, x_min=-1, x_max=2, ax=axarr[1], color=\"black\")\n",
    "axarr[1].set_title(f\"Final Decision Boundary (Loss = {loss:.3f})\")\n",
    "axarr[1].set(xlim=(-1, 2), ylim=(-1, 2))\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
